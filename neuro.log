WARNING: Logging before InitGoogleLogging() is written to STDERR
W0804 19:42:10.619678 27590 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0804 19:42:10.619750 27590 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0804 19:42:10.619765 27590 _caffe.cpp:142] Net('./zhang/colorization/models/colorization_deploy_v2.prototxt', 1, weights='./zhang/colorization/models/colorization_release_v2.caffemodel')
I0804 19:42:10.621417 27590 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_deploy_v2.prototxt
I0804 19:42:10.621446 27590 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 19:42:10.621711 27590 net.cpp:51] Initializing net from parameters: 
name: "LtoAB"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data_l"
  type: "Input"
  top: "data_l"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "bw_conv1_1"
  type: "Convolution"
  bottom: "data_l"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_2norm"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_2norm"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_2norm"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_2norm"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_3norm"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_3norm"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_3norm"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_3norm"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_3norm"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_3norm"
  top: "conv6_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv6_3"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "conv6_3"
  top: "conv6_3"
}
layer {
  name: "conv6_3norm"
  type: "BatchNorm"
  bottom: "conv6_3"
  top: "conv6_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_3norm"
  top: "conv7_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv7_3"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "conv7_3"
  top: "conv7_3"
}
layer {
  name: "conv7_3norm"
  type: "BatchNorm"
  bottom: "conv7_3"
  top: "conv7_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv8_1"
  type: "Deconvolution"
  bottom: "conv7_3norm"
  top: "conv8_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    stride: 2
    dilation: 1
  }
}
layer {
  name: "relu8_1"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_2"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv8_3"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_3"
  type: "ReLU"
  bottom: "conv8_3"
  top: "conv8_3"
}
layer {
  name: "conv8_313"
  type: "Convolution"
  bottom: "conv8_3"
  top: "conv8_313"
  convolution_param {
    num_output: 313
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv8_313_rh"
  type: "Scale"
  bottom: "conv8_313"
  top: "conv8_313_rh"
  scale_param {
    filler {
      type: "constant"
      value: 2.606
    }
    bias_term: false
  }
}
layer {
  name: "class8_313_rh"
  type: "Softmax"
  bottom: "conv8_313_rh"
  top: "class8_313_rh"
}
layer {
  name: "class8_ab"
  type: "Convolution"
  bottom: "class8_313_rh"
  top: "class8_ab"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "Silence"
  type: "Silence"
  bottom: "class8_ab"
}
I0804 19:42:10.621878 27590 layer_factory.hpp:77] Creating layer data_l
I0804 19:42:10.621897 27590 net.cpp:84] Creating Layer data_l
I0804 19:42:10.621909 27590 net.cpp:380] data_l -> data_l
I0804 19:42:10.632519 27590 net.cpp:122] Setting up data_l
I0804 19:42:10.632561 27590 net.cpp:129] Top shape: 1 1 224 224 (50176)
I0804 19:42:10.632573 27590 net.cpp:137] Memory required for data: 200704
I0804 19:42:10.632586 27590 layer_factory.hpp:77] Creating layer bw_conv1_1
I0804 19:42:10.632609 27590 net.cpp:84] Creating Layer bw_conv1_1
I0804 19:42:10.632622 27590 net.cpp:406] bw_conv1_1 <- data_l
I0804 19:42:10.632635 27590 net.cpp:380] bw_conv1_1 -> conv1_1
I0804 19:42:10.634754 27590 net.cpp:122] Setting up bw_conv1_1
I0804 19:42:10.634788 27590 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 19:42:10.634799 27590 net.cpp:137] Memory required for data: 13045760
I0804 19:42:10.634819 27590 layer_factory.hpp:77] Creating layer relu1_1
I0804 19:42:10.634837 27590 net.cpp:84] Creating Layer relu1_1
I0804 19:42:10.634848 27590 net.cpp:406] relu1_1 <- conv1_1
I0804 19:42:10.634862 27590 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0804 19:42:10.634877 27590 net.cpp:122] Setting up relu1_1
I0804 19:42:10.634889 27590 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 19:42:10.634901 27590 net.cpp:137] Memory required for data: 25890816
I0804 19:42:10.634910 27590 layer_factory.hpp:77] Creating layer conv1_2
I0804 19:42:10.634925 27590 net.cpp:84] Creating Layer conv1_2
I0804 19:42:10.634935 27590 net.cpp:406] conv1_2 <- conv1_1
I0804 19:42:10.634949 27590 net.cpp:380] conv1_2 -> conv1_2
I0804 19:42:10.636019 27590 net.cpp:122] Setting up conv1_2
I0804 19:42:10.636044 27590 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 19:42:10.636054 27590 net.cpp:137] Memory required for data: 29102080
I0804 19:42:10.636072 27590 layer_factory.hpp:77] Creating layer relu1_2
I0804 19:42:10.636087 27590 net.cpp:84] Creating Layer relu1_2
I0804 19:42:10.636098 27590 net.cpp:406] relu1_2 <- conv1_2
I0804 19:42:10.636111 27590 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0804 19:42:10.636126 27590 net.cpp:122] Setting up relu1_2
I0804 19:42:10.636137 27590 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 19:42:10.636148 27590 net.cpp:137] Memory required for data: 32313344
I0804 19:42:10.636158 27590 layer_factory.hpp:77] Creating layer conv1_2norm
I0804 19:42:10.636173 27590 net.cpp:84] Creating Layer conv1_2norm
I0804 19:42:10.636183 27590 net.cpp:406] conv1_2norm <- conv1_2
I0804 19:42:10.636196 27590 net.cpp:380] conv1_2norm -> conv1_2norm
I0804 19:42:10.636391 27590 net.cpp:122] Setting up conv1_2norm
I0804 19:42:10.636406 27590 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 19:42:10.636416 27590 net.cpp:137] Memory required for data: 35524608
I0804 19:42:10.636433 27590 layer_factory.hpp:77] Creating layer conv2_1
I0804 19:42:10.636448 27590 net.cpp:84] Creating Layer conv2_1
I0804 19:42:10.636459 27590 net.cpp:406] conv2_1 <- conv1_2norm
I0804 19:42:10.636489 27590 net.cpp:380] conv2_1 -> conv2_1
I0804 19:42:10.637596 27590 net.cpp:122] Setting up conv2_1
I0804 19:42:10.637624 27590 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 19:42:10.637634 27590 net.cpp:137] Memory required for data: 41947136
I0804 19:42:10.637652 27590 layer_factory.hpp:77] Creating layer relu2_1
I0804 19:42:10.637666 27590 net.cpp:84] Creating Layer relu2_1
I0804 19:42:10.637678 27590 net.cpp:406] relu2_1 <- conv2_1
I0804 19:42:10.637691 27590 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0804 19:42:10.637704 27590 net.cpp:122] Setting up relu2_1
I0804 19:42:10.637715 27590 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 19:42:10.637727 27590 net.cpp:137] Memory required for data: 48369664
I0804 19:42:10.637737 27590 layer_factory.hpp:77] Creating layer conv2_2
I0804 19:42:10.637753 27590 net.cpp:84] Creating Layer conv2_2
I0804 19:42:10.637763 27590 net.cpp:406] conv2_2 <- conv2_1
I0804 19:42:10.637778 27590 net.cpp:380] conv2_2 -> conv2_2
I0804 19:42:10.638890 27590 net.cpp:122] Setting up conv2_2
I0804 19:42:10.638952 27590 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 19:42:10.638963 27590 net.cpp:137] Memory required for data: 49975296
I0804 19:42:10.638978 27590 layer_factory.hpp:77] Creating layer relu2_2
I0804 19:42:10.638993 27590 net.cpp:84] Creating Layer relu2_2
I0804 19:42:10.639004 27590 net.cpp:406] relu2_2 <- conv2_2
I0804 19:42:10.639016 27590 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0804 19:42:10.639030 27590 net.cpp:122] Setting up relu2_2
I0804 19:42:10.639042 27590 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 19:42:10.639052 27590 net.cpp:137] Memory required for data: 51580928
I0804 19:42:10.639062 27590 layer_factory.hpp:77] Creating layer conv2_2norm
I0804 19:42:10.639077 27590 net.cpp:84] Creating Layer conv2_2norm
I0804 19:42:10.639087 27590 net.cpp:406] conv2_2norm <- conv2_2
I0804 19:42:10.639152 27590 net.cpp:380] conv2_2norm -> conv2_2norm
I0804 19:42:10.639350 27590 net.cpp:122] Setting up conv2_2norm
I0804 19:42:10.639366 27590 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 19:42:10.639376 27590 net.cpp:137] Memory required for data: 53186560
I0804 19:42:10.639391 27590 layer_factory.hpp:77] Creating layer conv3_1
I0804 19:42:10.639407 27590 net.cpp:84] Creating Layer conv3_1
I0804 19:42:10.639418 27590 net.cpp:406] conv3_1 <- conv2_2norm
I0804 19:42:10.639430 27590 net.cpp:380] conv3_1 -> conv3_1
I0804 19:42:10.639890 27590 net.cpp:122] Setting up conv3_1
I0804 19:42:10.639907 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.639919 27590 net.cpp:137] Memory required for data: 56397824
I0804 19:42:10.639931 27590 layer_factory.hpp:77] Creating layer relu3_1
I0804 19:42:10.639945 27590 net.cpp:84] Creating Layer relu3_1
I0804 19:42:10.639955 27590 net.cpp:406] relu3_1 <- conv3_1
I0804 19:42:10.639968 27590 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0804 19:42:10.639981 27590 net.cpp:122] Setting up relu3_1
I0804 19:42:10.639993 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.640003 27590 net.cpp:137] Memory required for data: 59609088
I0804 19:42:10.640013 27590 layer_factory.hpp:77] Creating layer conv3_2
I0804 19:42:10.640027 27590 net.cpp:84] Creating Layer conv3_2
I0804 19:42:10.640038 27590 net.cpp:406] conv3_2 <- conv3_1
I0804 19:42:10.640050 27590 net.cpp:380] conv3_2 -> conv3_2
I0804 19:42:10.641615 27590 net.cpp:122] Setting up conv3_2
I0804 19:42:10.641646 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.641657 27590 net.cpp:137] Memory required for data: 62820352
I0804 19:42:10.641724 27590 layer_factory.hpp:77] Creating layer relu3_2
I0804 19:42:10.641741 27590 net.cpp:84] Creating Layer relu3_2
I0804 19:42:10.641752 27590 net.cpp:406] relu3_2 <- conv3_2
I0804 19:42:10.641767 27590 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0804 19:42:10.641780 27590 net.cpp:122] Setting up relu3_2
I0804 19:42:10.641791 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.641803 27590 net.cpp:137] Memory required for data: 66031616
I0804 19:42:10.641813 27590 layer_factory.hpp:77] Creating layer conv3_3
I0804 19:42:10.641834 27590 net.cpp:84] Creating Layer conv3_3
I0804 19:42:10.641846 27590 net.cpp:406] conv3_3 <- conv3_2
I0804 19:42:10.641860 27590 net.cpp:380] conv3_3 -> conv3_3
I0804 19:42:10.643422 27590 net.cpp:122] Setting up conv3_3
I0804 19:42:10.643491 27590 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 19:42:10.643502 27590 net.cpp:137] Memory required for data: 66834432
I0804 19:42:10.643517 27590 layer_factory.hpp:77] Creating layer relu3_3
I0804 19:42:10.643535 27590 net.cpp:84] Creating Layer relu3_3
I0804 19:42:10.643546 27590 net.cpp:406] relu3_3 <- conv3_3
I0804 19:42:10.643559 27590 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0804 19:42:10.643573 27590 net.cpp:122] Setting up relu3_3
I0804 19:42:10.643584 27590 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 19:42:10.643594 27590 net.cpp:137] Memory required for data: 67637248
I0804 19:42:10.643605 27590 layer_factory.hpp:77] Creating layer conv3_3norm
I0804 19:42:10.643618 27590 net.cpp:84] Creating Layer conv3_3norm
I0804 19:42:10.643630 27590 net.cpp:406] conv3_3norm <- conv3_3
I0804 19:42:10.643643 27590 net.cpp:380] conv3_3norm -> conv3_3norm
I0804 19:42:10.643836 27590 net.cpp:122] Setting up conv3_3norm
I0804 19:42:10.643851 27590 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 19:42:10.643860 27590 net.cpp:137] Memory required for data: 68440064
I0804 19:42:10.643875 27590 layer_factory.hpp:77] Creating layer conv4_1
I0804 19:42:10.643893 27590 net.cpp:84] Creating Layer conv4_1
I0804 19:42:10.643903 27590 net.cpp:406] conv4_1 <- conv3_3norm
I0804 19:42:10.643916 27590 net.cpp:380] conv4_1 -> conv4_1
I0804 19:42:10.646618 27590 net.cpp:122] Setting up conv4_1
I0804 19:42:10.646658 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.646670 27590 net.cpp:137] Memory required for data: 70045696
I0804 19:42:10.646685 27590 layer_factory.hpp:77] Creating layer relu4_1
I0804 19:42:10.646700 27590 net.cpp:84] Creating Layer relu4_1
I0804 19:42:10.646711 27590 net.cpp:406] relu4_1 <- conv4_1
I0804 19:42:10.646725 27590 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0804 19:42:10.646740 27590 net.cpp:122] Setting up relu4_1
I0804 19:42:10.646752 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.646762 27590 net.cpp:137] Memory required for data: 71651328
I0804 19:42:10.646772 27590 layer_factory.hpp:77] Creating layer conv4_2
I0804 19:42:10.646788 27590 net.cpp:84] Creating Layer conv4_2
I0804 19:42:10.646800 27590 net.cpp:406] conv4_2 <- conv4_1
I0804 19:42:10.646811 27590 net.cpp:380] conv4_2 -> conv4_2
I0804 19:42:10.652024 27590 net.cpp:122] Setting up conv4_2
I0804 19:42:10.652070 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.652082 27590 net.cpp:137] Memory required for data: 73256960
I0804 19:42:10.652098 27590 layer_factory.hpp:77] Creating layer relu4_2
I0804 19:42:10.652115 27590 net.cpp:84] Creating Layer relu4_2
I0804 19:42:10.652127 27590 net.cpp:406] relu4_2 <- conv4_2
I0804 19:42:10.652140 27590 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0804 19:42:10.652156 27590 net.cpp:122] Setting up relu4_2
I0804 19:42:10.652168 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.652179 27590 net.cpp:137] Memory required for data: 74862592
I0804 19:42:10.652189 27590 layer_factory.hpp:77] Creating layer conv4_3
I0804 19:42:10.652202 27590 net.cpp:84] Creating Layer conv4_3
I0804 19:42:10.652214 27590 net.cpp:406] conv4_3 <- conv4_2
I0804 19:42:10.652230 27590 net.cpp:380] conv4_3 -> conv4_3
I0804 19:42:10.657335 27590 net.cpp:122] Setting up conv4_3
I0804 19:42:10.657379 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.657390 27590 net.cpp:137] Memory required for data: 76468224
I0804 19:42:10.657407 27590 layer_factory.hpp:77] Creating layer relu4_3
I0804 19:42:10.657424 27590 net.cpp:84] Creating Layer relu4_3
I0804 19:42:10.657436 27590 net.cpp:406] relu4_3 <- conv4_3
I0804 19:42:10.657449 27590 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0804 19:42:10.657464 27590 net.cpp:122] Setting up relu4_3
I0804 19:42:10.657492 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.657507 27590 net.cpp:137] Memory required for data: 78073856
I0804 19:42:10.657517 27590 layer_factory.hpp:77] Creating layer conv4_3norm
I0804 19:42:10.657531 27590 net.cpp:84] Creating Layer conv4_3norm
I0804 19:42:10.657541 27590 net.cpp:406] conv4_3norm <- conv4_3
I0804 19:42:10.657554 27590 net.cpp:380] conv4_3norm -> conv4_3norm
I0804 19:42:10.657757 27590 net.cpp:122] Setting up conv4_3norm
I0804 19:42:10.657771 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.657781 27590 net.cpp:137] Memory required for data: 79679488
I0804 19:42:10.657795 27590 layer_factory.hpp:77] Creating layer conv5_1
I0804 19:42:10.657810 27590 net.cpp:84] Creating Layer conv5_1
I0804 19:42:10.657821 27590 net.cpp:406] conv5_1 <- conv4_3norm
I0804 19:42:10.657836 27590 net.cpp:380] conv5_1 -> conv5_1
I0804 19:42:10.662909 27590 net.cpp:122] Setting up conv5_1
I0804 19:42:10.662955 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.662966 27590 net.cpp:137] Memory required for data: 81285120
I0804 19:42:10.662988 27590 layer_factory.hpp:77] Creating layer relu5_1
I0804 19:42:10.663007 27590 net.cpp:84] Creating Layer relu5_1
I0804 19:42:10.663018 27590 net.cpp:406] relu5_1 <- conv5_1
I0804 19:42:10.663031 27590 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0804 19:42:10.663046 27590 net.cpp:122] Setting up relu5_1
I0804 19:42:10.663058 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.663069 27590 net.cpp:137] Memory required for data: 82890752
I0804 19:42:10.663079 27590 layer_factory.hpp:77] Creating layer conv5_2
I0804 19:42:10.663097 27590 net.cpp:84] Creating Layer conv5_2
I0804 19:42:10.663107 27590 net.cpp:406] conv5_2 <- conv5_1
I0804 19:42:10.663120 27590 net.cpp:380] conv5_2 -> conv5_2
I0804 19:42:10.668066 27590 net.cpp:122] Setting up conv5_2
I0804 19:42:10.668113 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.668125 27590 net.cpp:137] Memory required for data: 84496384
I0804 19:42:10.668140 27590 layer_factory.hpp:77] Creating layer relu5_2
I0804 19:42:10.668159 27590 net.cpp:84] Creating Layer relu5_2
I0804 19:42:10.668170 27590 net.cpp:406] relu5_2 <- conv5_2
I0804 19:42:10.668182 27590 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0804 19:42:10.668197 27590 net.cpp:122] Setting up relu5_2
I0804 19:42:10.668210 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.668220 27590 net.cpp:137] Memory required for data: 86102016
I0804 19:42:10.668229 27590 layer_factory.hpp:77] Creating layer conv5_3
I0804 19:42:10.668246 27590 net.cpp:84] Creating Layer conv5_3
I0804 19:42:10.668256 27590 net.cpp:406] conv5_3 <- conv5_2
I0804 19:42:10.668268 27590 net.cpp:380] conv5_3 -> conv5_3
I0804 19:42:10.673223 27590 net.cpp:122] Setting up conv5_3
I0804 19:42:10.673270 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.673282 27590 net.cpp:137] Memory required for data: 87707648
I0804 19:42:10.673297 27590 layer_factory.hpp:77] Creating layer relu5_3
I0804 19:42:10.673312 27590 net.cpp:84] Creating Layer relu5_3
I0804 19:42:10.673324 27590 net.cpp:406] relu5_3 <- conv5_3
I0804 19:42:10.673338 27590 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0804 19:42:10.673353 27590 net.cpp:122] Setting up relu5_3
I0804 19:42:10.673365 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.673375 27590 net.cpp:137] Memory required for data: 89313280
I0804 19:42:10.673385 27590 layer_factory.hpp:77] Creating layer conv5_3norm
I0804 19:42:10.673400 27590 net.cpp:84] Creating Layer conv5_3norm
I0804 19:42:10.673410 27590 net.cpp:406] conv5_3norm <- conv5_3
I0804 19:42:10.673424 27590 net.cpp:380] conv5_3norm -> conv5_3norm
I0804 19:42:10.673624 27590 net.cpp:122] Setting up conv5_3norm
I0804 19:42:10.673640 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.673650 27590 net.cpp:137] Memory required for data: 90918912
I0804 19:42:10.673663 27590 layer_factory.hpp:77] Creating layer conv6_1
I0804 19:42:10.673683 27590 net.cpp:84] Creating Layer conv6_1
I0804 19:42:10.673712 27590 net.cpp:406] conv6_1 <- conv5_3norm
I0804 19:42:10.673724 27590 net.cpp:380] conv6_1 -> conv6_1
I0804 19:42:10.678587 27590 net.cpp:122] Setting up conv6_1
I0804 19:42:10.678632 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.678643 27590 net.cpp:137] Memory required for data: 92524544
I0804 19:42:10.678659 27590 layer_factory.hpp:77] Creating layer relu6_1
I0804 19:42:10.678674 27590 net.cpp:84] Creating Layer relu6_1
I0804 19:42:10.678686 27590 net.cpp:406] relu6_1 <- conv6_1
I0804 19:42:10.678701 27590 net.cpp:367] relu6_1 -> conv6_1 (in-place)
I0804 19:42:10.678716 27590 net.cpp:122] Setting up relu6_1
I0804 19:42:10.678728 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.678738 27590 net.cpp:137] Memory required for data: 94130176
I0804 19:42:10.678748 27590 layer_factory.hpp:77] Creating layer conv6_2
I0804 19:42:10.678764 27590 net.cpp:84] Creating Layer conv6_2
I0804 19:42:10.678776 27590 net.cpp:406] conv6_2 <- conv6_1
I0804 19:42:10.678788 27590 net.cpp:380] conv6_2 -> conv6_2
I0804 19:42:10.683681 27590 net.cpp:122] Setting up conv6_2
I0804 19:42:10.683725 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.683737 27590 net.cpp:137] Memory required for data: 95735808
I0804 19:42:10.683753 27590 layer_factory.hpp:77] Creating layer relu6_2
I0804 19:42:10.683768 27590 net.cpp:84] Creating Layer relu6_2
I0804 19:42:10.683780 27590 net.cpp:406] relu6_2 <- conv6_2
I0804 19:42:10.683794 27590 net.cpp:367] relu6_2 -> conv6_2 (in-place)
I0804 19:42:10.683809 27590 net.cpp:122] Setting up relu6_2
I0804 19:42:10.683820 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.683831 27590 net.cpp:137] Memory required for data: 97341440
I0804 19:42:10.683841 27590 layer_factory.hpp:77] Creating layer conv6_3
I0804 19:42:10.683856 27590 net.cpp:84] Creating Layer conv6_3
I0804 19:42:10.683866 27590 net.cpp:406] conv6_3 <- conv6_2
I0804 19:42:10.683881 27590 net.cpp:380] conv6_3 -> conv6_3
I0804 19:42:10.688747 27590 net.cpp:122] Setting up conv6_3
I0804 19:42:10.688793 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.688804 27590 net.cpp:137] Memory required for data: 98947072
I0804 19:42:10.688819 27590 layer_factory.hpp:77] Creating layer relu6_3
I0804 19:42:10.688838 27590 net.cpp:84] Creating Layer relu6_3
I0804 19:42:10.688849 27590 net.cpp:406] relu6_3 <- conv6_3
I0804 19:42:10.688863 27590 net.cpp:367] relu6_3 -> conv6_3 (in-place)
I0804 19:42:10.688876 27590 net.cpp:122] Setting up relu6_3
I0804 19:42:10.688889 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.688899 27590 net.cpp:137] Memory required for data: 100552704
I0804 19:42:10.688910 27590 layer_factory.hpp:77] Creating layer conv6_3norm
I0804 19:42:10.688925 27590 net.cpp:84] Creating Layer conv6_3norm
I0804 19:42:10.688935 27590 net.cpp:406] conv6_3norm <- conv6_3
I0804 19:42:10.688947 27590 net.cpp:380] conv6_3norm -> conv6_3norm
I0804 19:42:10.689162 27590 net.cpp:122] Setting up conv6_3norm
I0804 19:42:10.689179 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.689190 27590 net.cpp:137] Memory required for data: 102158336
I0804 19:42:10.689204 27590 layer_factory.hpp:77] Creating layer conv7_1
I0804 19:42:10.689219 27590 net.cpp:84] Creating Layer conv7_1
I0804 19:42:10.689230 27590 net.cpp:406] conv7_1 <- conv6_3norm
I0804 19:42:10.689244 27590 net.cpp:380] conv7_1 -> conv7_1
I0804 19:42:10.694128 27590 net.cpp:122] Setting up conv7_1
I0804 19:42:10.694175 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.694186 27590 net.cpp:137] Memory required for data: 103763968
I0804 19:42:10.694202 27590 layer_factory.hpp:77] Creating layer relu7_1
I0804 19:42:10.694218 27590 net.cpp:84] Creating Layer relu7_1
I0804 19:42:10.694229 27590 net.cpp:406] relu7_1 <- conv7_1
I0804 19:42:10.694244 27590 net.cpp:367] relu7_1 -> conv7_1 (in-place)
I0804 19:42:10.694259 27590 net.cpp:122] Setting up relu7_1
I0804 19:42:10.694272 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.694281 27590 net.cpp:137] Memory required for data: 105369600
I0804 19:42:10.694310 27590 layer_factory.hpp:77] Creating layer conv7_2
I0804 19:42:10.694325 27590 net.cpp:84] Creating Layer conv7_2
I0804 19:42:10.694335 27590 net.cpp:406] conv7_2 <- conv7_1
I0804 19:42:10.694350 27590 net.cpp:380] conv7_2 -> conv7_2
I0804 19:42:10.699260 27590 net.cpp:122] Setting up conv7_2
I0804 19:42:10.699307 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.699318 27590 net.cpp:137] Memory required for data: 106975232
I0804 19:42:10.699333 27590 layer_factory.hpp:77] Creating layer relu7_2
I0804 19:42:10.699352 27590 net.cpp:84] Creating Layer relu7_2
I0804 19:42:10.699363 27590 net.cpp:406] relu7_2 <- conv7_2
I0804 19:42:10.699376 27590 net.cpp:367] relu7_2 -> conv7_2 (in-place)
I0804 19:42:10.699391 27590 net.cpp:122] Setting up relu7_2
I0804 19:42:10.699404 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.699414 27590 net.cpp:137] Memory required for data: 108580864
I0804 19:42:10.699424 27590 layer_factory.hpp:77] Creating layer conv7_3
I0804 19:42:10.699440 27590 net.cpp:84] Creating Layer conv7_3
I0804 19:42:10.699450 27590 net.cpp:406] conv7_3 <- conv7_2
I0804 19:42:10.699463 27590 net.cpp:380] conv7_3 -> conv7_3
I0804 19:42:10.704349 27590 net.cpp:122] Setting up conv7_3
I0804 19:42:10.704396 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.704407 27590 net.cpp:137] Memory required for data: 110186496
I0804 19:42:10.704422 27590 layer_factory.hpp:77] Creating layer relu7_3
I0804 19:42:10.704439 27590 net.cpp:84] Creating Layer relu7_3
I0804 19:42:10.704452 27590 net.cpp:406] relu7_3 <- conv7_3
I0804 19:42:10.704464 27590 net.cpp:367] relu7_3 -> conv7_3 (in-place)
I0804 19:42:10.704478 27590 net.cpp:122] Setting up relu7_3
I0804 19:42:10.704490 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.704500 27590 net.cpp:137] Memory required for data: 111792128
I0804 19:42:10.704511 27590 layer_factory.hpp:77] Creating layer conv7_3norm
I0804 19:42:10.704526 27590 net.cpp:84] Creating Layer conv7_3norm
I0804 19:42:10.704537 27590 net.cpp:406] conv7_3norm <- conv7_3
I0804 19:42:10.704550 27590 net.cpp:380] conv7_3norm -> conv7_3norm
I0804 19:42:10.704764 27590 net.cpp:122] Setting up conv7_3norm
I0804 19:42:10.704779 27590 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:42:10.704790 27590 net.cpp:137] Memory required for data: 113397760
I0804 19:42:10.704804 27590 layer_factory.hpp:77] Creating layer conv8_1
I0804 19:42:10.704818 27590 net.cpp:84] Creating Layer conv8_1
I0804 19:42:10.704829 27590 net.cpp:406] conv8_1 <- conv7_3norm
I0804 19:42:10.704843 27590 net.cpp:380] conv8_1 -> conv8_1
I0804 19:42:10.709282 27590 net.cpp:122] Setting up conv8_1
I0804 19:42:10.709329 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.709341 27590 net.cpp:137] Memory required for data: 116609024
I0804 19:42:10.709357 27590 layer_factory.hpp:77] Creating layer relu8_1
I0804 19:42:10.709373 27590 net.cpp:84] Creating Layer relu8_1
I0804 19:42:10.709385 27590 net.cpp:406] relu8_1 <- conv8_1
I0804 19:42:10.709398 27590 net.cpp:367] relu8_1 -> conv8_1 (in-place)
I0804 19:42:10.709414 27590 net.cpp:122] Setting up relu8_1
I0804 19:42:10.709426 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.709436 27590 net.cpp:137] Memory required for data: 119820288
I0804 19:42:10.709446 27590 layer_factory.hpp:77] Creating layer conv8_2
I0804 19:42:10.709461 27590 net.cpp:84] Creating Layer conv8_2
I0804 19:42:10.709471 27590 net.cpp:406] conv8_2 <- conv8_1
I0804 19:42:10.709486 27590 net.cpp:380] conv8_2 -> conv8_2
I0804 19:42:10.711112 27590 net.cpp:122] Setting up conv8_2
I0804 19:42:10.711136 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.711148 27590 net.cpp:137] Memory required for data: 123031552
I0804 19:42:10.711161 27590 layer_factory.hpp:77] Creating layer relu8_2
I0804 19:42:10.711175 27590 net.cpp:84] Creating Layer relu8_2
I0804 19:42:10.711186 27590 net.cpp:406] relu8_2 <- conv8_2
I0804 19:42:10.711199 27590 net.cpp:367] relu8_2 -> conv8_2 (in-place)
I0804 19:42:10.711213 27590 net.cpp:122] Setting up relu8_2
I0804 19:42:10.711241 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.711252 27590 net.cpp:137] Memory required for data: 126242816
I0804 19:42:10.711262 27590 layer_factory.hpp:77] Creating layer conv8_3
I0804 19:42:10.711277 27590 net.cpp:84] Creating Layer conv8_3
I0804 19:42:10.711288 27590 net.cpp:406] conv8_3 <- conv8_2
I0804 19:42:10.711300 27590 net.cpp:380] conv8_3 -> conv8_3
I0804 19:42:10.712890 27590 net.cpp:122] Setting up conv8_3
I0804 19:42:10.712920 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.712931 27590 net.cpp:137] Memory required for data: 129454080
I0804 19:42:10.712954 27590 layer_factory.hpp:77] Creating layer relu8_3
I0804 19:42:10.712968 27590 net.cpp:84] Creating Layer relu8_3
I0804 19:42:10.712980 27590 net.cpp:406] relu8_3 <- conv8_3
I0804 19:42:10.712992 27590 net.cpp:367] relu8_3 -> conv8_3 (in-place)
I0804 19:42:10.713016 27590 net.cpp:122] Setting up relu8_3
I0804 19:42:10.713032 27590 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:42:10.713043 27590 net.cpp:137] Memory required for data: 132665344
I0804 19:42:10.713053 27590 layer_factory.hpp:77] Creating layer conv8_313
I0804 19:42:10.713069 27590 net.cpp:84] Creating Layer conv8_313
I0804 19:42:10.713079 27590 net.cpp:406] conv8_313 <- conv8_3
I0804 19:42:10.713093 27590 net.cpp:380] conv8_313 -> conv8_313
I0804 19:42:10.714274 27590 net.cpp:122] Setting up conv8_313
I0804 19:42:10.714298 27590 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 19:42:10.714308 27590 net.cpp:137] Memory required for data: 136591616
I0804 19:42:10.714323 27590 layer_factory.hpp:77] Creating layer conv8_313_rh
I0804 19:42:10.714339 27590 net.cpp:84] Creating Layer conv8_313_rh
I0804 19:42:10.714350 27590 net.cpp:406] conv8_313_rh <- conv8_313
I0804 19:42:10.714365 27590 net.cpp:380] conv8_313_rh -> conv8_313_rh
I0804 19:42:10.714470 27590 net.cpp:122] Setting up conv8_313_rh
I0804 19:42:10.714484 27590 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 19:42:10.714495 27590 net.cpp:137] Memory required for data: 140517888
I0804 19:42:10.714506 27590 layer_factory.hpp:77] Creating layer class8_313_rh
I0804 19:42:10.714520 27590 net.cpp:84] Creating Layer class8_313_rh
I0804 19:42:10.714531 27590 net.cpp:406] class8_313_rh <- conv8_313_rh
I0804 19:42:10.714545 27590 net.cpp:380] class8_313_rh -> class8_313_rh
I0804 19:42:10.714614 27590 net.cpp:122] Setting up class8_313_rh
I0804 19:42:10.714630 27590 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 19:42:10.714640 27590 net.cpp:137] Memory required for data: 144444160
I0804 19:42:10.714651 27590 layer_factory.hpp:77] Creating layer class8_ab
I0804 19:42:10.714665 27590 net.cpp:84] Creating Layer class8_ab
I0804 19:42:10.714675 27590 net.cpp:406] class8_ab <- class8_313_rh
I0804 19:42:10.714689 27590 net.cpp:380] class8_ab -> class8_ab
I0804 19:42:10.714916 27590 net.cpp:122] Setting up class8_ab
I0804 19:42:10.714931 27590 net.cpp:129] Top shape: 1 2 56 56 (6272)
I0804 19:42:10.714942 27590 net.cpp:137] Memory required for data: 144469248
I0804 19:42:10.714954 27590 layer_factory.hpp:77] Creating layer Silence
I0804 19:42:10.714967 27590 net.cpp:84] Creating Layer Silence
I0804 19:42:10.714977 27590 net.cpp:406] Silence <- class8_ab
I0804 19:42:10.714988 27590 net.cpp:122] Setting up Silence
I0804 19:42:10.714998 27590 net.cpp:137] Memory required for data: 144469248
I0804 19:42:10.715009 27590 net.cpp:200] Silence does not need backward computation.
I0804 19:42:10.715019 27590 net.cpp:200] class8_ab does not need backward computation.
I0804 19:42:10.715030 27590 net.cpp:200] class8_313_rh does not need backward computation.
I0804 19:42:10.715040 27590 net.cpp:200] conv8_313_rh does not need backward computation.
I0804 19:42:10.715051 27590 net.cpp:200] conv8_313 does not need backward computation.
I0804 19:42:10.715062 27590 net.cpp:200] relu8_3 does not need backward computation.
I0804 19:42:10.715072 27590 net.cpp:200] conv8_3 does not need backward computation.
I0804 19:42:10.715083 27590 net.cpp:200] relu8_2 does not need backward computation.
I0804 19:42:10.715109 27590 net.cpp:200] conv8_2 does not need backward computation.
I0804 19:42:10.715121 27590 net.cpp:200] relu8_1 does not need backward computation.
I0804 19:42:10.715131 27590 net.cpp:200] conv8_1 does not need backward computation.
I0804 19:42:10.715142 27590 net.cpp:200] conv7_3norm does not need backward computation.
I0804 19:42:10.715152 27590 net.cpp:200] relu7_3 does not need backward computation.
I0804 19:42:10.715162 27590 net.cpp:200] conv7_3 does not need backward computation.
I0804 19:42:10.715173 27590 net.cpp:200] relu7_2 does not need backward computation.
I0804 19:42:10.715183 27590 net.cpp:200] conv7_2 does not need backward computation.
I0804 19:42:10.715193 27590 net.cpp:200] relu7_1 does not need backward computation.
I0804 19:42:10.715204 27590 net.cpp:200] conv7_1 does not need backward computation.
I0804 19:42:10.715214 27590 net.cpp:200] conv6_3norm does not need backward computation.
I0804 19:42:10.715225 27590 net.cpp:200] relu6_3 does not need backward computation.
I0804 19:42:10.715235 27590 net.cpp:200] conv6_3 does not need backward computation.
I0804 19:42:10.715246 27590 net.cpp:200] relu6_2 does not need backward computation.
I0804 19:42:10.715256 27590 net.cpp:200] conv6_2 does not need backward computation.
I0804 19:42:10.715266 27590 net.cpp:200] relu6_1 does not need backward computation.
I0804 19:42:10.715276 27590 net.cpp:200] conv6_1 does not need backward computation.
I0804 19:42:10.715287 27590 net.cpp:200] conv5_3norm does not need backward computation.
I0804 19:42:10.715297 27590 net.cpp:200] relu5_3 does not need backward computation.
I0804 19:42:10.715307 27590 net.cpp:200] conv5_3 does not need backward computation.
I0804 19:42:10.715318 27590 net.cpp:200] relu5_2 does not need backward computation.
I0804 19:42:10.715328 27590 net.cpp:200] conv5_2 does not need backward computation.
I0804 19:42:10.715338 27590 net.cpp:200] relu5_1 does not need backward computation.
I0804 19:42:10.715349 27590 net.cpp:200] conv5_1 does not need backward computation.
I0804 19:42:10.715359 27590 net.cpp:200] conv4_3norm does not need backward computation.
I0804 19:42:10.715370 27590 net.cpp:200] relu4_3 does not need backward computation.
I0804 19:42:10.715380 27590 net.cpp:200] conv4_3 does not need backward computation.
I0804 19:42:10.715390 27590 net.cpp:200] relu4_2 does not need backward computation.
I0804 19:42:10.715401 27590 net.cpp:200] conv4_2 does not need backward computation.
I0804 19:42:10.715411 27590 net.cpp:200] relu4_1 does not need backward computation.
I0804 19:42:10.715421 27590 net.cpp:200] conv4_1 does not need backward computation.
I0804 19:42:10.715432 27590 net.cpp:200] conv3_3norm does not need backward computation.
I0804 19:42:10.715442 27590 net.cpp:200] relu3_3 does not need backward computation.
I0804 19:42:10.715452 27590 net.cpp:200] conv3_3 does not need backward computation.
I0804 19:42:10.715463 27590 net.cpp:200] relu3_2 does not need backward computation.
I0804 19:42:10.715476 27590 net.cpp:200] conv3_2 does not need backward computation.
I0804 19:42:10.715487 27590 net.cpp:200] relu3_1 does not need backward computation.
I0804 19:42:10.715497 27590 net.cpp:200] conv3_1 does not need backward computation.
I0804 19:42:10.715507 27590 net.cpp:200] conv2_2norm does not need backward computation.
I0804 19:42:10.715517 27590 net.cpp:200] relu2_2 does not need backward computation.
I0804 19:42:10.715528 27590 net.cpp:200] conv2_2 does not need backward computation.
I0804 19:42:10.715538 27590 net.cpp:200] relu2_1 does not need backward computation.
I0804 19:42:10.715548 27590 net.cpp:200] conv2_1 does not need backward computation.
I0804 19:42:10.715559 27590 net.cpp:200] conv1_2norm does not need backward computation.
I0804 19:42:10.715569 27590 net.cpp:200] relu1_2 does not need backward computation.
I0804 19:42:10.715579 27590 net.cpp:200] conv1_2 does not need backward computation.
I0804 19:42:10.715590 27590 net.cpp:200] relu1_1 does not need backward computation.
I0804 19:42:10.715600 27590 net.cpp:200] bw_conv1_1 does not need backward computation.
I0804 19:42:10.715621 27590 net.cpp:200] data_l does not need backward computation.
I0804 19:42:10.715656 27590 net.cpp:255] Network initialization done.
I0804 19:42:10.800568 27590 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_release_v2.caffemodel
I0804 19:42:10.800622 27590 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 19:42:10.800638 27590 net.cpp:744] Ignoring source layer img
I0804 19:42:10.800653 27590 net.cpp:744] Ignoring source layer img_lab
I0804 19:42:10.800664 27590 net.cpp:744] Ignoring source layer img_slice
I0804 19:42:10.800674 27590 net.cpp:744] Ignoring source layer data_l_meansub
I0804 19:42:10.800685 27590 net.cpp:744] Ignoring source layer data_ab_ss
I0804 19:42:10.800695 27590 net.cpp:744] Ignoring source layer data_ab_ss_data_ab_ss_0_split
I0804 19:42:10.800705 27590 net.cpp:744] Ignoring source layer ab_enc
I0804 19:42:10.800715 27590 net.cpp:744] Ignoring source layer gt_ab_313_ab_enc_0_split
I0804 19:42:10.800725 27590 net.cpp:744] Ignoring source layer ab_pb
I0804 19:42:10.800735 27590 net.cpp:744] Ignoring source layer ab_pb
I0804 19:42:10.800745 27590 net.cpp:744] Ignoring source layer pb_nongray
I0804 19:42:10.821725 27590 net.cpp:744] Ignoring source layer PriorBoost8
I0804 19:42:10.821748 27590 net.cpp:744] Ignoring source layer SoftmaxLoss8
/home/thijser/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.
  warn("The default mode, 'constant', will be changed to 'reflect' in "
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
killing all other torch instances
https://www.google.co.in/search?q=wardrobe+closet+press&safe=off&source=lnms&tbm=isch&num=25
there are total 100 images
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
could not load : http://kingshat.com/a/2017/06/CI-Closet-Maid_white-brown-boys_s4x3.jpg.rend_.hgtvcom.1280.960.jpeg
HTTP Error 403: Forbidden
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
th imageSelector.lua -avaible_images t/Pictures/wardrobe+closet+press/ActiOn_45.jpg,t/Pictures/wardrobe+closet+press/ActiOn_23.jpg,t/Pictures/wardrobe+closet+press/ActiOn_35.jpg,t/Pictures/wardrobe+closet+press/ActiOn_67.jpg,t/Pictures/wardrobe+closet+press/ActiOn_61.jpg,t/Pictures/wardrobe+closet+press/ActiOn_91.jpg,t/Pictures/wardrobe+closet+press/ActiOn_7.jpg,t/Pictures/wardrobe+closet+press/ActiOn_59.jpg,t/Pictures/wardrobe+closet+press/ActiOn_40.jpg,t/Pictures/wardrobe+closet+press/ActiOn_98.jpg,t/Pictures/wardrobe+closet+press/ActiOn_11.jpg,t/Pictures/wardrobe+closet+press/ActiOn_90.jpg,t/Pictures/wardrobe+closet+press/ActiOn_74.jpg,t/Pictures/wardrobe+closet+press/ActiOn_44.jpg,t/Pictures/wardrobe+closet+press/ActiOn_6.jpg,t/Pictures/wardrobe+closet+press/ActiOn_9.jpg,t/Pictures/wardrobe+closet+press/ActiOn_88.jpg,t/Pictures/wardrobe+closet+press/ActiOn_94.jpg,t/Pictures/wardrobe+closet+press/ActiOn_57.jpg,t/Pictures/wardrobe+closet+press/ActiOn_62.jpg,t/Pictures/wardrobe+closet+press/ActiOn_20.jpg,t/Pictures/wardrobe+closet+press/ActiOn_30.jpg,t/Pictures/wardrobe+closet+press/ActiOn_96.jpg,t/Pictures/wardrobe+closet+press/ActiOn_95.jpg,t/Pictures/wardrobe+closet+press/ActiOn_58.jpg,t/Pictures/wardrobe+closet+press/ActiOn_41.jpg,t/Pictures/wardrobe+closet+press/ActiOn_4.jpg,t/Pictures/wardrobe+closet+press/ActiOn_28.jpg,t/Pictures/wardrobe+closet+press/ActiOn_83.jpg,t/Pictures/wardrobe+closet+press/ActiOn_49.jpg,t/Pictures/wardrobe+closet+press/ActiOn_52.jpg,t/Pictures/wardrobe+closet+press/ActiOn_78.jpg,t/Pictures/wardrobe+closet+press/ActiOn_37.jpg,t/Pictures/wardrobe+closet+press/ActiOn_55.jpg,t/Pictures/wardrobe+closet+press/ActiOn_66.jpg,t/Pictures/wardrobe+closet+press/ActiOn_32.jpg,t/Pictures/wardrobe+closet+press/ActiOn_84.jpg,t/Pictures/wardrobe+closet+press/ActiOn_5.jpg,t/Pictures/wardrobe+closet+press/ActiOn_13.jpg,t/Pictures/wardrobe+closet+press/ActiOn_85.jpg,t/Pictures/wardrobe+closet+press/ActiOn_81.jpg,t/Pictures/wardrobe+closet+press/ActiOn_82.jpg,t/Pictures/wardrobe+closet+press/ActiOn_72.jpg,t/Pictures/wardrobe+closet+press/ActiOn_18.jpg,t/Pictures/wardrobe+closet+press/ActiOn_76.jpg,t/Pictures/wardrobe+closet+press/ActiOn_22.jpg,t/Pictures/wardrobe+closet+press/ActiOn_46.jpg,t/Pictures/wardrobe+closet+press/ActiOn_77.jpg,t/Pictures/wardrobe+closet+press/ActiOn_75.jpg,t/Pictures/wardrobe+closet+press/ActiOn_29.jpg,t/Pictures/wardrobe+closet+press/ActiOn_65.jpg,t/Pictures/wardrobe+closet+press/ActiOn_63.jpg,t/Pictures/wardrobe+closet+press/ActiOn_24.jpg,t/Pictures/wardrobe+closet+press/ActiOn_69.jpg,t/Pictures/wardrobe+closet+press/ActiOn_68.jpg,t/Pictures/wardrobe+closet+press/ActiOn_15.jpg,t/Pictures/wardrobe+closet+press/ActiOn_51.jpg,t/Pictures/wardrobe+closet+press/ActiOn_80.jpg,t/Pictures/wardrobe+closet+press/ActiOn_21.jpg,t/Pictures/wardrobe+closet+press/ActiOn_86.jpg,t/Pictures/wardrobe+closet+press/ActiOn_56.jpg,t/Pictures/wardrobe+closet+press/ActiOn_1.jpg,t/Pictures/wardrobe+closet+press/ActiOn_34.jpg,t/Pictures/wardrobe+closet+press/ActiOn_99.jpg,t/Pictures/wardrobe+closet+press/ActiOn_43.jpg,t/Pictures/wardrobe+closet+press/ActiOn_79.jpg,t/Pictures/wardrobe+closet+press/ActiOn_92.jpg,t/Pictures/wardrobe+closet+press/ActiOn_12.jpg,t/Pictures/wardrobe+closet+press/ActiOn_16.jpg,t/Pictures/wardrobe+closet+press/ActiOn_38.jpg,t/Pictures/wardrobe+closet+press/ActiOn_53.jpg,t/Pictures/wardrobe+closet+press/ActiOn_64.jpg,t/Pictures/wardrobe+closet+press/ActiOn_93.jpg,t/Pictures/wardrobe+closet+press/ActiOn_26.jpg,t/Pictures/wardrobe+closet+press/ActiOn_25.jpg,t/Pictures/wardrobe+closet+press/ActiOn_87.jpg,t/Pictures/wardrobe+closet+press/ActiOn_42.jpg,t/Pictures/wardrobe+closet+press/ActiOn_50.jpg,t/Pictures/wardrobe+closet+press/ActiOn_19.jpg,t/Pictures/wardrobe+closet+press/ActiOn_70.jpg,t/Pictures/wardrobe+closet+press/ActiOn_89.jpg,t/Pictures/wardrobe+closet+press/ActiOn_54.jpg,t/Pictures/wardrobe+closet+press/ActiOn_10.jpg
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
coleval=1429833708.8205	
neuroval=463787556	
coleval=1089679234.9649	
neuroval=446748252	
coleval=2037034018.6395	
neuroval=369405716	
coleval=1274504995.8147	
neuroval=389932360	
coleval=2244976289.0625	
neuroval=400454060	
coleval=1350749531.25	
neuroval=402968700	
coleval=2566550568.2222	
neuroval=492190100	
coleval=1140195848.084	
neuroval=460216376	
coleval=1623533499.3475	
neuroval=473642672	
coleval=2233031748.6185	
neuroval=378660868	
coleval=836947904.34185	
neuroval=440290352	
coleval=1149031498.8451	
neuroval=494235500	
coleval=1430651443.2137	
neuroval=447409232	
coleval=1839942943.3439	
neuroval=408608424	
coleval=1782170047.7431	
neuroval=543029120	
coleval=831350361.82363	
neuroval=397894524	
coleval=927429990.87323	
neuroval=522298436	
coleval=872036110.69715	
neuroval=430885320	
coleval=1818855972.2243	
neuroval=383168704	
coleval=1482355834.2097	
neuroval=587844440	
coleval=2276540082.7076	
neuroval=432402416	
coleval=1244493781.9276	
neuroval=373073792	
coleval=1232837330.7292	
neuroval=381521504	
coleval=797970412.70029	
neuroval=334087068	
coleval=2267002163.5682	
neuroval=381645108	
coleval=1048452314.1542	
neuroval=421955120	
coleval=711673646.17316	
neuroval=577185640	
coleval=2017396338.5654	
neuroval=296046024	
coleval=1630035341.9938	
neuroval=608938504	
coleval=886978583.02376	
neuroval=457759608	
coleval=2029393680.1716	
neuroval=495564840	
coleval=1872372219.1825	
neuroval=392174240	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
[1;35mimage.load[0m

loads an image into a torch.Tensor

[0;34m> [0musage:
[0;36mimage.load(
    string                              -- path to file
    [number]                            -- force destination depth: 1 | 3
    [string]                            -- type: byte | float | double
)
[0m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++	
coleval=1446036874.5836	
neuroval=474068320	
coleval=1482131472.4215	
neuroval=541145492	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_23.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_66.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_49.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_24.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_76.jpg"
    }
  2 : 1132057480.7003
}
coleval=1999660612.27	
neuroval=387697488	
coleval=543217356.51042	
neuroval=499272424	
coleval=925162160.29576	
neuroval=455498072	
coleval=1745512170.1527	
neuroval=337624784	
coleval=926192956.27392	
neuroval=433642340	
coleval=797970412.70029	
neuroval=334087068	
coleval=1059673421.3364	
neuroval=325177672	
coleval=1625717392.9488	
neuroval=351357992	
coleval=1760296188.9139	
neuroval=421511968	
coleval=1774613237.8844	
neuroval=424614272	
coleval=1661297658.9542	
neuroval=378353368	
coleval=831350361.82363	
neuroval=397894524	
coleval=412807419.278	
neuroval=395933764	
coleval=756261098.84314	
neuroval=428010068	
coleval=415191884.53292	
neuroval=444616916	
coleval=1468599547.1466	
neuroval=448874024	
coleval=1203987602.8969	
neuroval=466210440	
coleval=836947904.34185	
neuroval=440290352	
coleval=1369393597.433	
neuroval=433540092	
coleval=1467246784.4509	
neuroval=470243308	
coleval=1056142029.9485	
neuroval=468259304	
coleval=1116957162.3408	
neuroval=487984064	
coleval=847861223.45837	
neuroval=482385280	
coleval=711673646.17316	
neuroval=577185640	
coleval=1621937316.2733	
neuroval=542030112	
coleval=1494515326.9029	
neuroval=454674256	
coleval=1877636250	
neuroval=429579448	
coleval=1261371366.7029	
neuroval=416164240	
coleval=987467350.81674	
neuroval=348941352	
coleval=872036110.69715	
neuroval=430885320	
coleval=1157175098.386	
neuroval=481063352	
coleval=624905364.28468	
neuroval=494552512	
coleval=601341253.92292	
neuroval=446413896	
coleval=652964508.61793	
neuroval=456089384	
coleval=868454733.44276	
neuroval=451654376	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_38.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_90.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_9.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_67.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_55.jpg"
    }
  2 : 808741183.278
}
coleval=506065683.77156	
neuroval=412436556	
coleval=2291403716.5772	
neuroval=384830928	
coleval=1223656012.8348	
neuroval=379361940	
coleval=1870655139.2801	
neuroval=481567208	
coleval=805495207.32884	
neuroval=343915736	
coleval=412807419.278	
neuroval=395933764	
coleval=452462319.02672	
neuroval=394856196	
coleval=395319961.43549	
neuroval=438010724	
coleval=392267492.41334	
neuroval=469057604	
coleval=470601289.69322	
neuroval=439903508	
coleval=358444470.43267	
neuroval=428948748	
coleval=415191884.53292	
neuroval=444616916	
coleval=497928551.88467	
neuroval=453946524	
coleval=843170987.12315	
neuroval=459735224	
coleval=1309247256.0095	
neuroval=442929416	
coleval=1147171759.6313	
neuroval=457842440	
coleval=1674330829.3167	
neuroval=430758728	
coleval=543217356.51042	
neuroval=499272424	
coleval=619400289.76569	
neuroval=470304152	
coleval=1435355688.624	
neuroval=440317240	
coleval=1827299561.6948	
neuroval=416198576	
coleval=1479479284.5517	
neuroval=375691300	
coleval=1228528734.189	
neuroval=335100604	
coleval=601341253.92292	
neuroval=446413896	
coleval=613598904.0077	
neuroval=417964136	
coleval=517354808.73839	
neuroval=497422232	
coleval=994369203.45207	
neuroval=488561632	
coleval=1947796880.5244	
neuroval=473448240	
coleval=2059452612.7556	
neuroval=504839184	
coleval=652964508.61793	
neuroval=456089384	
coleval=957972476.86974	
neuroval=402741216	
coleval=1072853887.7087	
neuroval=516243328	
coleval=1349459340.3364	
neuroval=483627296	
coleval=926850687.00883	
neuroval=467891840	
coleval=167707772.68341	
neuroval=359649668	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_32.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_77.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_51.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_84.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_76.jpg"
    }
  2 : 527357440.68341
}
coleval=1473012891.1214	
neuroval=550942872	
coleval=1194299990.4171	
neuroval=500817064	
coleval=588601859.05612	
neuroval=448925564	
coleval=1349021064.2578	
neuroval=436876200	
coleval=1077386977.0919	
neuroval=449241004	
coleval=167707772.68341	
neuroval=359649668	
coleval=699187846.11629	
neuroval=357610252	
coleval=726260631.04175	
neuroval=361319956	
coleval=493378308.10664	
neuroval=370017980	
coleval=416617561.13876	
neuroval=400976984	
coleval=1329060791.0885	
neuroval=524110416	
coleval=358444470.43267	
neuroval=428948748	
coleval=465553775.91263	
neuroval=448656544	
coleval=636225000	
neuroval=474631952	
coleval=634124797.34667	
neuroval=491797296	
coleval=1107120700.667	
neuroval=466047712	
coleval=1348814862.7664	
neuroval=481852536	
coleval=412807419.278	
neuroval=395933764	
coleval=613179238.97879	
neuroval=359103852	
coleval=279396451.989	
neuroval=386448908	
coleval=349512612.20504	
neuroval=407940980	
coleval=466779580.87532	
neuroval=422377884	
coleval=498696167.78938	
neuroval=445098316	
coleval=395319961.43549	
neuroval=438010724	
coleval=837530975.0079	
neuroval=441127708	
coleval=940994272.73756	
neuroval=410038620	
coleval=960731238.47966	
neuroval=391603604	
coleval=914499024.69899	
neuroval=457620136	
coleval=1386742950.6586	
neuroval=442125080	
coleval=452462319.02672	
neuroval=394856196	
coleval=1346590074.9791	
neuroval=368803028	
coleval=770278420.15811	
neuroval=417683948	
coleval=994559526.04653	
neuroval=364053216	
coleval=1285714723.3937	
neuroval=321791860	
coleval=893674216.97061	
neuroval=409449224	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_32.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_77.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_51.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_84.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_76.jpg"
    }
  2 : 527357440.68341
}
coleval=2248498917.0801	
neuroval=387443988	
coleval=1437883349.0954	
neuroval=314847488	
coleval=438268897.7828	
neuroval=404729244	
coleval=1562797278.7134	
neuroval=441784464	
coleval=1899300263.6719	
neuroval=297668408	
coleval=167707772.68341	
neuroval=359649668	
coleval=155234526.22561	
neuroval=419057804	
coleval=824628527.05194	
neuroval=364977948	
coleval=790608734.23755	
neuroval=415376348	
coleval=1064841021.1174	
neuroval=481834484	
coleval=2421348612.9935	
neuroval=402492812	
coleval=279396451.989	
neuroval=386448908	
coleval=804951416.67893	
neuroval=411865180	
coleval=1256352720.9412	
neuroval=415041704	
coleval=1315999839.5647	
neuroval=365367444	
coleval=1353996015.625	
neuroval=328494304	
coleval=1014496875	
neuroval=305517880	
coleval=349512612.20504	
neuroval=407940980	
coleval=624632547.20761	
neuroval=398856636	
coleval=604577288.29539	
neuroval=426366500	
coleval=560601327.8652	
neuroval=403718532	
coleval=735722426.59601	
neuroval=424163900	
coleval=560601327.8652	
neuroval=403718532	
coleval=358444470.43267	
neuroval=428948748	
coleval=1044172500	
neuroval=382326176	
coleval=1053106875	
neuroval=538514940	
coleval=394784617.38016	
neuroval=402857044	
coleval=474879341.15248	
neuroval=451712408	
coleval=1553996041.9157	
neuroval=461946096	
coleval=412807419.278	
neuroval=395933764	
coleval=369131815.70871	
neuroval=387967148	
coleval=437957055.66406	
neuroval=392176932	
coleval=708685139.8577	
neuroval=380607020	
coleval=1994684956.0547	
neuroval=376867636	
coleval=1839222568.3594	
neuroval=349745492	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_32.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_77.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_51.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_84.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_76.jpg"
    }
  2 : 527357440.68341
}
coleval=1386945625	
neuroval=499627852	
coleval=606248285.15625	
neuroval=512885440	
coleval=1578423158.4821	
neuroval=432973680	
coleval=1393024175.5022	
neuroval=461513724	
coleval=637677236.4891	
neuroval=564689724	
coleval=167707772.68341	
neuroval=359649668	
coleval=584809507.02085	
neuroval=357409012	
coleval=164807157.88779	
neuroval=356306280	
coleval=160883008.37054	
neuroval=497953808	
coleval=1074955474.6094	
neuroval=486764628	
coleval=1131031982.4219	
neuroval=454738300	
coleval=155234526.22561	
neuroval=419057804	
coleval=491191136.71875	
neuroval=427966076	
coleval=2156275639.8079	
neuroval=443798428	
coleval=383166925.78125	
neuroval=510778596	
coleval=378168128.90625	
neuroval=483820884	
coleval=489899132.8125	
neuroval=481926436	
coleval=279396451.989	
neuroval=386448908	
coleval=276487764.70158	
neuroval=384823756	
coleval=1137754366.9616	
neuroval=364477524	
coleval=1198058135.0978	
neuroval=460318736	
coleval=1511161875	
neuroval=468815720	
coleval=1214454375	
neuroval=455531464	
coleval=369131815.70871	
neuroval=387967148	
coleval=787299221.19141	
neuroval=368185148	
coleval=713540822.75191	
neuroval=348890388	
coleval=1490902788.0859	
neuroval=368813564	
coleval=1376627475.5859	
neuroval=431336772	
coleval=1287039607.2824	
neuroval=416938804	
coleval=349512612.20504	
neuroval=407940980	
coleval=938185604.07366	
neuroval=428783804	
coleval=1138579971.0209	
neuroval=405011804	
coleval=1087209271.5219	
neuroval=459667312	
coleval=648126466.26567	
neuroval=449874652	
coleval=1215217541.0746	
neuroval=464835252	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_67.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_77.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_51.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_84.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_76.jpg"
    }
  2 : 521113437.88779
}
coleval=2130021370.2619	
neuroval=468083536	
coleval=1337652960.9375	
neuroval=456243648	
coleval=279096785.9241	
neuroval=332904548	
coleval=1207005214.9833	
neuroval=396317972	
coleval=1374349339.7574	
neuroval=387184220	
coleval=164807157.88779	
neuroval=356306280	
coleval=851832648.09657	
neuroval=378864064	
coleval=1354198928.08	
neuroval=410945400	
coleval=1608523546.3433	
neuroval=492967256	
coleval=909022180.66406	
neuroval=351139064	
coleval=1198879664.3157	
neuroval=375895848	
coleval=167707772.68341	
neuroval=359649668	
coleval=805495207.32884	
neuroval=343915736	
coleval=1822464316.4063	
neuroval=346824080	
coleval=2366677628.9063	
neuroval=325855192	
coleval=2232514769.5312	
neuroval=340918704	
coleval=1269039187.5	
neuroval=366668288	
coleval=155234526.22561	
neuroval=419057804	
coleval=713415515.97171	
neuroval=332892080	
coleval=839920453.125	
neuroval=361216584	
coleval=946212433.59375	
neuroval=349739760	
coleval=927658577.35357	
neuroval=345420416	
coleval=786268061.06735	
neuroval=295740488	
coleval=160883008.37054	
neuroval=497953808	
coleval=1094260202.35	
neuroval=528038872	
coleval=1091764153.4288	
neuroval=563573544	
coleval=1003256998.6669	
neuroval=431191176	
coleval=1015150107.8404	
neuroval=423203888	
coleval=1000651755.7199	
neuroval=454702360	
coleval=276487764.70158	
neuroval=384823756	
coleval=368136057.80984	
neuroval=439821984	
coleval=1255715469.0822	
neuroval=403478832	
coleval=1031377643.3288	
neuroval=456937688	
coleval=1005134372.542	
neuroval=415563996	
coleval=2051514650.8623	
neuroval=389814412	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_67.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_77.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_51.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_84.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_76.jpg"
    }
  2 : 521113437.88779
}
coleval=936382849.23982	
neuroval=431054320	
coleval=1293680206.2049	
neuroval=442735892	
coleval=2247962726.9013	
neuroval=335479204	
coleval=395752557.3101	
neuroval=449766160	
coleval=1117584087.591	
neuroval=570627736	
coleval=164807157.88779	
neuroval=356306280	
coleval=202889085.61143	
neuroval=439118800	
coleval=202111197.6759	
neuroval=433847824	
coleval=177314328.28391	
neuroval=410248744	
coleval=322816103.27582	
neuroval=451562800	
coleval=923186795.81571	
neuroval=417175784	
coleval=167707772.68341	
neuroval=359649668	
coleval=1594530123.4283	
neuroval=358238668	
coleval=1856111153.1162	
neuroval=396474604	
coleval=1779141022.2292	
neuroval=469768856	
coleval=1587167018.3305	
neuroval=469146200	
coleval=1309506161.0843	
neuroval=472227488	
coleval=155234526.22561	
neuroval=419057804	
coleval=735789315.59726	
neuroval=383854952	
coleval=651577077.39113	
neuroval=423428320	
coleval=2256670370.2889	
neuroval=357352056	
coleval=2237606138.3846	
neuroval=365298844	
coleval=2664762763.0197	
neuroval=327257068	
coleval=279096785.9241	
neuroval=332904548	
coleval=480285490.13655	
neuroval=361872820	
coleval=466901197.63462	
neuroval=436070976	
coleval=519813423.54911	
neuroval=452625328	
coleval=580580655.69196	
neuroval=423139760	
coleval=517998651.23713	
neuroval=472527448	
coleval=160883008.37054	
neuroval=497953808	
coleval=1022770591.2388	
neuroval=523878832	
coleval=1313275258.6894	
neuroval=525549120	
coleval=1565871479.1993	
neuroval=498004784	
coleval=1568035401.6996	
neuroval=487815216	
coleval=1003896417.5481	
neuroval=515096392	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_67.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_77.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_51.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_84.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_76.jpg"
    }
  2 : 521113437.88779
}
coleval=706677349.44661	
neuroval=403978920	
coleval=1678203714.8438	
neuroval=395665680	
coleval=1547064179.9064	
neuroval=498184908	
coleval=1272039375	
neuroval=500256724	
coleval=606302759.72378	
neuroval=403602856	
coleval=164807157.88779	
neuroval=356306280	
coleval=144304666.10313	
neuroval=341921688	
coleval=121793928.57143	
neuroval=312321068	
coleval=1537479602.0508	
neuroval=375469548	
coleval=1556320722.6562	
neuroval=361583432	
coleval=158593937.98828	
neuroval=375072592	
coleval=167707772.68341	
neuroval=359649668	
coleval=1968498825.8464	
neuroval=334798860	
coleval=1945373783.8542	
neuroval=311199780	
coleval=2409294475.2604	
neuroval=334176204	
coleval=2334178576.8229	
neuroval=370160096	
coleval=1717632480.4688	
neuroval=403919176	
coleval=155234526.22561	
neuroval=419057804	
coleval=1074612528.7056	
neuroval=402611200	
coleval=1050330092.0427	
neuroval=403515104	
coleval=1379244676.3933	
neuroval=404198916	
coleval=1471948677.697	
neuroval=535630332	
coleval=1865758542.4097	
neuroval=482352556	
coleval=177314328.28391	
neuroval=410248744	
coleval=175707292.96875	
neuroval=551896272	
coleval=176830783.34216	
neuroval=535442280	
coleval=1236344032.8019	
neuroval=461854760	
coleval=1259109755.7699	
neuroval=422222992	
coleval=1278571875	
neuroval=490543760	
coleval=279096785.9241	
neuroval=332904548	
coleval=953488729.58886	
neuroval=299590804	
coleval=914128561.42012	
neuroval=340904860	
coleval=605813712.43271	
neuroval=360344892	
coleval=579991469.61278	
neuroval=415737504	
coleval=944537939.36878	
neuroval=433709360	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_67.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_77.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_23.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_99.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_76.jpg"
    }
  2 : 434114996.57143
}
coleval=1029949551.1194	
neuroval=354133464	
coleval=2134671560.0586	
neuroval=358605932	
coleval=1191203419.9474	
neuroval=511475088	
coleval=1209538994.4584	
neuroval=487644676	
coleval=2521945861.8164	
neuroval=341113316	
coleval=121793928.57143	
neuroval=312321068	
coleval=116321400.66964	
neuroval=311240484	
coleval=532251269.53125	
neuroval=319664692	
coleval=116321400.66964	
neuroval=311240484	
coleval=2354739128.4958	
neuroval=351729568	
coleval=2770650232.929	
neuroval=355756768	
coleval=144304666.10313	
neuroval=341921688	
coleval=544725916.13615	
neuroval=355764360	
coleval=544335880.60294	
neuroval=419771336	
coleval=743716434.35816	
neuroval=351507252	
coleval=1505860800.4325	
neuroval=347703348	
coleval=1480027318.5221	
neuroval=393173492	
coleval=164807157.88779	
neuroval=356306280	
coleval=1921942605.7288	
neuroval=358290284	
coleval=87900188.811714	
neuroval=519309232	
coleval=742414259.90531	
neuroval=381902392	
coleval=756363430.87744	
neuroval=356427692	
coleval=971666882.07435	
neuroval=423817724	
coleval=167707772.68341	
neuroval=359649668	
coleval=699783909.13924	
neuroval=355392560	
coleval=1747448803.2198	
neuroval=387891212	
coleval=1640991152.5778	
neuroval=418849588	
coleval=1819068856.8729	
neuroval=404464996	
coleval=1631442946.7918	
neuroval=387349292	
coleval=158593937.98828	
neuroval=375072592	
coleval=60104003.90625	
neuroval=388958708	
coleval=470488175.20661	
neuroval=348364148	
coleval=1081934340.8687	
neuroval=417447772	
coleval=786483517.36886	
neuroval=381404692	
coleval=1771210949.707	
neuroval=391584404	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_67.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_77.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_23.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_99.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_37.jpg"
    }
  2 : 427561884.66964
}
coleval=1744835931.5129	
neuroval=520547736	
coleval=2584772418.9234	
neuroval=345254644	
coleval=2167025937.5	
neuroval=303978656	
coleval=1002717684.055	
neuroval=397649584	
coleval=1171082344.9458	
neuroval=330798588	
coleval=116321400.66964	
neuroval=311240484	
coleval=740690367.9548	
neuroval=405798808	
coleval=1162330596.0733	
neuroval=447945392	
coleval=1040734606.0287	
neuroval=510785400	
coleval=1582218681.7802	
neuroval=487620752	
coleval=1395759800.7702	
neuroval=439556512	
coleval=116321400.66964	
neuroval=311240484	
coleval=2354739128.4958	
neuroval=351729568	
coleval=2694006003.2364	
neuroval=469666688	
coleval=2542434841.3358	
neuroval=494441280	
coleval=2540517081.8493	
neuroval=460661952	
coleval=2837751354.5971	
neuroval=462111180	
coleval=121793928.57143	
neuroval=312321068	
coleval=2197554418.9453	
neuroval=314305072	
coleval=2202540739.4822	
neuroval=358593348	
coleval=2271970406.886	
neuroval=330174664	
coleval=2203655549.6061	
neuroval=346007016	
coleval=1828864011.4669	
neuroval=336548372	
coleval=60104003.90625	
neuroval=388958708	
coleval=1064439449.5335	
neuroval=377075092	
coleval=1399884007.2037	
neuroval=327782508	
coleval=2311174984.5773	
neuroval=338011708	
coleval=1338207299.1252	
neuroval=372070784	
coleval=892242177.79839	
neuroval=445713824	
coleval=144304666.10313	
neuroval=341921688	
coleval=90530888.787445	
neuroval=390109568	
coleval=60751486.816406	
neuroval=372488812	
coleval=1503683569.3359	
neuroval=448166312	
coleval=1448106855.4688	
neuroval=467496720	
coleval=1082854379.8828	
neuroval=380903020	
{
  1 : 
    {
      1 : "t/Pictures/wardrobe+closet+press/ActiOn_67.jpg"
      2 : "t/Pictures/wardrobe+closet+press/ActiOn_77.jpg"
      3 : "t/Pictures/wardrobe+closet+press/ActiOn_23.jpg"
      4 : "t/Pictures/wardrobe+closet+press/ActiOn_99.jpg"
      5 : "t/Pictures/wardrobe+closet+press/ActiOn_37.jpg"
    }
  2 : 427561884.66964
}
selected:	
t/Pictures/wardrobe+closet+press/ActiOn_67.jpg	
t/Pictures/wardrobe+closet+press/ActiOn_77.jpg	
t/Pictures/wardrobe+closet+press/ActiOn_23.jpg	
t/Pictures/wardrobe+closet+press/ActiOn_99.jpg	
t/Pictures/wardrobe+closet+press/ActiOn_37.jpg	
t/Pictures/wardrobe+closet+press/ActiOn_67.jpg,t/Pictures/wardrobe+closet+press/ActiOn_77.jpg,t/Pictures/wardrobe+closet+press/ActiOn_23.jpg,t/Pictures/wardrobe+closet+press/ActiOn_99.jpg,t/Pictures/wardrobe+closet+press/ActiOn_37.jpg	
writing selected	
t/Pictures/wardrobe+closet+press/ActiOn_67.jpg	
t/Pictures/wardrobe+closet+press/ActiOn_77.jpg	
t/Pictures/wardrobe+closet+press/ActiOn_23.jpg	
t/Pictures/wardrobe+closet+press/ActiOn_99.jpg	
t/Pictures/wardrobe+closet+press/ActiOn_37.jpg	
done writing selector	
2394586	
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
Setting up style layer  	2	:	relu1_1	
Setting up style layer  	7	:	relu2_1	
Setting up style layer  	12	:	relu3_1	
Setting up style layer  	21	:	relu4_1	
Setting up content layer	23	:	relu4_2	
Setting up style layer  	30	:	relu5_1	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
Running optimization with L-BFGS	
 512
  64
  64
[torch.LongStorage of size 3]

24329636.870956	
<optim.lbfgs> 	creating recyclable direction/step/history buffers	
 512
  64
  64
[torch.LongStorage of size 3]

24329616.349793	
 512
  64
  64
[torch.LongStorage of size 3]

16867948.459244	
 512
  64
  64
[torch.LongStorage of size 3]

12649882.354507	
 512
  64
  64
[torch.LongStorage of size 3]

10583612.145004	
 512
  64
  64
[torch.LongStorage of size 3]

9071110.7966614	
 512
  64
  64
[torch.LongStorage of size 3]

8055831.6458511	
 512
  64
  64
[torch.LongStorage of size 3]

7335775.1050568	
 512
  64
  64
[torch.LongStorage of size 3]

6776296.3864899	
 512
  64
  64
[torch.LongStorage of size 3]

6291385.8922958	
 512
  64
  64
[torch.LongStorage of size 3]

5900163.7306976	
 512
  64
  64
[torch.LongStorage of size 3]

5592721.8009567	
 512
  64
  64
[torch.LongStorage of size 3]

5331348.4115601	
 512
  64
  64
[torch.LongStorage of size 3]

5106976.9062805	
 512
  64
  64
[torch.LongStorage of size 3]

4908531.8525696	
 512
  64
  64
[torch.LongStorage of size 3]

4734690.4674149	
 512
  64
  64
[torch.LongStorage of size 3]

4573785.781517	
 512
  64
  64
[torch.LongStorage of size 3]

4431737.1954346	
 512
  64
  64
[torch.LongStorage of size 3]

4306928.6932373	
 512
  64
  64
[torch.LongStorage of size 3]

4181621.2428284	
 512
  64
  64
[torch.LongStorage of size 3]

4074838.1965256	
 512
  64
  64
[torch.LongStorage of size 3]

3974725.4967308	
 512
  64
  64
[torch.LongStorage of size 3]

3879331.484623	
 512
  64
  64
[torch.LongStorage of size 3]

3791547.2484207	
 512
  64
  64
[torch.LongStorage of size 3]

3712594.4896126	
 512
  64
  64
[torch.LongStorage of size 3]

3637854.3250084	
 512
  64
  64
[torch.LongStorage of size 3]

3566389.9842072	
 512
  64
  64
[torch.LongStorage of size 3]

3502406.6524124	
 512
  64
  64
[torch.LongStorage of size 3]

3442147.4234962	
 512
  64
  64
[torch.LongStorage of size 3]

3382475.682621	
 512
  64
  64
[torch.LongStorage of size 3]

3329676.9939423	
 512
  64
  64
[torch.LongStorage of size 3]

3280571.2077141	
 512
  64
  64
[torch.LongStorage of size 3]

3229784.3200302	
 512
  64
  64
[torch.LongStorage of size 3]

3180628.7830353	
 512
  64
  64
[torch.LongStorage of size 3]

3136278.9118385	
 512
  64
  64
[torch.LongStorage of size 3]

3092431.5683746	
 512
  64
  64
[torch.LongStorage of size 3]

3051413.5270119	
 512
  64
  64
[torch.LongStorage of size 3]

3013253.2815742	
 512
  64
  64
[torch.LongStorage of size 3]

2975626.7157936	
 512
  64
  64
[torch.LongStorage of size 3]

2938274.3972206	
 512
  64
  64
[torch.LongStorage of size 3]

2904482.0411873	
 512
  64
  64
[torch.LongStorage of size 3]

2871287.2506905	
 512
  64
  64
[torch.LongStorage of size 3]

2838688.6479187	
 512
  64
  64
[torch.LongStorage of size 3]

2809157.2455788	
 512
  64
  64
[torch.LongStorage of size 3]

2780130.142231	
 512
  64
  64
[torch.LongStorage of size 3]

2751878.109417	
 512
  64
  64
[torch.LongStorage of size 3]

2726109.3696404	
 512
  64
  64
[torch.LongStorage of size 3]

2700902.6743507	
 512
  64
  64
[torch.LongStorage of size 3]

2675025.820446	
 512
  64
  64
[torch.LongStorage of size 3]

2651234.1840363	
 512
  64
  64
[torch.LongStorage of size 3]

2628028.6124802	
 512
  64
  64
[torch.LongStorage of size 3]

2604319.8660851	
 512
  64
  64
[torch.LongStorage of size 3]

2581568.3330536	
 512
  64
  64
[torch.LongStorage of size 3]

2560189.8852921	
 512
  64
  64
[torch.LongStorage of size 3]

2539135.4398155	
 512
  64
  64
[torch.LongStorage of size 3]

2518540.1469421	
 512
  64
  64
[torch.LongStorage of size 3]

2497786.5532684	
 512
  64
  64
[torch.LongStorage of size 3]

2477109.3505287	
 512
  64
  64
[torch.LongStorage of size 3]

2457349.7690201	
 512
  64
  64
[torch.LongStorage of size 3]

2438802.3426628	
 512
  64
  64
[torch.LongStorage of size 3]

2419722.9841042	
 512
  64
  64
[torch.LongStorage of size 3]

2400596.7051315	
 512
  64
  64
[torch.LongStorage of size 3]

2382191.3681412	
 512
  64
  64
[torch.LongStorage of size 3]

2364225.6978607	
 512
  64
  64
[torch.LongStorage of size 3]

2346922.2528648	
 512
  64
  64
[torch.LongStorage of size 3]

2330307.2112465	
 512
  64
  64
[torch.LongStorage of size 3]

2314750.4269218	
 512
  64
  64
[torch.LongStorage of size 3]

2298902.8081512	
 512
  64
  64
[torch.LongStorage of size 3]

2283774.3803596	
 512
  64
  64
[torch.LongStorage of size 3]

2270591.1352158	
 512
  64
  64
[torch.LongStorage of size 3]

2253968.5967255	
 512
  64
  64
[torch.LongStorage of size 3]

2238921.8179893	
 512
  64
  64
[torch.LongStorage of size 3]

2224470.0045776	
 512
  64
  64
[torch.LongStorage of size 3]

2208525.3454208	
 512
  64
  64
[torch.LongStorage of size 3]

2193598.7300491	
 512
  64
  64
[torch.LongStorage of size 3]

2179420.6265831	
 512
  64
  64
[torch.LongStorage of size 3]

2165492.7116013	
 512
  64
  64
[torch.LongStorage of size 3]

2151692.1500206	
 512
  64
  64
[torch.LongStorage of size 3]

2138057.1635437	
 512
  64
  64
[torch.LongStorage of size 3]

2124482.1033287	
 512
  64
  64
[torch.LongStorage of size 3]

2110971.8398285	
 512
  64
  64
[torch.LongStorage of size 3]

2098082.3874664	
 512
  64
  64
[torch.LongStorage of size 3]

2084979.9486351	
 512
  64
  64
[torch.LongStorage of size 3]

2071860.7225418	
 512
  64
  64
[torch.LongStorage of size 3]

2058786.1464119	
 512
  64
  64
[torch.LongStorage of size 3]

2045907.2994614	
 512
  64
  64
[torch.LongStorage of size 3]

2033189.6050644	
 512
  64
  64
[torch.LongStorage of size 3]

2021050.5435753	
 512
  64
  64
[torch.LongStorage of size 3]

2009099.3557739	
 512
  64
  64
[torch.LongStorage of size 3]

1997442.4679947	
 512
  64
  64
[torch.LongStorage of size 3]

1985141.2971878	
 512
  64
  64
[torch.LongStorage of size 3]

1973313.3850861	
 512
  64
  64
[torch.LongStorage of size 3]

1961392.9807281	
 512
  64
  64
[torch.LongStorage of size 3]

1949515.2154732	
 512
  64
  64
[torch.LongStorage of size 3]

1937728.5451126	
 512
  64
  64
[torch.LongStorage of size 3]

1926434.5161057	
 512
  64
  64
[torch.LongStorage of size 3]

1915358.6044884	
 512
  64
  64
[torch.LongStorage of size 3]

1903954.4083977	
 512
  64
  64
[torch.LongStorage of size 3]

1892798.351841	
 512
  64
  64
[torch.LongStorage of size 3]

1881765.8017731	
 512
  64
  64
[torch.LongStorage of size 3]

1870865.9240532	
 512
  64
  64
[torch.LongStorage of size 3]

1860790.6213379	
 512
  64
  64
[torch.LongStorage of size 3]

1850203.4670448	
 512
  64
  64
[torch.LongStorage of size 3]

1840035.4815674	
 512
  64
  64
[torch.LongStorage of size 3]

1829182.3723984	
 512
  64
  64
[torch.LongStorage of size 3]

1818767.8182793	
 512
  64
  64
[torch.LongStorage of size 3]

1808719.701767	
 512
  64
  64
[torch.LongStorage of size 3]

1798956.4199257	
 512
  64
  64
[torch.LongStorage of size 3]

1789060.9573174	
 512
  64
  64
[torch.LongStorage of size 3]

1780259.6371651	
 512
  64
  64
[torch.LongStorage of size 3]

1770483.5278893	
 512
  64
  64
[torch.LongStorage of size 3]

1760677.8834724	
 512
  64
  64
[torch.LongStorage of size 3]

1751044.8366737	
 512
  64
  64
[torch.LongStorage of size 3]

1741264.3572617	
 512
  64
  64
[torch.LongStorage of size 3]

1731314.9791336	
 512
  64
  64
[torch.LongStorage of size 3]

1721733.560524	
 512
  64
  64
[torch.LongStorage of size 3]

1712018.470726	
 512
  64
  64
[torch.LongStorage of size 3]

1702596.7403412	
 512
  64
  64
[torch.LongStorage of size 3]

1692932.1421814	
 512
  64
  64
[torch.LongStorage of size 3]

1683451.6016388	
 512
  64
  64
[torch.LongStorage of size 3]

1674189.7054863	
 512
  64
  64
[torch.LongStorage of size 3]

1665179.2797279	
 512
  64
  64
[torch.LongStorage of size 3]

1656338.0835724	
 512
  64
  64
[torch.LongStorage of size 3]

1649558.1607628	
 512
  64
  64
[torch.LongStorage of size 3]

1641933.7396431	
 512
  64
  64
[torch.LongStorage of size 3]

1631986.6279602	
 512
  64
  64
[torch.LongStorage of size 3]

1624936.6536903	
 512
  64
  64
[torch.LongStorage of size 3]

1616876.8535233	
 512
  64
  64
[torch.LongStorage of size 3]

1608445.3227615	
 512
  64
  64
[torch.LongStorage of size 3]

1599617.3978615	
 512
  64
  64
[torch.LongStorage of size 3]

1591901.2473106	
 512
  64
  64
[torch.LongStorage of size 3]

1584247.7204704	
 512
  64
  64
[torch.LongStorage of size 3]

1576576.5684319	
 512
  64
  64
[torch.LongStorage of size 3]

1568659.7538948	
 512
  64
  64
[torch.LongStorage of size 3]

1560811.9678879	
 512
  64
  64
[torch.LongStorage of size 3]

1553119.7851372	
 512
  64
  64
[torch.LongStorage of size 3]

1545858.0203629	
 512
  64
  64
[torch.LongStorage of size 3]

1538480.0933647	
 512
  64
  64
[torch.LongStorage of size 3]

1530496.213665	
 512
  64
  64
[torch.LongStorage of size 3]

1523509.7898293	
 512
  64
  64
[torch.LongStorage of size 3]

1516623.0325699	
 512
  64
  64
[torch.LongStorage of size 3]

1509560.768795	
 512
  64
  64
[torch.LongStorage of size 3]

1502653.5534477	
 512
  64
  64
[torch.LongStorage of size 3]

1495529.3218231	
 512
  64
  64
[torch.LongStorage of size 3]

1488759.2808914	
 512
  64
  64
[torch.LongStorage of size 3]

1481901.9623947	
 512
  64
  64
[torch.LongStorage of size 3]

1474810.2675438	
 512
  64
  64
[torch.LongStorage of size 3]

1467895.8455086	
 512
  64
  64
[torch.LongStorage of size 3]

1461240.6454277	
 512
  64
  64
[torch.LongStorage of size 3]

1454520.0410271	
 512
  64
  64
[torch.LongStorage of size 3]

1448106.6503143	
 512
  64
  64
[torch.LongStorage of size 3]

1441833.8713455	
 512
  64
  64
[torch.LongStorage of size 3]

1434771.9987297	
 512
  64
  64
[torch.LongStorage of size 3]

1428405.4385948	
 512
  64
  64
[torch.LongStorage of size 3]

1422111.2022018	
 512
  64
  64
[torch.LongStorage of size 3]

1415599.3079185	
 512
  64
  64
[torch.LongStorage of size 3]

1409027.8203011	
 512
  64
  64
[torch.LongStorage of size 3]

1402537.564888	
 512
  64
  64
[torch.LongStorage of size 3]

1396213.4549713	
 512
  64
  64
[torch.LongStorage of size 3]

1390004.5541954	
 512
  64
  64
[torch.LongStorage of size 3]

1383620.986557	
 512
  64
  64
[torch.LongStorage of size 3]

1377375.1802635	
 512
  64
  64
[torch.LongStorage of size 3]

1371127.3005486	
 512
  64
  64
[torch.LongStorage of size 3]

1365337.5072098	
 512
  64
  64
[torch.LongStorage of size 3]

1359152.7859116	
 512
  64
  64
[torch.LongStorage of size 3]

1353163.3735657	
 512
  64
  64
[torch.LongStorage of size 3]

1347204.0634346	
 512
  64
  64
[torch.LongStorage of size 3]

1341424.5759583	
 512
  64
  64
[torch.LongStorage of size 3]

1335663.7346268	
 512
  64
  64
[torch.LongStorage of size 3]

1329639.2752075	
 512
  64
  64
[torch.LongStorage of size 3]

1323738.7797546	
 512
  64
  64
[torch.LongStorage of size 3]

1317971.172924	
 512
  64
  64
[torch.LongStorage of size 3]

1312259.1514969	
 512
  64
  64
[torch.LongStorage of size 3]

1306403.8720322	
 512
  64
  64
[torch.LongStorage of size 3]

1300898.6044121	
 512
  64
  64
[torch.LongStorage of size 3]

1295320.4644394	
 512
  64
  64
[torch.LongStorage of size 3]

1289978.3966827	
 512
  64
  64
[torch.LongStorage of size 3]

1284376.9045067	
 512
  64
  64
[torch.LongStorage of size 3]

1279300.7911682	
 512
  64
  64
[torch.LongStorage of size 3]

1274174.1959953	
 512
  64
  64
[torch.LongStorage of size 3]

1268922.5559044	
 512
  64
  64
[torch.LongStorage of size 3]

1263668.6876488	
 512
  64
  64
[torch.LongStorage of size 3]

1258575.5636024	
 512
  64
  64
[torch.LongStorage of size 3]

1253626.0685158	
 512
  64
  64
[torch.LongStorage of size 3]

1248647.5854874	
 512
  64
  64
[torch.LongStorage of size 3]

1243653.1233597	
 512
  64
  64
[torch.LongStorage of size 3]

1238820.2532959	
 512
  64
  64
[torch.LongStorage of size 3]

1233924.6438408	
 512
  64
  64
[torch.LongStorage of size 3]

1229186.3128853	
 512
  64
  64
[torch.LongStorage of size 3]

1224843.7613678	
 512
  64
  64
[torch.LongStorage of size 3]

1220750.5460739	
 512
  64
  64
[torch.LongStorage of size 3]

1215735.4761314	
 512
  64
  64
[torch.LongStorage of size 3]

1210911.3067436	
 512
  64
  64
[torch.LongStorage of size 3]

1206693.4947777	
 512
  64
  64
[torch.LongStorage of size 3]

1202155.1371765	
 512
  64
  64
[torch.LongStorage of size 3]

1197767.5953102	
 512
  64
  64
[torch.LongStorage of size 3]

1193284.6665764	
 512
  64
  64
[torch.LongStorage of size 3]

1189019.4477272	
 512
  64
  64
[torch.LongStorage of size 3]

1184728.9559746	
 512
  64
  64
[torch.LongStorage of size 3]

1180436.709938	
 512
  64
  64
[torch.LongStorage of size 3]

1176179.576683	
 512
  64
  64
[torch.LongStorage of size 3]

1171971.2854385	
 512
  64
  64
[torch.LongStorage of size 3]

1167765.9500885	
 512
  64
  64
[torch.LongStorage of size 3]

1163539.2727852	
 512
  64
  64
[torch.LongStorage of size 3]

1159490.6434631	
 512
  64
  64
[torch.LongStorage of size 3]

1155587.3419762	
 512
  64
  64
[torch.LongStorage of size 3]

1151910.1530647	
 512
  64
  64
[torch.LongStorage of size 3]

1147820.2450752	
 512
  64
  64
[torch.LongStorage of size 3]

1143843.2476044	
 512
  64
  64
[torch.LongStorage of size 3]

1140203.3699989	
 512
  64
  64
[torch.LongStorage of size 3]

1136475.7846832	
 512
  64
  64
[torch.LongStorage of size 3]

1132576.6533279	
 512
  64
  64
[torch.LongStorage of size 3]

1128809.2312622	
 512
  64
  64
[torch.LongStorage of size 3]

1125192.3465538	
 512
  64
  64
[torch.LongStorage of size 3]

1121631.6795349	
 512
  64
  64
[torch.LongStorage of size 3]

1117962.1447563	
 512
  64
  64
[torch.LongStorage of size 3]

1114373.6981964	
 512
  64
  64
[torch.LongStorage of size 3]

1110737.5776482	
 512
  64
  64
[torch.LongStorage of size 3]

1107243.4160805	
 512
  64
  64
[torch.LongStorage of size 3]

1103699.5064545	
 512
  64
  64
[torch.LongStorage of size 3]

1100282.0024109	
 512
  64
  64
[torch.LongStorage of size 3]

1096871.7012405	
 512
  64
  64
[torch.LongStorage of size 3]

1093478.3477402	
 512
  64
  64
[torch.LongStorage of size 3]

1090135.4128647	
 512
  64
  64
[torch.LongStorage of size 3]

1086894.563446	
 512
  64
  64
[torch.LongStorage of size 3]

1083599.3217278	
 512
  64
  64
[torch.LongStorage of size 3]

1080314.1438866	
 512
  64
  64
[torch.LongStorage of size 3]

1077102.7718353	
 512
  64
  64
[torch.LongStorage of size 3]

1074034.1740799	
 512
  64
  64
[torch.LongStorage of size 3]

1071005.4720306	
 512
  64
  64
[torch.LongStorage of size 3]

1068078.269825	
 512
  64
  64
[torch.LongStorage of size 3]

1065144.0597534	
 512
  64
  64
[torch.LongStorage of size 3]

1062157.514286	
 512
  64
  64
[torch.LongStorage of size 3]

1059178.4914589	
 512
  64
  64
[torch.LongStorage of size 3]

1056327.6763535	
 512
  64
  64
[torch.LongStorage of size 3]

1053556.9474983	
 512
  64
  64
[torch.LongStorage of size 3]

1050787.0179558	
 512
  64
  64
[torch.LongStorage of size 3]

1047981.4814186	
 512
  64
  64
[torch.LongStorage of size 3]

1045243.382988	
 512
  64
  64
[torch.LongStorage of size 3]

1042440.9150314	
 512
  64
  64
[torch.LongStorage of size 3]

1039593.5201836	
 512
  64
  64
[torch.LongStorage of size 3]

1036914.7081566	
 512
  64
  64
[torch.LongStorage of size 3]

1034289.1198921	
 512
  64
  64
[torch.LongStorage of size 3]

1031575.9466362	
 512
  64
  64
[torch.LongStorage of size 3]

1028844.7808647	
 512
  64
  64
[torch.LongStorage of size 3]

1026286.6346359	
 512
  64
  64
[torch.LongStorage of size 3]

1023713.3804512	
 512
  64
  64
[torch.LongStorage of size 3]

1021004.5018959	
 512
  64
  64
[torch.LongStorage of size 3]

1018416.1223412	
 512
  64
  64
[torch.LongStorage of size 3]

1015860.1641464	
 512
  64
  64
[torch.LongStorage of size 3]

1013375.0877762	
 512
  64
  64
[torch.LongStorage of size 3]

1010845.9933662	
 512
  64
  64
[torch.LongStorage of size 3]

1008444.0302849	
 512
  64
  64
[torch.LongStorage of size 3]

1006059.1920662	
 512
  64
  64
[torch.LongStorage of size 3]

1003769.9145699	
 512
  64
  64
[torch.LongStorage of size 3]

1001284.1500282	
 512
  64
  64
[torch.LongStorage of size 3]

998750.41618347	
 512
  64
  64
[torch.LongStorage of size 3]

996260.14650345	
 512
  64
  64
[torch.LongStorage of size 3]

993892.11114883	
 512
  64
  64
[torch.LongStorage of size 3]

991669.21583176	
 512
  64
  64
[torch.LongStorage of size 3]

989402.43349075	
 512
  64
  64
[torch.LongStorage of size 3]

987119.55089569	
 512
  64
  64
[torch.LongStorage of size 3]

984967.98084259	
 512
  64
  64
[torch.LongStorage of size 3]

982729.09858704	
 512
  64
  64
[torch.LongStorage of size 3]

980501.36749268	
 512
  64
  64
[torch.LongStorage of size 3]

978397.41706848	
 512
  64
  64
[torch.LongStorage of size 3]

976243.85082245	
 512
  64
  64
[torch.LongStorage of size 3]

974156.31055832	
 512
  64
  64
[torch.LongStorage of size 3]

972125.92853546	
 512
  64
  64
[torch.LongStorage of size 3]

969989.66369629	
 512
  64
  64
[torch.LongStorage of size 3]

967903.41171265	
 512
  64
  64
[torch.LongStorage of size 3]

965875.6444931	
 512
  64
  64
[torch.LongStorage of size 3]

963881.63288116	
 512
  64
  64
[torch.LongStorage of size 3]

961856.71897888	
 512
  64
  64
[torch.LongStorage of size 3]

959840.9069252	
 512
  64
  64
[torch.LongStorage of size 3]

957859.14093018	
 512
  64
  64
[torch.LongStorage of size 3]

955839.02633667	
 512
  64
  64
[torch.LongStorage of size 3]

953885.97925186	
 512
  64
  64
[torch.LongStorage of size 3]

951937.70072937	
 512
  64
  64
[torch.LongStorage of size 3]

950054.13187027	
 512
  64
  64
[torch.LongStorage of size 3]

948308.54366302	
 512
  64
  64
[torch.LongStorage of size 3]

946501.20222092	
 512
  64
  64
[torch.LongStorage of size 3]

944653.45632553	
 512
  64
  64
[torch.LongStorage of size 3]

942805.20828247	
 512
  64
  64
[torch.LongStorage of size 3]

941023.58032227	
 512
  64
  64
[torch.LongStorage of size 3]

939216.18700027	
 512
  64
  64
[torch.LongStorage of size 3]

937438.38655472	
 512
  64
  64
[torch.LongStorage of size 3]

935701.60497665	
 512
  64
  64
[torch.LongStorage of size 3]

933932.5567627	
 512
  64
  64
[torch.LongStorage of size 3]

932167.37043381	
 512
  64
  64
[torch.LongStorage of size 3]

930364.8638916	
 512
  64
  64
[torch.LongStorage of size 3]

928637.25831985	
 512
  64
  64
[torch.LongStorage of size 3]

926916.73999786	
 512
  64
  64
[torch.LongStorage of size 3]

925323.61282349	
 512
  64
  64
[torch.LongStorage of size 3]

923639.68055725	
 512
  64
  64
[torch.LongStorage of size 3]

921910.21148682	
 512
  64
  64
[torch.LongStorage of size 3]

920160.87018967	
 512
  64
  64
[torch.LongStorage of size 3]

918498.4897995	
 512
  64
  64
[torch.LongStorage of size 3]

916855.71899414	
 512
  64
  64
[torch.LongStorage of size 3]

915253.40150833	
 512
  64
  64
[torch.LongStorage of size 3]

913755.37694931	
 512
  64
  64
[torch.LongStorage of size 3]

912258.77031326	
 512
  64
  64
[torch.LongStorage of size 3]

910709.6134758	
 512
  64
  64
[torch.LongStorage of size 3]

909234.12349701	
 512
  64
  64
[torch.LongStorage of size 3]

907709.13299561	
 512
  64
  64
[torch.LongStorage of size 3]

906204.75305557	
 512
  64
  64
[torch.LongStorage of size 3]

904704.2880249	
 512
  64
  64
[torch.LongStorage of size 3]

903306.49282455	
 512
  64
  64
[torch.LongStorage of size 3]

901822.36974716	
 512
  64
  64
[torch.LongStorage of size 3]

900292.60795593	
 512
  64
  64
[torch.LongStorage of size 3]

898807.55865097	
 512
  64
  64
[torch.LongStorage of size 3]

897411.83641434	
 512
  64
  64
[torch.LongStorage of size 3]

895984.79288101	
 512
  64
  64
[torch.LongStorage of size 3]

894584.62474823	
 512
  64
  64
[torch.LongStorage of size 3]

893219.09202576	
 512
  64
  64
[torch.LongStorage of size 3]

891823.54560852	
 512
  64
  64
[torch.LongStorage of size 3]

890354.63247299	
 512
  64
  64
[torch.LongStorage of size 3]

888991.44264221	
 512
  64
  64
[torch.LongStorage of size 3]

887566.98896408	
 512
  64
  64
[torch.LongStorage of size 3]

886179.24051285	
 512
  64
  64
[torch.LongStorage of size 3]

884831.73500061	
 512
  64
  64
[torch.LongStorage of size 3]

883475.7276535	
 512
  64
  64
[torch.LongStorage of size 3]

882112.42897034	
 512
  64
  64
[torch.LongStorage of size 3]

880795.36533356	
 512
  64
  64
[torch.LongStorage of size 3]

879498.45428467	
 512
  64
  64
[torch.LongStorage of size 3]

878198.02963257	
 512
  64
  64
[torch.LongStorage of size 3]

876921.94850922	
 512
  64
  64
[torch.LongStorage of size 3]

875735.83379745	
 512
  64
  64
[torch.LongStorage of size 3]

874451.62912369	
 512
  64
  64
[torch.LongStorage of size 3]

873223.5590744	
 512
  64
  64
[torch.LongStorage of size 3]

871969.78618622	
 512
  64
  64
[torch.LongStorage of size 3]

870736.70438766	
 512
  64
  64
[torch.LongStorage of size 3]

869525.44603348	
Iteration 333 / 1000	
  Content 1 loss: 557513.671875	
  Style 1 loss: 6670.630646	
  Style 2 loss: 55424.078369	
  Style 3 loss: 36306.970215	
  Style 4 loss: 212483.251953	
  Style 5 loss: 1126.842976	
  Total loss: 869525.446033	
s/askrxffeqxoy.png_out_prepost_333.png	
 512
  64
  64
[torch.LongStorage of size 3]

868299.37822342	
 512
  64
  64
[torch.LongStorage of size 3]

867089.83121872	
 512
  64
  64
[torch.LongStorage of size 3]

865960.89258194	
 512
  64
  64
[torch.LongStorage of size 3]

864774.43460464	
 512
  64
  64
[torch.LongStorage of size 3]

863584.49811935	
 512
  64
  64
[torch.LongStorage of size 3]

862423.80918503	
 512
  64
  64
[torch.LongStorage of size 3]

861285.43489456	
 512
  64
  64
[torch.LongStorage of size 3]

860163.6750412	
 512
  64
  64
[torch.LongStorage of size 3]

859090.43794632	
 512
  64
  64
[torch.LongStorage of size 3]

857997.81864166	
 512
  64
  64
[torch.LongStorage of size 3]

856837.10206985	
 512
  64
  64
[torch.LongStorage of size 3]

855653.69251251	
 512
  64
  64
[torch.LongStorage of size 3]

854562.55479813	
 512
  64
  64
[torch.LongStorage of size 3]

853462.67744064	
 512
  64
  64
[torch.LongStorage of size 3]

852335.79738617	
 512
  64
  64
[torch.LongStorage of size 3]

851209.06665802	
 512
  64
  64
[torch.LongStorage of size 3]

850108.61177444	
 512
  64
  64
[torch.LongStorage of size 3]

849025.87493896	
 512
  64
  64
[torch.LongStorage of size 3]

847973.56149673	
 512
  64
  64
[torch.LongStorage of size 3]

846959.33454514	
 512
  64
  64
[torch.LongStorage of size 3]

845955.3412056	
 512
  64
  64
[torch.LongStorage of size 3]

844986.91062927	
 512
  64
  64
[torch.LongStorage of size 3]

843986.58554077	
 512
  64
  64
[torch.LongStorage of size 3]

842966.38465881	
 512
  64
  64
[torch.LongStorage of size 3]

841939.29548264	
 512
  64
  64
[torch.LongStorage of size 3]

840858.51678848	
 512
  64
  64
[torch.LongStorage of size 3]

839840.43571472	
 512
  64
  64
[torch.LongStorage of size 3]

838879.87890244	
 512
  64
  64
[torch.LongStorage of size 3]

837870.41055679	
 512
  64
  64
[torch.LongStorage of size 3]

836874.79984283	
 512
  64
  64
[torch.LongStorage of size 3]

835724.80264664	
 512
  64
  64
[torch.LongStorage of size 3]

834663.49805832	
 512
  64
  64
[torch.LongStorage of size 3]

833674.28602219	
 512
  64
  64
[torch.LongStorage of size 3]

832652.78358459	
 512
  64
  64
[torch.LongStorage of size 3]

831688.10619354	
 512
  64
  64
[torch.LongStorage of size 3]

830657.67049789	
 512
  64
  64
[torch.LongStorage of size 3]

829662.55655289	
 512
  64
  64
[torch.LongStorage of size 3]

828738.94300461	
 512
  64
  64
[torch.LongStorage of size 3]

827804.08697128	
 512
  64
  64
[torch.LongStorage of size 3]

826834.31776047	
 512
  64
  64
[torch.LongStorage of size 3]

825875.04148483	
 512
  64
  64
[torch.LongStorage of size 3]

824937.72075653	
 512
  64
  64
[torch.LongStorage of size 3]

823987.30916977	
 512
  64
  64
[torch.LongStorage of size 3]

823053.55392456	
 512
  64
  64
[torch.LongStorage of size 3]

822128.55293274	
 512
  64
  64
[torch.LongStorage of size 3]

821263.13568115	
 512
  64
  64
[torch.LongStorage of size 3]

820314.44433212	
 512
  64
  64
[torch.LongStorage of size 3]

819334.60773468	
 512
  64
  64
[torch.LongStorage of size 3]

818315.2460289	
 512
  64
  64
[torch.LongStorage of size 3]

817335.62282562	
 512
  64
  64
[torch.LongStorage of size 3]

816394.86377716	
 512
  64
  64
[torch.LongStorage of size 3]

815452.4968338	
 512
  64
  64
[torch.LongStorage of size 3]

814503.6009407	
 512
  64
  64
[torch.LongStorage of size 3]

813579.12511826	
 512
  64
  64
[torch.LongStorage of size 3]

812675.56049347	
 512
  64
  64
[torch.LongStorage of size 3]

811762.66805649	
 512
  64
  64
[torch.LongStorage of size 3]

810877.99150467	
 512
  64
  64
[torch.LongStorage of size 3]

810054.20097351	
 512
  64
  64
[torch.LongStorage of size 3]

809166.59454346	
 512
  64
  64
[torch.LongStorage of size 3]

808263.46176147	
 512
  64
  64
[torch.LongStorage of size 3]

807395.25981903	
 512
  64
  64
[torch.LongStorage of size 3]

806506.31015778	
 512
  64
  64
[torch.LongStorage of size 3]

805601.72706604	
 512
  64
  64
[torch.LongStorage of size 3]

804718.92889023	
 512
  64
  64
[torch.LongStorage of size 3]

803862.06167221	
 512
  64
  64
[torch.LongStorage of size 3]

803042.12005615	
 512
  64
  64
[torch.LongStorage of size 3]

802270.08739471	
 512
  64
  64
[torch.LongStorage of size 3]

801468.77603531	
 512
  64
  64
[torch.LongStorage of size 3]

800695.37618637	
 512
  64
  64
[torch.LongStorage of size 3]

799920.62891006	
 512
  64
  64
[torch.LongStorage of size 3]

799157.99499512	
 512
  64
  64
[torch.LongStorage of size 3]

798375.47924042	
 512
  64
  64
[torch.LongStorage of size 3]

797630.64331055	
 512
  64
  64
[torch.LongStorage of size 3]

796878.81763458	
 512
  64
  64
[torch.LongStorage of size 3]

796152.32580185	
 512
  64
  64
[torch.LongStorage of size 3]

795462.01147079	
 512
  64
  64
[torch.LongStorage of size 3]

794732.52922058	
 512
  64
  64
[torch.LongStorage of size 3]

793968.92055511	
 512
  64
  64
[torch.LongStorage of size 3]

793226.08488083	
 512
  64
  64
[torch.LongStorage of size 3]

792488.1414032	
 512
  64
  64
[torch.LongStorage of size 3]

791748.19747925	
 512
  64
  64
[torch.LongStorage of size 3]

791002.25852966	
 512
  64
  64
[torch.LongStorage of size 3]

790259.01321411	
 512
  64
  64
[torch.LongStorage of size 3]

789555.86578369	
 512
  64
  64
[torch.LongStorage of size 3]

788870.2948761	
 512
  64
  64
[torch.LongStorage of size 3]

788162.90262222	
 512
  64
  64
[torch.LongStorage of size 3]

787403.69081497	
 512
  64
  64
[torch.LongStorage of size 3]

786708.73414993	
 512
  64
  64
[torch.LongStorage of size 3]

786017.39690781	
 512
  64
  64
[torch.LongStorage of size 3]

785319.08790588	
 512
  64
  64
[torch.LongStorage of size 3]

784652.47144699	
 512
  64
  64
[torch.LongStorage of size 3]

783963.32334518	
 512
  64
  64
[torch.LongStorage of size 3]

783267.55025864	
 512
  64
  64
[torch.LongStorage of size 3]

782594.9347496	
 512
  64
  64
[torch.LongStorage of size 3]

781964.69371796	
 512
  64
  64
[torch.LongStorage of size 3]

781298.27157974	
 512
  64
  64
[torch.LongStorage of size 3]

780619.60575104	
 512
  64
  64
[torch.LongStorage of size 3]

779962.12989807	
 512
  64
  64
[torch.LongStorage of size 3]

779290.50987244	
 512
  64
  64
[torch.LongStorage of size 3]

778631.39839172	
 512
  64
  64
[torch.LongStorage of size 3]

778018.02471161	
 512
  64
  64
[torch.LongStorage of size 3]

777396.2348175	
 512
  64
  64
[torch.LongStorage of size 3]

776799.31684494	
 512
  64
  64
[torch.LongStorage of size 3]

776142.19839096	
 512
  64
  64
[torch.LongStorage of size 3]

775472.19491959	
 512
  64
  64
[torch.LongStorage of size 3]

774791.16436005	
 512
  64
  64
[torch.LongStorage of size 3]

774114.56932068	
 512
  64
  64
[torch.LongStorage of size 3]

773442.39686966	
 512
  64
  64
[torch.LongStorage of size 3]

772770.85115433	
 512
  64
  64
[torch.LongStorage of size 3]

772132.09201813	
 512
  64
  64
[torch.LongStorage of size 3]

771458.07531357	
 512
  64
  64
[torch.LongStorage of size 3]

770808.57126236	
 512
  64
  64
[torch.LongStorage of size 3]

770169.12752151	
 512
  64
  64
[torch.LongStorage of size 3]

769571.45950317	
 512
  64
  64
[torch.LongStorage of size 3]

768935.82872391	
 512
  64
  64
[torch.LongStorage of size 3]

768330.07123947	
 512
  64
  64
[torch.LongStorage of size 3]

767735.56816101	
 512
  64
  64
[torch.LongStorage of size 3]

767125.75584412	
 512
  64
  64
[torch.LongStorage of size 3]

766562.39496231	
 512
  64
  64
[torch.LongStorage of size 3]

765964.74136353	
 512
  64
  64
[torch.LongStorage of size 3]

765385.15851974	
 512
  64
  64
[torch.LongStorage of size 3]

764828.88751984	
 512
  64
  64
[torch.LongStorage of size 3]

764267.18826294	
 512
  64
  64
[torch.LongStorage of size 3]

763704.07754898	
 512
  64
  64
[torch.LongStorage of size 3]

763207.28067398	
 512
  64
  64
[torch.LongStorage of size 3]

762666.59044266	
 512
  64
  64
[torch.LongStorage of size 3]

762090.44111252	
 512
  64
  64
[torch.LongStorage of size 3]

761562.68146515	
 512
  64
  64
[torch.LongStorage of size 3]

761021.47500992	
 512
  64
  64
[torch.LongStorage of size 3]

760479.84273911	
 512
  64
  64
[torch.LongStorage of size 3]

759948.9299202	
 512
  64
  64
[torch.LongStorage of size 3]

759411.92937851	
 512
  64
  64
[torch.LongStorage of size 3]

758896.78987503	
 512
  64
  64
[torch.LongStorage of size 3]

758390.21942139	
 512
  64
  64
[torch.LongStorage of size 3]

757887.13237762	
 512
  64
  64
[torch.LongStorage of size 3]

757406.26382828	
 512
  64
  64
[torch.LongStorage of size 3]

756914.71166611	
 512
  64
  64
[torch.LongStorage of size 3]

756439.49178696	
 512
  64
  64
[torch.LongStorage of size 3]

755921.46680832	
 512
  64
  64
[torch.LongStorage of size 3]

755412.92972565	
 512
  64
  64
[torch.LongStorage of size 3]

754917.39583969	
 512
  64
  64
[torch.LongStorage of size 3]

754453.42611313	
 512
  64
  64
[torch.LongStorage of size 3]

753999.112854	
 512
  64
  64
[torch.LongStorage of size 3]

753550.61576843	
 512
  64
  64
[torch.LongStorage of size 3]

753102.58110046	
 512
  64
  64
[torch.LongStorage of size 3]

752660.4268074	
 512
  64
  64
[torch.LongStorage of size 3]

752149.55636978	
 512
  64
  64
[torch.LongStorage of size 3]

751659.82984543	
 512
  64
  64
[torch.LongStorage of size 3]

751207.32131958	
 512
  64
  64
[torch.LongStorage of size 3]

750767.41737366	
 512
  64
  64
[torch.LongStorage of size 3]

750331.09714508	
 512
  64
  64
[torch.LongStorage of size 3]

749885.78014374	
 512
  64
  64
[torch.LongStorage of size 3]

749432.7069664	
 512
  64
  64
[torch.LongStorage of size 3]

748989.26275253	
 512
  64
  64
[torch.LongStorage of size 3]

748544.06942368	
 512
  64
  64
[torch.LongStorage of size 3]

748100.33248901	
 512
  64
  64
[torch.LongStorage of size 3]

747687.68386841	
 512
  64
  64
[torch.LongStorage of size 3]

747265.25501251	
 512
  64
  64
[torch.LongStorage of size 3]

746849.84994888	
 512
  64
  64
[torch.LongStorage of size 3]

746431.62553787	
 512
  64
  64
[torch.LongStorage of size 3]

746004.26969528	
 512
  64
  64
[torch.LongStorage of size 3]

745590.12922287	
 512
  64
  64
[torch.LongStorage of size 3]

745171.75365448	
 512
  64
  64
[torch.LongStorage of size 3]

744771.41550064	
 512
  64
  64
[torch.LongStorage of size 3]

744355.4785347	
 512
  64
  64
[torch.LongStorage of size 3]

743968.29050064	
 512
  64
  64
[torch.LongStorage of size 3]

743542.79323578	
 512
  64
  64
[torch.LongStorage of size 3]

743139.05435562	
 512
  64
  64
[torch.LongStorage of size 3]

742724.14627075	
 512
  64
  64
[torch.LongStorage of size 3]

742331.34950638	
 512
  64
  64
[torch.LongStorage of size 3]

741927.50318527	
 512
  64
  64
[torch.LongStorage of size 3]

741543.58533859	
 512
  64
  64
[torch.LongStorage of size 3]

741149.34465408	
 512
  64
  64
[torch.LongStorage of size 3]

740752.14466095	
 512
  64
  64
[torch.LongStorage of size 3]

740363.20566177	
 512
  64
  64
[torch.LongStorage of size 3]

739961.80662155	
 512
  64
  64
[torch.LongStorage of size 3]

739584.32052612	
 512
  64
  64
[torch.LongStorage of size 3]

739153.99621964	
 512
  64
  64
[torch.LongStorage of size 3]

738729.34663773	
 512
  64
  64
[torch.LongStorage of size 3]

738313.04204941	
 512
  64
  64
[torch.LongStorage of size 3]

737905.04478455	
 512
  64
  64
[torch.LongStorage of size 3]

737490.30963898	
 512
  64
  64
[torch.LongStorage of size 3]

737084.58036423	
 512
  64
  64
[torch.LongStorage of size 3]

736684.52213287	
 512
  64
  64
[torch.LongStorage of size 3]

736299.23290253	
 512
  64
  64
[torch.LongStorage of size 3]

735892.18179703	
 512
  64
  64
[torch.LongStorage of size 3]

735484.4601059	
 512
  64
  64
[torch.LongStorage of size 3]

735078.06793213	
 512
  64
  64
[torch.LongStorage of size 3]

734682.59992599	
 512
  64
  64
[torch.LongStorage of size 3]

734297.01253891	
 512
  64
  64
[torch.LongStorage of size 3]

733941.46402359	
 512
  64
  64
[torch.LongStorage of size 3]

733562.83594131	
 512
  64
  64
[torch.LongStorage of size 3]

733178.20085526	
 512
  64
  64
[torch.LongStorage of size 3]

732784.16456223	
 512
  64
  64
[torch.LongStorage of size 3]

732399.45934296	
 512
  64
  64
[torch.LongStorage of size 3]

732011.80809021	
 512
  64
  64
[torch.LongStorage of size 3]

731640.70978165	
 512
  64
  64
[torch.LongStorage of size 3]

731282.13514328	
 512
  64
  64
[torch.LongStorage of size 3]

730917.47234344	
 512
  64
  64
[torch.LongStorage of size 3]

730557.16014862	
 512
  64
  64
[torch.LongStorage of size 3]

730178.97266388	
 512
  64
  64
[torch.LongStorage of size 3]

729800.09698868	
 512
  64
  64
[torch.LongStorage of size 3]

729435.63503265	
 512
  64
  64
[torch.LongStorage of size 3]

729086.2743187	
 512
  64
  64
[torch.LongStorage of size 3]

728722.74009705	
 512
  64
  64
[torch.LongStorage of size 3]

728376.71369553	
 512
  64
  64
[torch.LongStorage of size 3]

728023.72148514	
 512
  64
  64
[torch.LongStorage of size 3]

727707.21870422	
 512
  64
  64
[torch.LongStorage of size 3]

727348.75230789	
 512
  64
  64
[torch.LongStorage of size 3]

727013.22006226	
 512
  64
  64
[torch.LongStorage of size 3]

726653.44982147	
 512
  64
  64
[torch.LongStorage of size 3]

726311.7442894	
 512
  64
  64
[torch.LongStorage of size 3]

725963.515625	
 512
  64
  64
[torch.LongStorage of size 3]

725637.99928665	
 512
  64
  64
[torch.LongStorage of size 3]

725304.25672531	
 512
  64
  64
[torch.LongStorage of size 3]

724959.11876678	
 512
  64
  64
[torch.LongStorage of size 3]

724631.89908981	
 512
  64
  64
[torch.LongStorage of size 3]

724293.16970825	
 512
  64
  64
[torch.LongStorage of size 3]

723970.54450989	
 512
  64
  64
[torch.LongStorage of size 3]

723648.8527298	
 512
  64
  64
[torch.LongStorage of size 3]

723341.24795914	
 512
  64
  64
[torch.LongStorage of size 3]

723023.60525131	
 512
  64
  64
[torch.LongStorage of size 3]

722710.92786789	
 512
  64
  64
[torch.LongStorage of size 3]

722390.51649094	
 512
  64
  64
[torch.LongStorage of size 3]

722084.91634369	
 512
  64
  64
[torch.LongStorage of size 3]

721776.13128662	
 512
  64
  64
[torch.LongStorage of size 3]

721477.36988068	
 512
  64
  64
[torch.LongStorage of size 3]

721165.62757492	
 512
  64
  64
[torch.LongStorage of size 3]

720860.4759407	
 512
  64
  64
[torch.LongStorage of size 3]

720557.57127762	
 512
  64
  64
[torch.LongStorage of size 3]

720257.17697144	
 512
  64
  64
[torch.LongStorage of size 3]

719950.8908844	
 512
  64
  64
[torch.LongStorage of size 3]

719675.63623428	
 512
  64
  64
[torch.LongStorage of size 3]

719370.59724808	
 512
  64
  64
[torch.LongStorage of size 3]

719078.05934906	
 512
  64
  64
[torch.LongStorage of size 3]

718795.9352684	
 512
  64
  64
[torch.LongStorage of size 3]

718518.12242508	
 512
  64
  64
[torch.LongStorage of size 3]

718218.8520813	
 512
  64
  64
[torch.LongStorage of size 3]

717943.33837509	
 512
  64
  64
[torch.LongStorage of size 3]

717667.55346298	
 512
  64
  64
[torch.LongStorage of size 3]

717391.85909271	
 512
  64
  64
[torch.LongStorage of size 3]

717108.34152222	
 512
  64
  64
[torch.LongStorage of size 3]

716862.75308609	
 512
  64
  64
[torch.LongStorage of size 3]

716585.60583115	
 512
  64
  64
[torch.LongStorage of size 3]

716311.47405624	
 512
  64
  64
[torch.LongStorage of size 3]

716053.98155212	
 512
  64
  64
[torch.LongStorage of size 3]

715794.14178848	
 512
  64
  64
[torch.LongStorage of size 3]

715528.49317551	
 512
  64
  64
[torch.LongStorage of size 3]

715293.3511734	
 512
  64
  64
[torch.LongStorage of size 3]

715033.92354965	
 512
  64
  64
[torch.LongStorage of size 3]

714764.78120804	
 512
  64
  64
[torch.LongStorage of size 3]

714489.15224075	
 512
  64
  64
[torch.LongStorage of size 3]

714249.9115181	
 512
  64
  64
[torch.LongStorage of size 3]

713973.83481979	
 512
  64
  64
[torch.LongStorage of size 3]

713723.95978928	
 512
  64
  64
[torch.LongStorage of size 3]

713472.66822815	
 512
  64
  64
[torch.LongStorage of size 3]

713210.41284561	
 512
  64
  64
[torch.LongStorage of size 3]

712950.49032211	
 512
  64
  64
[torch.LongStorage of size 3]

712704.80049133	
 512
  64
  64
[torch.LongStorage of size 3]

712435.1442337	
 512
  64
  64
[torch.LongStorage of size 3]

712186.37369156	
 512
  64
  64
[torch.LongStorage of size 3]

711929.97756958	
 512
  64
  64
[torch.LongStorage of size 3]

711673.93053055	
 512
  64
  64
[torch.LongStorage of size 3]

711422.34716415	
 512
  64
  64
[torch.LongStorage of size 3]

711177.48512268	
 512
  64
  64
[torch.LongStorage of size 3]

710933.50795746	
 512
  64
  64
[torch.LongStorage of size 3]

710678.5310936	
 512
  64
  64
[torch.LongStorage of size 3]

710426.46659851	
 512
  64
  64
[torch.LongStorage of size 3]

710181.33815765	
 512
  64
  64
[torch.LongStorage of size 3]

709941.00851059	
 512
  64
  64
[torch.LongStorage of size 3]

709682.83575058	
 512
  64
  64
[torch.LongStorage of size 3]

709432.90067673	
 512
  64
  64
[torch.LongStorage of size 3]

709182.09144592	
 512
  64
  64
[torch.LongStorage of size 3]

708947.88282394	
 512
  64
  64
[torch.LongStorage of size 3]

708693.16133499	
 512
  64
  64
[torch.LongStorage of size 3]

708486.86706543	
 512
  64
  64
[torch.LongStorage of size 3]

708215.75231552	
 512
  64
  64
[torch.LongStorage of size 3]

707978.3665657	
 512
  64
  64
[torch.LongStorage of size 3]

707719.80829239	
 512
  64
  64
[torch.LongStorage of size 3]

707484.42022324	
 512
  64
  64
[torch.LongStorage of size 3]

707248.25662613	
 512
  64
  64
[torch.LongStorage of size 3]

707003.31439972	
 512
  64
  64
[torch.LongStorage of size 3]

706765.37080765	
 512
  64
  64
[torch.LongStorage of size 3]

706525.61588287	
 512
  64
  64
[torch.LongStorage of size 3]

706287.77841568	
 512
  64
  64
[torch.LongStorage of size 3]

706048.60548019	
 512
  64
  64
[torch.LongStorage of size 3]

705805.07078171	
 512
  64
  64
[torch.LongStorage of size 3]

705553.10602188	
 512
  64
  64
[torch.LongStorage of size 3]

705329.12719727	
 512
  64
  64
[torch.LongStorage of size 3]

705094.59692001	
 512
  64
  64
[torch.LongStorage of size 3]

704868.72480392	
 512
  64
  64
[torch.LongStorage of size 3]

704627.24050522	
 512
  64
  64
[torch.LongStorage of size 3]

704406.60879135	
 512
  64
  64
[torch.LongStorage of size 3]

704168.89600754	
 512
  64
  64
[torch.LongStorage of size 3]

703933.52651596	
 512
  64
  64
[torch.LongStorage of size 3]

703698.84609222	
 512
  64
  64
[torch.LongStorage of size 3]

703460.36849976	
 512
  64
  64
[torch.LongStorage of size 3]

703238.53256226	
 512
  64
  64
[torch.LongStorage of size 3]

703009.02524948	
 512
  64
  64
[torch.LongStorage of size 3]

702785.56875229	
 512
  64
  64
[torch.LongStorage of size 3]

702558.85360718	
 512
  64
  64
[torch.LongStorage of size 3]

702341.06702805	
 512
  64
  64
[torch.LongStorage of size 3]

702116.72515869	
 512
  64
  64
[torch.LongStorage of size 3]

701908.43519211	
 512
  64
  64
[torch.LongStorage of size 3]

701670.14163971	
 512
  64
  64
[torch.LongStorage of size 3]

701482.93289185	
 512
  64
  64
[torch.LongStorage of size 3]

701234.08691406	
 512
  64
  64
[torch.LongStorage of size 3]

701014.32495117	
 512
  64
  64
[torch.LongStorage of size 3]

700772.84549713	
 512
  64
  64
[torch.LongStorage of size 3]

700563.62565994	
 512
  64
  64
[torch.LongStorage of size 3]

700348.77037048	
 512
  64
  64
[torch.LongStorage of size 3]

700129.65219498	
 512
  64
  64
[torch.LongStorage of size 3]

699908.69451523	
 512
  64
  64
[torch.LongStorage of size 3]

699696.77761078	
 512
  64
  64
[torch.LongStorage of size 3]

699479.50483322	
 512
  64
  64
[torch.LongStorage of size 3]

699280.57884216	
 512
  64
  64
[torch.LongStorage of size 3]

699065.46873093	
 512
  64
  64
[torch.LongStorage of size 3]

698860.99933624	
 512
  64
  64
[torch.LongStorage of size 3]

698642.78425217	
 512
  64
  64
[torch.LongStorage of size 3]

698433.30991745	
 512
  64
  64
[torch.LongStorage of size 3]

698221.17734909	
 512
  64
  64
[torch.LongStorage of size 3]

698033.06158066	
 512
  64
  64
[torch.LongStorage of size 3]

697832.82226562	
 512
  64
  64
[torch.LongStorage of size 3]

697629.23826218	
 512
  64
  64
[torch.LongStorage of size 3]

697434.44929123	
 512
  64
  64
[torch.LongStorage of size 3]

697232.76103973	
 512
  64
  64
[torch.LongStorage of size 3]

697027.09869385	
 512
  64
  64
[torch.LongStorage of size 3]

696826.4043045	
 512
  64
  64
[torch.LongStorage of size 3]

696628.03564072	
 512
  64
  64
[torch.LongStorage of size 3]

696418.91241074	
 512
  64
  64
[torch.LongStorage of size 3]

696215.66755295	
 512
  64
  64
[torch.LongStorage of size 3]

696015.26205063	
 512
  64
  64
[torch.LongStorage of size 3]

695818.39574814	
Iteration 666 / 1000	
  Content 1 loss: 517553.281250	
  Style 1 loss: 808.553696	
  Style 2 loss: 16125.477600	
  Style 3 loss: 17818.659973	
  Style 4 loss: 142440.673828	
  Style 5 loss: 1071.749401	
  Total loss: 695818.395748	
s/askrxffeqxoy.png_out_prepost_666.png	
 512
  64
  64
[torch.LongStorage of size 3]

695614.73478317	
 512
  64
  64
[torch.LongStorage of size 3]

695447.93851852	
 512
  64
  64
[torch.LongStorage of size 3]

695230.77880859	
 512
  64
  64
[torch.LongStorage of size 3]

695056.16340637	
 512
  64
  64
[torch.LongStorage of size 3]

694808.67990494	
 512
  64
  64
[torch.LongStorage of size 3]

694607.29225159	
 512
  64
  64
[torch.LongStorage of size 3]

694432.21466064	
 512
  64
  64
[torch.LongStorage of size 3]

694248.33684921	
 512
  64
  64
[torch.LongStorage of size 3]

694056.12991333	
 512
  64
  64
[torch.LongStorage of size 3]

693866.47382736	
 512
  64
  64
[torch.LongStorage of size 3]

693676.7939949	
 512
  64
  64
[torch.LongStorage of size 3]

693487.54964828	
 512
  64
  64
[torch.LongStorage of size 3]

693307.05799103	
 512
  64
  64
[torch.LongStorage of size 3]

693125.73158264	
 512
  64
  64
[torch.LongStorage of size 3]

692950.42634964	
 512
  64
  64
[torch.LongStorage of size 3]

692779.59428787	
 512
  64
  64
[torch.LongStorage of size 3]

692616.43899918	
 512
  64
  64
[torch.LongStorage of size 3]

692439.20274734	
 512
  64
  64
[torch.LongStorage of size 3]

692268.71948242	
 512
  64
  64
[torch.LongStorage of size 3]

692098.05370331	
 512
  64
  64
[torch.LongStorage of size 3]

691932.97685623	
 512
  64
  64
[torch.LongStorage of size 3]

691768.32817078	
 512
  64
  64
[torch.LongStorage of size 3]

691606.66118622	
 512
  64
  64
[torch.LongStorage of size 3]

691450.67243576	
 512
  64
  64
[torch.LongStorage of size 3]

691292.31206894	
 512
  64
  64
[torch.LongStorage of size 3]

691121.55700684	
 512
  64
  64
[torch.LongStorage of size 3]

690961.22714996	
 512
  64
  64
[torch.LongStorage of size 3]

690795.4158783	
 512
  64
  64
[torch.LongStorage of size 3]

690657.622509	
 512
  64
  64
[torch.LongStorage of size 3]

690485.94070435	
 512
  64
  64
[torch.LongStorage of size 3]

690318.65558624	
 512
  64
  64
[torch.LongStorage of size 3]

690148.19910049	
 512
  64
  64
[torch.LongStorage of size 3]

689991.99380875	
 512
  64
  64
[torch.LongStorage of size 3]

689834.20404434	
 512
  64
  64
[torch.LongStorage of size 3]

689679.61450577	
 512
  64
  64
[torch.LongStorage of size 3]

689524.15689468	
 512
  64
  64
[torch.LongStorage of size 3]

689371.61752701	
 512
  64
  64
[torch.LongStorage of size 3]

689220.27597427	
 512
  64
  64
[torch.LongStorage of size 3]

689066.93878174	
 512
  64
  64
[torch.LongStorage of size 3]

688911.30722046	
 512
  64
  64
[torch.LongStorage of size 3]

688762.35031128	
 512
  64
  64
[torch.LongStorage of size 3]

688612.66119003	
 512
  64
  64
[torch.LongStorage of size 3]

688474.00989532	
 512
  64
  64
[torch.LongStorage of size 3]

688320.83679199	
 512
  64
  64
[torch.LongStorage of size 3]

688171.54607773	
 512
  64
  64
[torch.LongStorage of size 3]

688009.24858093	
 512
  64
  64
[torch.LongStorage of size 3]

687862.2744751	
 512
  64
  64
[torch.LongStorage of size 3]

687707.11481094	
 512
  64
  64
[torch.LongStorage of size 3]

687555.66585541	
 512
  64
  64
[torch.LongStorage of size 3]

687406.36053085	
 512
  64
  64
[torch.LongStorage of size 3]

687263.67050171	
 512
  64
  64
[torch.LongStorage of size 3]

687109.3800354	
 512
  64
  64
[torch.LongStorage of size 3]

686956.51351929	
 512
  64
  64
[torch.LongStorage of size 3]

686807.85915375	
 512
  64
  64
[torch.LongStorage of size 3]

686668.60740662	
 512
  64
  64
[torch.LongStorage of size 3]

686516.94162369	
 512
  64
  64
[torch.LongStorage of size 3]

686374.66205597	
 512
  64
  64
[torch.LongStorage of size 3]

686231.44081116	
 512
  64
  64
[torch.LongStorage of size 3]

686086.96428299	
 512
  64
  64
[torch.LongStorage of size 3]

685944.73279953	
 512
  64
  64
[torch.LongStorage of size 3]

685798.3313179	
 512
  64
  64
[torch.LongStorage of size 3]

685646.82510376	
 512
  64
  64
[torch.LongStorage of size 3]

685511.68949127	
 512
  64
  64
[torch.LongStorage of size 3]

685370.05689621	
 512
  64
  64
[torch.LongStorage of size 3]

685239.88271713	
 512
  64
  64
[torch.LongStorage of size 3]

685091.63063049	
 512
  64
  64
[torch.LongStorage of size 3]

684956.38406754	
 512
  64
  64
[torch.LongStorage of size 3]

684808.80498886	
 512
  64
  64
[torch.LongStorage of size 3]

684676.48366928	
 512
  64
  64
[torch.LongStorage of size 3]

684522.05791473	
 512
  64
  64
[torch.LongStorage of size 3]

684389.40034866	
 512
  64
  64
[torch.LongStorage of size 3]

684239.25388336	
 512
  64
  64
[torch.LongStorage of size 3]

684100.42697906	
 512
  64
  64
[torch.LongStorage of size 3]

683957.5295639	
 512
  64
  64
[torch.LongStorage of size 3]

683820.6687355	
 512
  64
  64
[torch.LongStorage of size 3]

683679.82479095	
 512
  64
  64
[torch.LongStorage of size 3]

683543.84422302	
 512
  64
  64
[torch.LongStorage of size 3]

683409.44665909	
 512
  64
  64
[torch.LongStorage of size 3]

683274.13288116	
 512
  64
  64
[torch.LongStorage of size 3]

683144.01733398	
 512
  64
  64
[torch.LongStorage of size 3]

683011.24633789	
 512
  64
  64
[torch.LongStorage of size 3]

682879.60187912	
 512
  64
  64
[torch.LongStorage of size 3]

682735.65254211	
 512
  64
  64
[torch.LongStorage of size 3]

682606.21898651	
 512
  64
  64
[torch.LongStorage of size 3]

682466.06445312	
 512
  64
  64
[torch.LongStorage of size 3]

682343.84553909	
 512
  64
  64
[torch.LongStorage of size 3]

682189.1113472	
 512
  64
  64
[torch.LongStorage of size 3]

682066.80904388	
 512
  64
  64
[torch.LongStorage of size 3]

681921.56112671	
 512
  64
  64
[torch.LongStorage of size 3]

681792.02278137	
 512
  64
  64
[torch.LongStorage of size 3]

681655.98642349	
 512
  64
  64
[torch.LongStorage of size 3]

681529.46220398	
 512
  64
  64
[torch.LongStorage of size 3]

681399.6320343	
 512
  64
  64
[torch.LongStorage of size 3]

681267.82850266	
 512
  64
  64
[torch.LongStorage of size 3]

681135.56716919	
 512
  64
  64
[torch.LongStorage of size 3]

681002.29558945	
 512
  64
  64
[torch.LongStorage of size 3]

680866.48664474	
 512
  64
  64
[torch.LongStorage of size 3]

680735.35335541	
 512
  64
  64
[torch.LongStorage of size 3]

680614.02294159	
 512
  64
  64
[torch.LongStorage of size 3]

680474.12530899	
 512
  64
  64
[torch.LongStorage of size 3]

680357.42107391	
 512
  64
  64
[torch.LongStorage of size 3]

680222.68642426	
 512
  64
  64
[torch.LongStorage of size 3]

680101.18110657	
 512
  64
  64
[torch.LongStorage of size 3]

679971.65370941	
 512
  64
  64
[torch.LongStorage of size 3]

679854.38135147	
 512
  64
  64
[torch.LongStorage of size 3]

679725.61639786	
 512
  64
  64
[torch.LongStorage of size 3]

679594.57714081	
 512
  64
  64
[torch.LongStorage of size 3]

679463.751297	
 512
  64
  64
[torch.LongStorage of size 3]

679336.43531799	
 512
  64
  64
[torch.LongStorage of size 3]

679204.43813324	
 512
  64
  64
[torch.LongStorage of size 3]

679075.77075958	
 512
  64
  64
[torch.LongStorage of size 3]

678946.25658035	
 512
  64
  64
[torch.LongStorage of size 3]

678817.82791138	
 512
  64
  64
[torch.LongStorage of size 3]

678685.18262863	
 512
  64
  64
[torch.LongStorage of size 3]

678565.10099411	
 512
  64
  64
[torch.LongStorage of size 3]

678427.92701721	
 512
  64
  64
[torch.LongStorage of size 3]

678314.57624435	
 512
  64
  64
[torch.LongStorage of size 3]

678168.4419632	
 512
  64
  64
[torch.LongStorage of size 3]

678047.89815903	
 512
  64
  64
[torch.LongStorage of size 3]

677906.9572258	
 512
  64
  64
[torch.LongStorage of size 3]

677780.20433426	
 512
  64
  64
[torch.LongStorage of size 3]

677645.04922867	
 512
  64
  64
[torch.LongStorage of size 3]

677518.32643509	
 512
  64
  64
[torch.LongStorage of size 3]

677377.2193718	
 512
  64
  64
[torch.LongStorage of size 3]

677249.00766373	
 512
  64
  64
[torch.LongStorage of size 3]

677119.40633774	
 512
  64
  64
[torch.LongStorage of size 3]

676987.49900818	
 512
  64
  64
[torch.LongStorage of size 3]

676863.99860382	
 512
  64
  64
[torch.LongStorage of size 3]

676723.78847122	
 512
  64
  64
[torch.LongStorage of size 3]

676606.82823181	
 512
  64
  64
[torch.LongStorage of size 3]

676467.07429886	
 512
  64
  64
[torch.LongStorage of size 3]

676349.61244583	
 512
  64
  64
[torch.LongStorage of size 3]

676213.90396118	
 512
  64
  64
[torch.LongStorage of size 3]

676090.19119263	
 512
  64
  64
[torch.LongStorage of size 3]

675963.41415405	
 512
  64
  64
[torch.LongStorage of size 3]

675841.27401352	
 512
  64
  64
[torch.LongStorage of size 3]

675722.66336441	
 512
  64
  64
[torch.LongStorage of size 3]

675599.73150253	
 512
  64
  64
[torch.LongStorage of size 3]

675474.17463303	
 512
  64
  64
[torch.LongStorage of size 3]

675351.00416183	
 512
  64
  64
[torch.LongStorage of size 3]

675233.07729721	
 512
  64
  64
[torch.LongStorage of size 3]

675105.13319016	
 512
  64
  64
[torch.LongStorage of size 3]

674992.21469879	
 512
  64
  64
[torch.LongStorage of size 3]

674868.56868744	
 512
  64
  64
[torch.LongStorage of size 3]

674754.11798477	
 512
  64
  64
[torch.LongStorage of size 3]

674631.38898849	
 512
  64
  64
[torch.LongStorage of size 3]

674520.94120026	
 512
  64
  64
[torch.LongStorage of size 3]

674398.25498581	
 512
  64
  64
[torch.LongStorage of size 3]

674289.10238266	
 512
  64
  64
[torch.LongStorage of size 3]

674172.06548691	
 512
  64
  64
[torch.LongStorage of size 3]

674059.89870071	
 512
  64
  64
[torch.LongStorage of size 3]

673942.97716141	
 512
  64
  64
[torch.LongStorage of size 3]

673834.11178589	
 512
  64
  64
[torch.LongStorage of size 3]

673717.11612701	
 512
  64
  64
[torch.LongStorage of size 3]

673612.32789993	
 512
  64
  64
[torch.LongStorage of size 3]

673496.80837631	
 512
  64
  64
[torch.LongStorage of size 3]

673393.34461212	
 512
  64
  64
[torch.LongStorage of size 3]

673272.27369308	
 512
  64
  64
[torch.LongStorage of size 3]

673171.84141159	
 512
  64
  64
[torch.LongStorage of size 3]

673047.43747711	
 512
  64
  64
[torch.LongStorage of size 3]

672939.70283508	
 512
  64
  64
[torch.LongStorage of size 3]

672812.63252258	
 512
  64
  64
[torch.LongStorage of size 3]

672705.3771019	
 512
  64
  64
[torch.LongStorage of size 3]

672588.90769958	
 512
  64
  64
[torch.LongStorage of size 3]

672477.55788803	
 512
  64
  64
[torch.LongStorage of size 3]

672357.91599274	
 512
  64
  64
[torch.LongStorage of size 3]

672242.37297058	
 512
  64
  64
[torch.LongStorage of size 3]

672129.70939636	
 512
  64
  64
[torch.LongStorage of size 3]

672013.50719452	
 512
  64
  64
[torch.LongStorage of size 3]

671900.63041687	
 512
  64
  64
[torch.LongStorage of size 3]

671789.90463257	
 512
  64
  64
[torch.LongStorage of size 3]

671675.47374725	
 512
  64
  64
[torch.LongStorage of size 3]

671567.22394943	
 512
  64
  64
[torch.LongStorage of size 3]

671455.9727478	
 512
  64
  64
[torch.LongStorage of size 3]

671343.99618149	
 512
  64
  64
[torch.LongStorage of size 3]

671226.30298615	
 512
  64
  64
[torch.LongStorage of size 3]

671132.54274368	
 512
  64
  64
[torch.LongStorage of size 3]

671003.61946106	
 512
  64
  64
[torch.LongStorage of size 3]

670915.46895981	
 512
  64
  64
[torch.LongStorage of size 3]

670778.01023483	
 512
  64
  64
[torch.LongStorage of size 3]

670667.4230957	
 512
  64
  64
[torch.LongStorage of size 3]

670563.54253769	
 512
  64
  64
[torch.LongStorage of size 3]

670451.29079819	
 512
  64
  64
[torch.LongStorage of size 3]

670336.05495453	
 512
  64
  64
[torch.LongStorage of size 3]

670223.32895279	
 512
  64
  64
[torch.LongStorage of size 3]

670111.33615494	
 512
  64
  64
[torch.LongStorage of size 3]

670003.87149811	
 512
  64
  64
[torch.LongStorage of size 3]

669899.24049377	
 512
  64
  64
[torch.LongStorage of size 3]

669797.71297455	
 512
  64
  64
[torch.LongStorage of size 3]

669690.40430069	
 512
  64
  64
[torch.LongStorage of size 3]

669586.75209045	
 512
  64
  64
[torch.LongStorage of size 3]

669488.59985352	
 512
  64
  64
[torch.LongStorage of size 3]

669381.78525925	
 512
  64
  64
[torch.LongStorage of size 3]

669283.68263245	
 512
  64
  64
[torch.LongStorage of size 3]

669174.19467926	
 512
  64
  64
[torch.LongStorage of size 3]

669081.2270546	
 512
  64
  64
[torch.LongStorage of size 3]

668967.57822037	
 512
  64
  64
[torch.LongStorage of size 3]

668871.71323776	
 512
  64
  64
[torch.LongStorage of size 3]

668761.40844345	
 512
  64
  64
[torch.LongStorage of size 3]

668655.80102921	
 512
  64
  64
[torch.LongStorage of size 3]

668553.48556519	
 512
  64
  64
[torch.LongStorage of size 3]

668449.57712173	
 512
  64
  64
[torch.LongStorage of size 3]

668342.88560867	
 512
  64
  64
[torch.LongStorage of size 3]

668240.94429016	
 512
  64
  64
[torch.LongStorage of size 3]

668139.14686203	
 512
  64
  64
[torch.LongStorage of size 3]

668045.59738159	
 512
  64
  64
[torch.LongStorage of size 3]

667936.47266388	
 512
  64
  64
[torch.LongStorage of size 3]

667850.49121857	
 512
  64
  64
[torch.LongStorage of size 3]

667743.91828537	
 512
  64
  64
[torch.LongStorage of size 3]

667646.21385574	
 512
  64
  64
[torch.LongStorage of size 3]

667544.36450958	
 512
  64
  64
[torch.LongStorage of size 3]

667451.22468948	
 512
  64
  64
[torch.LongStorage of size 3]

667352.52008438	
 512
  64
  64
[torch.LongStorage of size 3]

667263.82341385	
 512
  64
  64
[torch.LongStorage of size 3]

667161.02043152	
 512
  64
  64
[torch.LongStorage of size 3]

667079.43008423	
 512
  64
  64
[torch.LongStorage of size 3]

666979.94251251	
 512
  64
  64
[torch.LongStorage of size 3]

666894.11319733	
 512
  64
  64
[torch.LongStorage of size 3]

666794.55663681	
 512
  64
  64
[torch.LongStorage of size 3]

666711.57255173	
 512
  64
  64
[torch.LongStorage of size 3]

666607.52040863	
 512
  64
  64
[torch.LongStorage of size 3]

666521.58401489	
 512
  64
  64
[torch.LongStorage of size 3]

666426.65103912	
 512
  64
  64
[torch.LongStorage of size 3]

666341.43693924	
 512
  64
  64
[torch.LongStorage of size 3]

666240.20090103	
 512
  64
  64
[torch.LongStorage of size 3]

666153.7906456	
 512
  64
  64
[torch.LongStorage of size 3]

666057.76309967	
 512
  64
  64
[torch.LongStorage of size 3]

665969.48074341	
 512
  64
  64
[torch.LongStorage of size 3]

665877.48794556	
 512
  64
  64
[torch.LongStorage of size 3]

665793.60363007	
 512
  64
  64
[torch.LongStorage of size 3]

665699.46886063	
 512
  64
  64
[torch.LongStorage of size 3]

665612.48718262	
 512
  64
  64
[torch.LongStorage of size 3]

665519.2445755	
 512
  64
  64
[torch.LongStorage of size 3]

665432.87092209	
 512
  64
  64
[torch.LongStorage of size 3]

665338.62243652	
 512
  64
  64
[torch.LongStorage of size 3]

665255.58124542	
 512
  64
  64
[torch.LongStorage of size 3]

665170.72795868	
 512
  64
  64
[torch.LongStorage of size 3]

665086.22728348	
 512
  64
  64
[torch.LongStorage of size 3]

664991.58430099	
 512
  64
  64
[torch.LongStorage of size 3]

664909.00014877	
 512
  64
  64
[torch.LongStorage of size 3]

664813.3518219	
 512
  64
  64
[torch.LongStorage of size 3]

664729.58070755	
 512
  64
  64
[torch.LongStorage of size 3]

664639.32376862	
 512
  64
  64
[torch.LongStorage of size 3]

664559.11899567	
 512
  64
  64
[torch.LongStorage of size 3]

664459.86675262	
 512
  64
  64
[torch.LongStorage of size 3]

664383.55804443	
 512
  64
  64
[torch.LongStorage of size 3]

664282.247715	
 512
  64
  64
[torch.LongStorage of size 3]

664202.34716415	
 512
  64
  64
[torch.LongStorage of size 3]

664105.32060623	
 512
  64
  64
[torch.LongStorage of size 3]

664023.61446381	
 512
  64
  64
[torch.LongStorage of size 3]

663937.49658585	
 512
  64
  64
[torch.LongStorage of size 3]

663857.48180389	
 512
  64
  64
[torch.LongStorage of size 3]

663778.67118835	
 512
  64
  64
[torch.LongStorage of size 3]

663690.97856522	
 512
  64
  64
[torch.LongStorage of size 3]

663607.0917511	
 512
  64
  64
[torch.LongStorage of size 3]

663523.44135284	
 512
  64
  64
[torch.LongStorage of size 3]

663442.85022736	
 512
  64
  64
[torch.LongStorage of size 3]

663361.32919312	
 512
  64
  64
[torch.LongStorage of size 3]

663275.58280945	
 512
  64
  64
[torch.LongStorage of size 3]

663198.18193436	
 512
  64
  64
[torch.LongStorage of size 3]

663116.57299042	
 512
  64
  64
[torch.LongStorage of size 3]

663046.45572662	
 512
  64
  64
[torch.LongStorage of size 3]

662958.37921143	
 512
  64
  64
[torch.LongStorage of size 3]

662882.68861771	
 512
  64
  64
[torch.LongStorage of size 3]

662793.49946976	
 512
  64
  64
[torch.LongStorage of size 3]

662715.76921463	
 512
  64
  64
[torch.LongStorage of size 3]

662629.98199463	
 512
  64
  64
[torch.LongStorage of size 3]

662556.43281937	
 512
  64
  64
[torch.LongStorage of size 3]

662471.24441147	
 512
  64
  64
[torch.LongStorage of size 3]

662394.19181824	
 512
  64
  64
[torch.LongStorage of size 3]

662302.30770111	
 512
  64
  64
[torch.LongStorage of size 3]

662233.25284958	
 512
  64
  64
[torch.LongStorage of size 3]

662144.9090004	
 512
  64
  64
[torch.LongStorage of size 3]

662069.90215302	
 512
  64
  64
[torch.LongStorage of size 3]

661989.69566345	
 512
  64
  64
[torch.LongStorage of size 3]

661914.05845642	
 512
  64
  64
[torch.LongStorage of size 3]

661834.90856171	
 512
  64
  64
[torch.LongStorage of size 3]

661760.94079971	
 512
  64
  64
[torch.LongStorage of size 3]

661685.20292282	
 512
  64
  64
[torch.LongStorage of size 3]

661611.87602997	
 512
  64
  64
[torch.LongStorage of size 3]

661539.50305939	
 512
  64
  64
[torch.LongStorage of size 3]

661464.85527039	
 512
  64
  64
[torch.LongStorage of size 3]

661389.37618256	
 512
  64
  64
[torch.LongStorage of size 3]

661309.78841782	
 512
  64
  64
[torch.LongStorage of size 3]

661236.68434143	
 512
  64
  64
[torch.LongStorage of size 3]

661159.94560242	
 512
  64
  64
[torch.LongStorage of size 3]

661086.07397079	
 512
  64
  64
[torch.LongStorage of size 3]

661003.55642319	
 512
  64
  64
[torch.LongStorage of size 3]

660935.34065247	
 512
  64
  64
[torch.LongStorage of size 3]

660851.33634567	
 512
  64
  64
[torch.LongStorage of size 3]

660791.79590225	
 512
  64
  64
[torch.LongStorage of size 3]

660699.884758	
 512
  64
  64
[torch.LongStorage of size 3]

660631.39795303	
 512
  64
  64
[torch.LongStorage of size 3]

660545.38454056	
 512
  64
  64
[torch.LongStorage of size 3]

660468.59851837	
 512
  64
  64
[torch.LongStorage of size 3]

660398.09638977	
 512
  64
  64
[torch.LongStorage of size 3]

660320.20620346	
 512
  64
  64
[torch.LongStorage of size 3]

660249.96917725	
 512
  64
  64
[torch.LongStorage of size 3]

660174.67407227	
 512
  64
  64
[torch.LongStorage of size 3]

660097.10580826	
 512
  64
  64
[torch.LongStorage of size 3]

660023.75379562	
 512
  64
  64
[torch.LongStorage of size 3]

659948.81511688	
 512
  64
  64
[torch.LongStorage of size 3]

659879.67193604	
 512
  64
  64
[torch.LongStorage of size 3]

659800.47292709	
 512
  64
  64
[torch.LongStorage of size 3]

659731.34395599	
 512
  64
  64
[torch.LongStorage of size 3]

659654.79341507	
 512
  64
  64
[torch.LongStorage of size 3]

659583.02009583	
 512
  64
  64
[torch.LongStorage of size 3]

659508.52836609	
 512
  64
  64
[torch.LongStorage of size 3]

659438.26143265	
 512
  64
  64
[torch.LongStorage of size 3]

659366.12844467	
 512
  64
  64
[torch.LongStorage of size 3]

659293.43790054	
 512
  64
  64
[torch.LongStorage of size 3]

659219.4436264	
 512
  64
  64
[torch.LongStorage of size 3]

659146.73055649	
 512
  64
  64
[torch.LongStorage of size 3]

659070.79278946	
 512
  64
  64
[torch.LongStorage of size 3]

658997.94120789	
 512
  64
  64
[torch.LongStorage of size 3]

658925.44773102	
 512
  64
  64
[torch.LongStorage of size 3]

658852.55037308	
 512
  64
  64
[torch.LongStorage of size 3]

658775.1496315	
 512
  64
  64
[torch.LongStorage of size 3]

658707.0110321	
 512
  64
  64
[torch.LongStorage of size 3]

658626.32541656	
 512
  64
  64
[torch.LongStorage of size 3]

658567.05036163	
 512
  64
  64
[torch.LongStorage of size 3]

658474.89368439	
 512
  64
  64
[torch.LongStorage of size 3]

658409.65108871	
 512
  64
  64
[torch.LongStorage of size 3]

658327.50391006	
 512
  64
  64
[torch.LongStorage of size 3]

658255.75237274	
 512
  64
  64
[torch.LongStorage of size 3]

658183.4838295	
 512
  64
  64
[torch.LongStorage of size 3]

658110.65851212	
 512
  64
  64
[torch.LongStorage of size 3]

658041.51607513	
 512
  64
  64
[torch.LongStorage of size 3]

657970.19504547	
 512
  64
  64
[torch.LongStorage of size 3]

657900.82386017	
 512
  64
  64
[torch.LongStorage of size 3]

657828.2601738	
 512
  64
  64
[torch.LongStorage of size 3]

657757.19047546	
 512
  64
  64
[torch.LongStorage of size 3]

657686.64440155	
Iteration 999 / 1000	
  Content 1 loss: 502773.789062	
  Style 1 loss: 976.406765	
  Style 2 loss: 11827.675629	
  Style 3 loss: 13461.814880	
  Style 4 loss: 127584.545898	
  Style 5 loss: 1062.412167	
  Total loss: 657686.644402	
s/askrxffeqxoy.png_out_prepost_999.png	
 512
  64
  64
[torch.LongStorage of size 3]

657618.25019836	
s/askrxffeqxoy.png_out_prepost_1000.png	
<optim.lbfgs> 	reached max number of iterations	
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0804 19:51:52.394088 14035 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0804 19:51:52.394152 14035 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0804 19:51:52.394163 14035 _caffe.cpp:142] Net('./zhang/colorization/models/colorization_deploy_v2.prototxt', 1, weights='./zhang/colorization/models/colorization_release_v2.caffemodel')
I0804 19:51:52.395819 14035 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_deploy_v2.prototxt
I0804 19:51:52.395844 14035 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 19:51:52.396109 14035 net.cpp:51] Initializing net from parameters: 
name: "LtoAB"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data_l"
  type: "Input"
  top: "data_l"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "bw_conv1_1"
  type: "Convolution"
  bottom: "data_l"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_2norm"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_2norm"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_2norm"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_2norm"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_3norm"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_3norm"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_3norm"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_3norm"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_3norm"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_3norm"
  top: "conv6_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv6_3"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "conv6_3"
  top: "conv6_3"
}
layer {
  name: "conv6_3norm"
  type: "BatchNorm"
  bottom: "conv6_3"
  top: "conv6_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_3norm"
  top: "conv7_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv7_3"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "conv7_3"
  top: "conv7_3"
}
layer {
  name: "conv7_3norm"
  type: "BatchNorm"
  bottom: "conv7_3"
  top: "conv7_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv8_1"
  type: "Deconvolution"
  bottom: "conv7_3norm"
  top: "conv8_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    stride: 2
    dilation: 1
  }
}
layer {
  name: "relu8_1"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_2"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv8_3"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_3"
  type: "ReLU"
  bottom: "conv8_3"
  top: "conv8_3"
}
layer {
  name: "conv8_313"
  type: "Convolution"
  bottom: "conv8_3"
  top: "conv8_313"
  convolution_param {
    num_output: 313
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv8_313_rh"
  type: "Scale"
  bottom: "conv8_313"
  top: "conv8_313_rh"
  scale_param {
    filler {
      type: "constant"
      value: 2.606
    }
    bias_term: false
  }
}
layer {
  name: "class8_313_rh"
  type: "Softmax"
  bottom: "conv8_313_rh"
  top: "class8_313_rh"
}
layer {
  name: "class8_ab"
  type: "Convolution"
  bottom: "class8_313_rh"
  top: "class8_ab"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "Silence"
  type: "Silence"
  bottom: "class8_ab"
}
I0804 19:51:52.396282 14035 layer_factory.hpp:77] Creating layer data_l
I0804 19:51:52.396302 14035 net.cpp:84] Creating Layer data_l
I0804 19:51:52.396315 14035 net.cpp:380] data_l -> data_l
I0804 19:51:52.406592 14035 net.cpp:122] Setting up data_l
I0804 19:51:52.406636 14035 net.cpp:129] Top shape: 1 1 224 224 (50176)
I0804 19:51:52.406648 14035 net.cpp:137] Memory required for data: 200704
I0804 19:51:52.406661 14035 layer_factory.hpp:77] Creating layer bw_conv1_1
I0804 19:51:52.406682 14035 net.cpp:84] Creating Layer bw_conv1_1
I0804 19:51:52.406694 14035 net.cpp:406] bw_conv1_1 <- data_l
I0804 19:51:52.406708 14035 net.cpp:380] bw_conv1_1 -> conv1_1
I0804 19:51:52.408609 14035 net.cpp:122] Setting up bw_conv1_1
I0804 19:51:52.408639 14035 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 19:51:52.408650 14035 net.cpp:137] Memory required for data: 13045760
I0804 19:51:52.408669 14035 layer_factory.hpp:77] Creating layer relu1_1
I0804 19:51:52.408687 14035 net.cpp:84] Creating Layer relu1_1
I0804 19:51:52.408699 14035 net.cpp:406] relu1_1 <- conv1_1
I0804 19:51:52.408710 14035 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0804 19:51:52.408725 14035 net.cpp:122] Setting up relu1_1
I0804 19:51:52.408737 14035 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 19:51:52.408747 14035 net.cpp:137] Memory required for data: 25890816
I0804 19:51:52.408758 14035 layer_factory.hpp:77] Creating layer conv1_2
I0804 19:51:52.408774 14035 net.cpp:84] Creating Layer conv1_2
I0804 19:51:52.408784 14035 net.cpp:406] conv1_2 <- conv1_1
I0804 19:51:52.408797 14035 net.cpp:380] conv1_2 -> conv1_2
I0804 19:51:52.409889 14035 net.cpp:122] Setting up conv1_2
I0804 19:51:52.409915 14035 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 19:51:52.409927 14035 net.cpp:137] Memory required for data: 29102080
I0804 19:51:52.409960 14035 layer_factory.hpp:77] Creating layer relu1_2
I0804 19:51:52.409977 14035 net.cpp:84] Creating Layer relu1_2
I0804 19:51:52.409988 14035 net.cpp:406] relu1_2 <- conv1_2
I0804 19:51:52.410001 14035 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0804 19:51:52.410014 14035 net.cpp:122] Setting up relu1_2
I0804 19:51:52.410027 14035 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 19:51:52.410037 14035 net.cpp:137] Memory required for data: 32313344
I0804 19:51:52.410048 14035 layer_factory.hpp:77] Creating layer conv1_2norm
I0804 19:51:52.410063 14035 net.cpp:84] Creating Layer conv1_2norm
I0804 19:51:52.410074 14035 net.cpp:406] conv1_2norm <- conv1_2
I0804 19:51:52.410087 14035 net.cpp:380] conv1_2norm -> conv1_2norm
I0804 19:51:52.410289 14035 net.cpp:122] Setting up conv1_2norm
I0804 19:51:52.410302 14035 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 19:51:52.410313 14035 net.cpp:137] Memory required for data: 35524608
I0804 19:51:52.410331 14035 layer_factory.hpp:77] Creating layer conv2_1
I0804 19:51:52.410346 14035 net.cpp:84] Creating Layer conv2_1
I0804 19:51:52.410357 14035 net.cpp:406] conv2_1 <- conv1_2norm
I0804 19:51:52.410369 14035 net.cpp:380] conv2_1 -> conv2_1
I0804 19:51:52.411459 14035 net.cpp:122] Setting up conv2_1
I0804 19:51:52.411483 14035 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 19:51:52.411494 14035 net.cpp:137] Memory required for data: 41947136
I0804 19:51:52.411509 14035 layer_factory.hpp:77] Creating layer relu2_1
I0804 19:51:52.411525 14035 net.cpp:84] Creating Layer relu2_1
I0804 19:51:52.411536 14035 net.cpp:406] relu2_1 <- conv2_1
I0804 19:51:52.411548 14035 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0804 19:51:52.411562 14035 net.cpp:122] Setting up relu2_1
I0804 19:51:52.411574 14035 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 19:51:52.411584 14035 net.cpp:137] Memory required for data: 48369664
I0804 19:51:52.411594 14035 layer_factory.hpp:77] Creating layer conv2_2
I0804 19:51:52.411610 14035 net.cpp:84] Creating Layer conv2_2
I0804 19:51:52.411622 14035 net.cpp:406] conv2_2 <- conv2_1
I0804 19:51:52.411634 14035 net.cpp:380] conv2_2 -> conv2_2
I0804 19:51:52.412775 14035 net.cpp:122] Setting up conv2_2
I0804 19:51:52.412797 14035 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 19:51:52.412809 14035 net.cpp:137] Memory required for data: 49975296
I0804 19:51:52.412823 14035 layer_factory.hpp:77] Creating layer relu2_2
I0804 19:51:52.412837 14035 net.cpp:84] Creating Layer relu2_2
I0804 19:51:52.412847 14035 net.cpp:406] relu2_2 <- conv2_2
I0804 19:51:52.412861 14035 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0804 19:51:52.412875 14035 net.cpp:122] Setting up relu2_2
I0804 19:51:52.412888 14035 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 19:51:52.412897 14035 net.cpp:137] Memory required for data: 51580928
I0804 19:51:52.412907 14035 layer_factory.hpp:77] Creating layer conv2_2norm
I0804 19:51:52.412920 14035 net.cpp:84] Creating Layer conv2_2norm
I0804 19:51:52.412931 14035 net.cpp:406] conv2_2norm <- conv2_2
I0804 19:51:52.412945 14035 net.cpp:380] conv2_2norm -> conv2_2norm
I0804 19:51:52.413151 14035 net.cpp:122] Setting up conv2_2norm
I0804 19:51:52.413170 14035 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 19:51:52.413182 14035 net.cpp:137] Memory required for data: 53186560
I0804 19:51:52.413197 14035 layer_factory.hpp:77] Creating layer conv3_1
I0804 19:51:52.413211 14035 net.cpp:84] Creating Layer conv3_1
I0804 19:51:52.413223 14035 net.cpp:406] conv3_1 <- conv2_2norm
I0804 19:51:52.413235 14035 net.cpp:380] conv3_1 -> conv3_1
I0804 19:51:52.413661 14035 net.cpp:122] Setting up conv3_1
I0804 19:51:52.413676 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.413686 14035 net.cpp:137] Memory required for data: 56397824
I0804 19:51:52.413699 14035 layer_factory.hpp:77] Creating layer relu3_1
I0804 19:51:52.413712 14035 net.cpp:84] Creating Layer relu3_1
I0804 19:51:52.413722 14035 net.cpp:406] relu3_1 <- conv3_1
I0804 19:51:52.413738 14035 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0804 19:51:52.413769 14035 net.cpp:122] Setting up relu3_1
I0804 19:51:52.413781 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.413792 14035 net.cpp:137] Memory required for data: 59609088
I0804 19:51:52.413802 14035 layer_factory.hpp:77] Creating layer conv3_2
I0804 19:51:52.413815 14035 net.cpp:84] Creating Layer conv3_2
I0804 19:51:52.413827 14035 net.cpp:406] conv3_2 <- conv3_1
I0804 19:51:52.413841 14035 net.cpp:380] conv3_2 -> conv3_2
I0804 19:51:52.415386 14035 net.cpp:122] Setting up conv3_2
I0804 19:51:52.415411 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.415422 14035 net.cpp:137] Memory required for data: 62820352
I0804 19:51:52.415439 14035 layer_factory.hpp:77] Creating layer relu3_2
I0804 19:51:52.415455 14035 net.cpp:84] Creating Layer relu3_2
I0804 19:51:52.415467 14035 net.cpp:406] relu3_2 <- conv3_2
I0804 19:51:52.415478 14035 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0804 19:51:52.415493 14035 net.cpp:122] Setting up relu3_2
I0804 19:51:52.415504 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.415514 14035 net.cpp:137] Memory required for data: 66031616
I0804 19:51:52.415524 14035 layer_factory.hpp:77] Creating layer conv3_3
I0804 19:51:52.415539 14035 net.cpp:84] Creating Layer conv3_3
I0804 19:51:52.415550 14035 net.cpp:406] conv3_3 <- conv3_2
I0804 19:51:52.415562 14035 net.cpp:380] conv3_3 -> conv3_3
I0804 19:51:52.417188 14035 net.cpp:122] Setting up conv3_3
I0804 19:51:52.417227 14035 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 19:51:52.417237 14035 net.cpp:137] Memory required for data: 66834432
I0804 19:51:52.417253 14035 layer_factory.hpp:77] Creating layer relu3_3
I0804 19:51:52.417270 14035 net.cpp:84] Creating Layer relu3_3
I0804 19:51:52.417281 14035 net.cpp:406] relu3_3 <- conv3_3
I0804 19:51:52.417294 14035 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0804 19:51:52.417309 14035 net.cpp:122] Setting up relu3_3
I0804 19:51:52.417321 14035 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 19:51:52.417331 14035 net.cpp:137] Memory required for data: 67637248
I0804 19:51:52.417341 14035 layer_factory.hpp:77] Creating layer conv3_3norm
I0804 19:51:52.417357 14035 net.cpp:84] Creating Layer conv3_3norm
I0804 19:51:52.417367 14035 net.cpp:406] conv3_3norm <- conv3_3
I0804 19:51:52.417381 14035 net.cpp:380] conv3_3norm -> conv3_3norm
I0804 19:51:52.417582 14035 net.cpp:122] Setting up conv3_3norm
I0804 19:51:52.417596 14035 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 19:51:52.417608 14035 net.cpp:137] Memory required for data: 68440064
I0804 19:51:52.417623 14035 layer_factory.hpp:77] Creating layer conv4_1
I0804 19:51:52.417637 14035 net.cpp:84] Creating Layer conv4_1
I0804 19:51:52.417649 14035 net.cpp:406] conv4_1 <- conv3_3norm
I0804 19:51:52.417665 14035 net.cpp:380] conv4_1 -> conv4_1
I0804 19:51:52.420441 14035 net.cpp:122] Setting up conv4_1
I0804 19:51:52.420481 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.420492 14035 net.cpp:137] Memory required for data: 70045696
I0804 19:51:52.420508 14035 layer_factory.hpp:77] Creating layer relu4_1
I0804 19:51:52.420524 14035 net.cpp:84] Creating Layer relu4_1
I0804 19:51:52.420536 14035 net.cpp:406] relu4_1 <- conv4_1
I0804 19:51:52.420550 14035 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0804 19:51:52.420565 14035 net.cpp:122] Setting up relu4_1
I0804 19:51:52.420578 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.420588 14035 net.cpp:137] Memory required for data: 71651328
I0804 19:51:52.420598 14035 layer_factory.hpp:77] Creating layer conv4_2
I0804 19:51:52.420613 14035 net.cpp:84] Creating Layer conv4_2
I0804 19:51:52.420624 14035 net.cpp:406] conv4_2 <- conv4_1
I0804 19:51:52.420637 14035 net.cpp:380] conv4_2 -> conv4_2
I0804 19:51:52.425671 14035 net.cpp:122] Setting up conv4_2
I0804 19:51:52.425716 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.425727 14035 net.cpp:137] Memory required for data: 73256960
I0804 19:51:52.425743 14035 layer_factory.hpp:77] Creating layer relu4_2
I0804 19:51:52.425761 14035 net.cpp:84] Creating Layer relu4_2
I0804 19:51:52.425789 14035 net.cpp:406] relu4_2 <- conv4_2
I0804 19:51:52.425802 14035 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0804 19:51:52.425817 14035 net.cpp:122] Setting up relu4_2
I0804 19:51:52.425829 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.425839 14035 net.cpp:137] Memory required for data: 74862592
I0804 19:51:52.425850 14035 layer_factory.hpp:77] Creating layer conv4_3
I0804 19:51:52.425869 14035 net.cpp:84] Creating Layer conv4_3
I0804 19:51:52.425880 14035 net.cpp:406] conv4_3 <- conv4_2
I0804 19:51:52.425894 14035 net.cpp:380] conv4_3 -> conv4_3
I0804 19:51:52.430963 14035 net.cpp:122] Setting up conv4_3
I0804 19:51:52.431010 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.431022 14035 net.cpp:137] Memory required for data: 76468224
I0804 19:51:52.431038 14035 layer_factory.hpp:77] Creating layer relu4_3
I0804 19:51:52.431057 14035 net.cpp:84] Creating Layer relu4_3
I0804 19:51:52.431068 14035 net.cpp:406] relu4_3 <- conv4_3
I0804 19:51:52.431082 14035 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0804 19:51:52.431097 14035 net.cpp:122] Setting up relu4_3
I0804 19:51:52.431108 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.431119 14035 net.cpp:137] Memory required for data: 78073856
I0804 19:51:52.431129 14035 layer_factory.hpp:77] Creating layer conv4_3norm
I0804 19:51:52.431145 14035 net.cpp:84] Creating Layer conv4_3norm
I0804 19:51:52.431155 14035 net.cpp:406] conv4_3norm <- conv4_3
I0804 19:51:52.431169 14035 net.cpp:380] conv4_3norm -> conv4_3norm
I0804 19:51:52.431381 14035 net.cpp:122] Setting up conv4_3norm
I0804 19:51:52.431396 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.431407 14035 net.cpp:137] Memory required for data: 79679488
I0804 19:51:52.431422 14035 layer_factory.hpp:77] Creating layer conv5_1
I0804 19:51:52.431437 14035 net.cpp:84] Creating Layer conv5_1
I0804 19:51:52.431448 14035 net.cpp:406] conv5_1 <- conv4_3norm
I0804 19:51:52.431463 14035 net.cpp:380] conv5_1 -> conv5_1
I0804 19:51:52.436480 14035 net.cpp:122] Setting up conv5_1
I0804 19:51:52.436528 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.436539 14035 net.cpp:137] Memory required for data: 81285120
I0804 19:51:52.436563 14035 layer_factory.hpp:77] Creating layer relu5_1
I0804 19:51:52.436578 14035 net.cpp:84] Creating Layer relu5_1
I0804 19:51:52.436590 14035 net.cpp:406] relu5_1 <- conv5_1
I0804 19:51:52.436607 14035 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0804 19:51:52.436624 14035 net.cpp:122] Setting up relu5_1
I0804 19:51:52.436635 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.436645 14035 net.cpp:137] Memory required for data: 82890752
I0804 19:51:52.436655 14035 layer_factory.hpp:77] Creating layer conv5_2
I0804 19:51:52.436671 14035 net.cpp:84] Creating Layer conv5_2
I0804 19:51:52.436681 14035 net.cpp:406] conv5_2 <- conv5_1
I0804 19:51:52.436697 14035 net.cpp:380] conv5_2 -> conv5_2
I0804 19:51:52.441773 14035 net.cpp:122] Setting up conv5_2
I0804 19:51:52.441819 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.441831 14035 net.cpp:137] Memory required for data: 84496384
I0804 19:51:52.441846 14035 layer_factory.hpp:77] Creating layer relu5_2
I0804 19:51:52.441864 14035 net.cpp:84] Creating Layer relu5_2
I0804 19:51:52.441874 14035 net.cpp:406] relu5_2 <- conv5_2
I0804 19:51:52.441890 14035 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0804 19:51:52.441905 14035 net.cpp:122] Setting up relu5_2
I0804 19:51:52.441915 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.441926 14035 net.cpp:137] Memory required for data: 86102016
I0804 19:51:52.441936 14035 layer_factory.hpp:77] Creating layer conv5_3
I0804 19:51:52.441952 14035 net.cpp:84] Creating Layer conv5_3
I0804 19:51:52.441963 14035 net.cpp:406] conv5_3 <- conv5_2
I0804 19:51:52.441975 14035 net.cpp:380] conv5_3 -> conv5_3
I0804 19:51:52.446918 14035 net.cpp:122] Setting up conv5_3
I0804 19:51:52.446962 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.446990 14035 net.cpp:137] Memory required for data: 87707648
I0804 19:51:52.447006 14035 layer_factory.hpp:77] Creating layer relu5_3
I0804 19:51:52.447023 14035 net.cpp:84] Creating Layer relu5_3
I0804 19:51:52.447036 14035 net.cpp:406] relu5_3 <- conv5_3
I0804 19:51:52.447047 14035 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0804 19:51:52.447067 14035 net.cpp:122] Setting up relu5_3
I0804 19:51:52.447078 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.447089 14035 net.cpp:137] Memory required for data: 89313280
I0804 19:51:52.447099 14035 layer_factory.hpp:77] Creating layer conv5_3norm
I0804 19:51:52.447113 14035 net.cpp:84] Creating Layer conv5_3norm
I0804 19:51:52.447124 14035 net.cpp:406] conv5_3norm <- conv5_3
I0804 19:51:52.447139 14035 net.cpp:380] conv5_3norm -> conv5_3norm
I0804 19:51:52.447343 14035 net.cpp:122] Setting up conv5_3norm
I0804 19:51:52.447357 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.447368 14035 net.cpp:137] Memory required for data: 90918912
I0804 19:51:52.447383 14035 layer_factory.hpp:77] Creating layer conv6_1
I0804 19:51:52.447402 14035 net.cpp:84] Creating Layer conv6_1
I0804 19:51:52.447413 14035 net.cpp:406] conv6_1 <- conv5_3norm
I0804 19:51:52.447425 14035 net.cpp:380] conv6_1 -> conv6_1
I0804 19:51:52.452284 14035 net.cpp:122] Setting up conv6_1
I0804 19:51:52.452330 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.452342 14035 net.cpp:137] Memory required for data: 92524544
I0804 19:51:52.452358 14035 layer_factory.hpp:77] Creating layer relu6_1
I0804 19:51:52.452374 14035 net.cpp:84] Creating Layer relu6_1
I0804 19:51:52.452385 14035 net.cpp:406] relu6_1 <- conv6_1
I0804 19:51:52.452400 14035 net.cpp:367] relu6_1 -> conv6_1 (in-place)
I0804 19:51:52.452415 14035 net.cpp:122] Setting up relu6_1
I0804 19:51:52.452427 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.452437 14035 net.cpp:137] Memory required for data: 94130176
I0804 19:51:52.452447 14035 layer_factory.hpp:77] Creating layer conv6_2
I0804 19:51:52.452462 14035 net.cpp:84] Creating Layer conv6_2
I0804 19:51:52.452473 14035 net.cpp:406] conv6_2 <- conv6_1
I0804 19:51:52.452487 14035 net.cpp:380] conv6_2 -> conv6_2
I0804 19:51:52.457437 14035 net.cpp:122] Setting up conv6_2
I0804 19:51:52.457480 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.457491 14035 net.cpp:137] Memory required for data: 95735808
I0804 19:51:52.457507 14035 layer_factory.hpp:77] Creating layer relu6_2
I0804 19:51:52.457525 14035 net.cpp:84] Creating Layer relu6_2
I0804 19:51:52.457537 14035 net.cpp:406] relu6_2 <- conv6_2
I0804 19:51:52.457551 14035 net.cpp:367] relu6_2 -> conv6_2 (in-place)
I0804 19:51:52.457566 14035 net.cpp:122] Setting up relu6_2
I0804 19:51:52.457577 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.457587 14035 net.cpp:137] Memory required for data: 97341440
I0804 19:51:52.457597 14035 layer_factory.hpp:77] Creating layer conv6_3
I0804 19:51:52.457614 14035 net.cpp:84] Creating Layer conv6_3
I0804 19:51:52.457624 14035 net.cpp:406] conv6_3 <- conv6_2
I0804 19:51:52.457638 14035 net.cpp:380] conv6_3 -> conv6_3
I0804 19:51:52.462508 14035 net.cpp:122] Setting up conv6_3
I0804 19:51:52.462554 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.462565 14035 net.cpp:137] Memory required for data: 98947072
I0804 19:51:52.462581 14035 layer_factory.hpp:77] Creating layer relu6_3
I0804 19:51:52.462602 14035 net.cpp:84] Creating Layer relu6_3
I0804 19:51:52.462615 14035 net.cpp:406] relu6_3 <- conv6_3
I0804 19:51:52.462627 14035 net.cpp:367] relu6_3 -> conv6_3 (in-place)
I0804 19:51:52.462641 14035 net.cpp:122] Setting up relu6_3
I0804 19:51:52.462653 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.462663 14035 net.cpp:137] Memory required for data: 100552704
I0804 19:51:52.462673 14035 layer_factory.hpp:77] Creating layer conv6_3norm
I0804 19:51:52.462689 14035 net.cpp:84] Creating Layer conv6_3norm
I0804 19:51:52.462699 14035 net.cpp:406] conv6_3norm <- conv6_3
I0804 19:51:52.462713 14035 net.cpp:380] conv6_3norm -> conv6_3norm
I0804 19:51:52.462939 14035 net.cpp:122] Setting up conv6_3norm
I0804 19:51:52.462954 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.462965 14035 net.cpp:137] Memory required for data: 102158336
I0804 19:51:52.462978 14035 layer_factory.hpp:77] Creating layer conv7_1
I0804 19:51:52.462994 14035 net.cpp:84] Creating Layer conv7_1
I0804 19:51:52.463006 14035 net.cpp:406] conv7_1 <- conv6_3norm
I0804 19:51:52.463019 14035 net.cpp:380] conv7_1 -> conv7_1
I0804 19:51:52.467906 14035 net.cpp:122] Setting up conv7_1
I0804 19:51:52.467952 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.467964 14035 net.cpp:137] Memory required for data: 103763968
I0804 19:51:52.467979 14035 layer_factory.hpp:77] Creating layer relu7_1
I0804 19:51:52.467998 14035 net.cpp:84] Creating Layer relu7_1
I0804 19:51:52.468010 14035 net.cpp:406] relu7_1 <- conv7_1
I0804 19:51:52.468022 14035 net.cpp:367] relu7_1 -> conv7_1 (in-place)
I0804 19:51:52.468037 14035 net.cpp:122] Setting up relu7_1
I0804 19:51:52.468050 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.468060 14035 net.cpp:137] Memory required for data: 105369600
I0804 19:51:52.468070 14035 layer_factory.hpp:77] Creating layer conv7_2
I0804 19:51:52.468086 14035 net.cpp:84] Creating Layer conv7_2
I0804 19:51:52.468096 14035 net.cpp:406] conv7_2 <- conv7_1
I0804 19:51:52.468109 14035 net.cpp:380] conv7_2 -> conv7_2
I0804 19:51:52.473075 14035 net.cpp:122] Setting up conv7_2
I0804 19:51:52.473124 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.473136 14035 net.cpp:137] Memory required for data: 106975232
I0804 19:51:52.473151 14035 layer_factory.hpp:77] Creating layer relu7_2
I0804 19:51:52.473168 14035 net.cpp:84] Creating Layer relu7_2
I0804 19:51:52.473181 14035 net.cpp:406] relu7_2 <- conv7_2
I0804 19:51:52.473193 14035 net.cpp:367] relu7_2 -> conv7_2 (in-place)
I0804 19:51:52.473208 14035 net.cpp:122] Setting up relu7_2
I0804 19:51:52.473220 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.473230 14035 net.cpp:137] Memory required for data: 108580864
I0804 19:51:52.473240 14035 layer_factory.hpp:77] Creating layer conv7_3
I0804 19:51:52.473256 14035 net.cpp:84] Creating Layer conv7_3
I0804 19:51:52.473268 14035 net.cpp:406] conv7_3 <- conv7_2
I0804 19:51:52.473279 14035 net.cpp:380] conv7_3 -> conv7_3
I0804 19:51:52.478200 14035 net.cpp:122] Setting up conv7_3
I0804 19:51:52.478246 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.478257 14035 net.cpp:137] Memory required for data: 110186496
I0804 19:51:52.478273 14035 layer_factory.hpp:77] Creating layer relu7_3
I0804 19:51:52.478289 14035 net.cpp:84] Creating Layer relu7_3
I0804 19:51:52.478302 14035 net.cpp:406] relu7_3 <- conv7_3
I0804 19:51:52.478315 14035 net.cpp:367] relu7_3 -> conv7_3 (in-place)
I0804 19:51:52.478330 14035 net.cpp:122] Setting up relu7_3
I0804 19:51:52.478343 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.478353 14035 net.cpp:137] Memory required for data: 111792128
I0804 19:51:52.478363 14035 layer_factory.hpp:77] Creating layer conv7_3norm
I0804 19:51:52.478379 14035 net.cpp:84] Creating Layer conv7_3norm
I0804 19:51:52.478389 14035 net.cpp:406] conv7_3norm <- conv7_3
I0804 19:51:52.478401 14035 net.cpp:380] conv7_3norm -> conv7_3norm
I0804 19:51:52.478613 14035 net.cpp:122] Setting up conv7_3norm
I0804 19:51:52.478631 14035 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 19:51:52.478644 14035 net.cpp:137] Memory required for data: 113397760
I0804 19:51:52.478664 14035 layer_factory.hpp:77] Creating layer conv8_1
I0804 19:51:52.478682 14035 net.cpp:84] Creating Layer conv8_1
I0804 19:51:52.478696 14035 net.cpp:406] conv8_1 <- conv7_3norm
I0804 19:51:52.478713 14035 net.cpp:380] conv8_1 -> conv8_1
I0804 19:51:52.483170 14035 net.cpp:122] Setting up conv8_1
I0804 19:51:52.483217 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.483228 14035 net.cpp:137] Memory required for data: 116609024
I0804 19:51:52.483244 14035 layer_factory.hpp:77] Creating layer relu8_1
I0804 19:51:52.483280 14035 net.cpp:84] Creating Layer relu8_1
I0804 19:51:52.483292 14035 net.cpp:406] relu8_1 <- conv8_1
I0804 19:51:52.483306 14035 net.cpp:367] relu8_1 -> conv8_1 (in-place)
I0804 19:51:52.483320 14035 net.cpp:122] Setting up relu8_1
I0804 19:51:52.483333 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.483343 14035 net.cpp:137] Memory required for data: 119820288
I0804 19:51:52.483353 14035 layer_factory.hpp:77] Creating layer conv8_2
I0804 19:51:52.483371 14035 net.cpp:84] Creating Layer conv8_2
I0804 19:51:52.483381 14035 net.cpp:406] conv8_2 <- conv8_1
I0804 19:51:52.483393 14035 net.cpp:380] conv8_2 -> conv8_2
I0804 19:51:52.485025 14035 net.cpp:122] Setting up conv8_2
I0804 19:51:52.485054 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.485065 14035 net.cpp:137] Memory required for data: 123031552
I0804 19:51:52.485080 14035 layer_factory.hpp:77] Creating layer relu8_2
I0804 19:51:52.485095 14035 net.cpp:84] Creating Layer relu8_2
I0804 19:51:52.485105 14035 net.cpp:406] relu8_2 <- conv8_2
I0804 19:51:52.485117 14035 net.cpp:367] relu8_2 -> conv8_2 (in-place)
I0804 19:51:52.485132 14035 net.cpp:122] Setting up relu8_2
I0804 19:51:52.485144 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.485154 14035 net.cpp:137] Memory required for data: 126242816
I0804 19:51:52.485165 14035 layer_factory.hpp:77] Creating layer conv8_3
I0804 19:51:52.485178 14035 net.cpp:84] Creating Layer conv8_3
I0804 19:51:52.485189 14035 net.cpp:406] conv8_3 <- conv8_2
I0804 19:51:52.485203 14035 net.cpp:380] conv8_3 -> conv8_3
I0804 19:51:52.486790 14035 net.cpp:122] Setting up conv8_3
I0804 19:51:52.486820 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.486831 14035 net.cpp:137] Memory required for data: 129454080
I0804 19:51:52.486853 14035 layer_factory.hpp:77] Creating layer relu8_3
I0804 19:51:52.486871 14035 net.cpp:84] Creating Layer relu8_3
I0804 19:51:52.486881 14035 net.cpp:406] relu8_3 <- conv8_3
I0804 19:51:52.486894 14035 net.cpp:367] relu8_3 -> conv8_3 (in-place)
I0804 19:51:52.486908 14035 net.cpp:122] Setting up relu8_3
I0804 19:51:52.486920 14035 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 19:51:52.486932 14035 net.cpp:137] Memory required for data: 132665344
I0804 19:51:52.486941 14035 layer_factory.hpp:77] Creating layer conv8_313
I0804 19:51:52.486955 14035 net.cpp:84] Creating Layer conv8_313
I0804 19:51:52.486968 14035 net.cpp:406] conv8_313 <- conv8_3
I0804 19:51:52.486981 14035 net.cpp:380] conv8_313 -> conv8_313
I0804 19:51:52.488167 14035 net.cpp:122] Setting up conv8_313
I0804 19:51:52.488191 14035 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 19:51:52.488203 14035 net.cpp:137] Memory required for data: 136591616
I0804 19:51:52.488216 14035 layer_factory.hpp:77] Creating layer conv8_313_rh
I0804 19:51:52.488232 14035 net.cpp:84] Creating Layer conv8_313_rh
I0804 19:51:52.488245 14035 net.cpp:406] conv8_313_rh <- conv8_313
I0804 19:51:52.488257 14035 net.cpp:380] conv8_313_rh -> conv8_313_rh
I0804 19:51:52.488364 14035 net.cpp:122] Setting up conv8_313_rh
I0804 19:51:52.488379 14035 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 19:51:52.488389 14035 net.cpp:137] Memory required for data: 140517888
I0804 19:51:52.488401 14035 layer_factory.hpp:77] Creating layer class8_313_rh
I0804 19:51:52.488415 14035 net.cpp:84] Creating Layer class8_313_rh
I0804 19:51:52.488426 14035 net.cpp:406] class8_313_rh <- conv8_313_rh
I0804 19:51:52.488438 14035 net.cpp:380] class8_313_rh -> class8_313_rh
I0804 19:51:52.488512 14035 net.cpp:122] Setting up class8_313_rh
I0804 19:51:52.488528 14035 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 19:51:52.488538 14035 net.cpp:137] Memory required for data: 144444160
I0804 19:51:52.488548 14035 layer_factory.hpp:77] Creating layer class8_ab
I0804 19:51:52.488562 14035 net.cpp:84] Creating Layer class8_ab
I0804 19:51:52.488574 14035 net.cpp:406] class8_ab <- class8_313_rh
I0804 19:51:52.488586 14035 net.cpp:380] class8_ab -> class8_ab
I0804 19:51:52.488823 14035 net.cpp:122] Setting up class8_ab
I0804 19:51:52.488857 14035 net.cpp:129] Top shape: 1 2 56 56 (6272)
I0804 19:51:52.488868 14035 net.cpp:137] Memory required for data: 144469248
I0804 19:51:52.488881 14035 layer_factory.hpp:77] Creating layer Silence
I0804 19:51:52.488894 14035 net.cpp:84] Creating Layer Silence
I0804 19:51:52.488905 14035 net.cpp:406] Silence <- class8_ab
I0804 19:51:52.488916 14035 net.cpp:122] Setting up Silence
I0804 19:51:52.488927 14035 net.cpp:137] Memory required for data: 144469248
I0804 19:51:52.488937 14035 net.cpp:200] Silence does not need backward computation.
I0804 19:51:52.488948 14035 net.cpp:200] class8_ab does not need backward computation.
I0804 19:51:52.488960 14035 net.cpp:200] class8_313_rh does not need backward computation.
I0804 19:51:52.488970 14035 net.cpp:200] conv8_313_rh does not need backward computation.
I0804 19:51:52.488981 14035 net.cpp:200] conv8_313 does not need backward computation.
I0804 19:51:52.488991 14035 net.cpp:200] relu8_3 does not need backward computation.
I0804 19:51:52.489001 14035 net.cpp:200] conv8_3 does not need backward computation.
I0804 19:51:52.489024 14035 net.cpp:200] relu8_2 does not need backward computation.
I0804 19:51:52.489035 14035 net.cpp:200] conv8_2 does not need backward computation.
I0804 19:51:52.489045 14035 net.cpp:200] relu8_1 does not need backward computation.
I0804 19:51:52.489056 14035 net.cpp:200] conv8_1 does not need backward computation.
I0804 19:51:52.489068 14035 net.cpp:200] conv7_3norm does not need backward computation.
I0804 19:51:52.489078 14035 net.cpp:200] relu7_3 does not need backward computation.
I0804 19:51:52.489089 14035 net.cpp:200] conv7_3 does not need backward computation.
I0804 19:51:52.489099 14035 net.cpp:200] relu7_2 does not need backward computation.
I0804 19:51:52.489109 14035 net.cpp:200] conv7_2 does not need backward computation.
I0804 19:51:52.489120 14035 net.cpp:200] relu7_1 does not need backward computation.
I0804 19:51:52.489130 14035 net.cpp:200] conv7_1 does not need backward computation.
I0804 19:51:52.489142 14035 net.cpp:200] conv6_3norm does not need backward computation.
I0804 19:51:52.489153 14035 net.cpp:200] relu6_3 does not need backward computation.
I0804 19:51:52.489164 14035 net.cpp:200] conv6_3 does not need backward computation.
I0804 19:51:52.489176 14035 net.cpp:200] relu6_2 does not need backward computation.
I0804 19:51:52.489186 14035 net.cpp:200] conv6_2 does not need backward computation.
I0804 19:51:52.489195 14035 net.cpp:200] relu6_1 does not need backward computation.
I0804 19:51:52.489207 14035 net.cpp:200] conv6_1 does not need backward computation.
I0804 19:51:52.489217 14035 net.cpp:200] conv5_3norm does not need backward computation.
I0804 19:51:52.489228 14035 net.cpp:200] relu5_3 does not need backward computation.
I0804 19:51:52.489238 14035 net.cpp:200] conv5_3 does not need backward computation.
I0804 19:51:52.489248 14035 net.cpp:200] relu5_2 does not need backward computation.
I0804 19:51:52.489259 14035 net.cpp:200] conv5_2 does not need backward computation.
I0804 19:51:52.489269 14035 net.cpp:200] relu5_1 does not need backward computation.
I0804 19:51:52.489279 14035 net.cpp:200] conv5_1 does not need backward computation.
I0804 19:51:52.489289 14035 net.cpp:200] conv4_3norm does not need backward computation.
I0804 19:51:52.489300 14035 net.cpp:200] relu4_3 does not need backward computation.
I0804 19:51:52.489310 14035 net.cpp:200] conv4_3 does not need backward computation.
I0804 19:51:52.489321 14035 net.cpp:200] relu4_2 does not need backward computation.
I0804 19:51:52.489331 14035 net.cpp:200] conv4_2 does not need backward computation.
I0804 19:51:52.489341 14035 net.cpp:200] relu4_1 does not need backward computation.
I0804 19:51:52.489352 14035 net.cpp:200] conv4_1 does not need backward computation.
I0804 19:51:52.489362 14035 net.cpp:200] conv3_3norm does not need backward computation.
I0804 19:51:52.489373 14035 net.cpp:200] relu3_3 does not need backward computation.
I0804 19:51:52.489383 14035 net.cpp:200] conv3_3 does not need backward computation.
I0804 19:51:52.489406 14035 net.cpp:200] relu3_2 does not need backward computation.
I0804 19:51:52.489418 14035 net.cpp:200] conv3_2 does not need backward computation.
I0804 19:51:52.489428 14035 net.cpp:200] relu3_1 does not need backward computation.
I0804 19:51:52.489439 14035 net.cpp:200] conv3_1 does not need backward computation.
I0804 19:51:52.489449 14035 net.cpp:200] conv2_2norm does not need backward computation.
I0804 19:51:52.489460 14035 net.cpp:200] relu2_2 does not need backward computation.
I0804 19:51:52.489470 14035 net.cpp:200] conv2_2 does not need backward computation.
I0804 19:51:52.489480 14035 net.cpp:200] relu2_1 does not need backward computation.
I0804 19:51:52.489491 14035 net.cpp:200] conv2_1 does not need backward computation.
I0804 19:51:52.489502 14035 net.cpp:200] conv1_2norm does not need backward computation.
I0804 19:51:52.489512 14035 net.cpp:200] relu1_2 does not need backward computation.
I0804 19:51:52.489523 14035 net.cpp:200] conv1_2 does not need backward computation.
I0804 19:51:52.489533 14035 net.cpp:200] relu1_1 does not need backward computation.
I0804 19:51:52.489545 14035 net.cpp:200] bw_conv1_1 does not need backward computation.
I0804 19:51:52.489557 14035 net.cpp:200] data_l does not need backward computation.
I0804 19:51:52.489591 14035 net.cpp:255] Network initialization done.
I0804 19:51:52.571900 14035 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_release_v2.caffemodel
I0804 19:51:52.571945 14035 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 19:51:52.571959 14035 net.cpp:744] Ignoring source layer img
I0804 19:51:52.571969 14035 net.cpp:744] Ignoring source layer img_lab
I0804 19:51:52.571979 14035 net.cpp:744] Ignoring source layer img_slice
I0804 19:51:52.571990 14035 net.cpp:744] Ignoring source layer data_l_meansub
I0804 19:51:52.572000 14035 net.cpp:744] Ignoring source layer data_ab_ss
I0804 19:51:52.572010 14035 net.cpp:744] Ignoring source layer data_ab_ss_data_ab_ss_0_split
I0804 19:51:52.572021 14035 net.cpp:744] Ignoring source layer ab_enc
I0804 19:51:52.572029 14035 net.cpp:744] Ignoring source layer gt_ab_313_ab_enc_0_split
I0804 19:51:52.572039 14035 net.cpp:744] Ignoring source layer ab_pb
I0804 19:51:52.572049 14035 net.cpp:744] Ignoring source layer ab_pb
I0804 19:51:52.572059 14035 net.cpp:744] Ignoring source layer pb_nongray
I0804 19:51:52.593904 14035 net.cpp:744] Ignoring source layer PriorBoost8
I0804 19:51:52.593940 14035 net.cpp:744] Ignoring source layer SoftmaxLoss8
/home/thijser/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.
  warn("The default mode, 'constant', will be changed to 'reflect' in "
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
killing all other torch instances
/home/thijser/torch/install/bin/luajit: no process found
https://www.google.co.in/search?q=missile&safe=off&source=lnms&tbm=isch&num=25
there are total 100 images
1
could not load : https://admin2.scout.com/sites/default/files/2016/03/09/New-NSM-background.jpg
HTTP Error 404: Not Found
2
3
4
5
6
7
8
9
10
could not load : http://u0v052dm9wl3gxo0y3lx0u44wz.wpengine.netdna-cdn.com/wp-content/uploads/2016/05/Common-Anti-Air-Modular-Missile.jpg
HTTP Error 403: Forbidden
11
12
13
14
15
could not load : https://49yzp92imhtx8radn224z7y1-wpengine.netdna-ssl.com/wp-content/uploads/2011/06/missile.jpg
HTTP Error 403: Forbidden
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
could not load : https://www.mda.mil/img/hprotator/SM-CTV-01a_02_003.png
<urlopen error [Errno 110] Connection timed out>
84
85
86
87
88
89
90
91
92
93
could not load : https://warontherocks.com/wp-content/uploads/2017/05/missile-def-alaska.jpg
HTTP Error 403: Forbidden
94
95
th imageSelector.lua -avaible_images t/Pictures/missile/ActiOn_45.jpg,t/Pictures/missile/ActiOn_23.jpg,t/Pictures/missile/ActiOn_35.jpg,t/Pictures/missile/ActiOn_67.jpg,t/Pictures/missile/ActiOn_61.jpg,t/Pictures/missile/ActiOn_7.jpg,t/Pictures/missile/ActiOn_59.jpg,t/Pictures/missile/ActiOn_40.jpg,t/Pictures/missile/ActiOn_11.jpg,t/Pictures/missile/ActiOn_90.jpg,t/Pictures/missile/ActiOn_74.jpg,t/Pictures/missile/ActiOn_44.jpg,t/Pictures/missile/ActiOn_6.jpg,t/Pictures/missile/ActiOn_2.jpg,t/Pictures/missile/ActiOn_9.jpg,t/Pictures/missile/ActiOn_31.png,t/Pictures/missile/ActiOn_88.jpg,t/Pictures/missile/ActiOn_94.jpg,t/Pictures/missile/ActiOn_57.jpg,t/Pictures/missile/ActiOn_62.jpg,t/Pictures/missile/ActiOn_20.jpg,t/Pictures/missile/ActiOn_30.jpg,t/Pictures/missile/ActiOn_91.png,t/Pictures/missile/ActiOn_95.jpg,t/Pictures/missile/ActiOn_58.jpg,t/Pictures/missile/ActiOn_41.jpg,t/Pictures/missile/ActiOn_4.jpg,t/Pictures/missile/ActiOn_28.jpg,t/Pictures/missile/ActiOn_83.jpg,t/Pictures/missile/ActiOn_49.jpg,t/Pictures/missile/ActiOn_52.jpg,t/Pictures/missile/ActiOn_78.jpg,t/Pictures/missile/ActiOn_37.jpg,t/Pictures/missile/ActiOn_55.jpg,t/Pictures/missile/ActiOn_73.jpg,t/Pictures/missile/ActiOn_66.jpg,t/Pictures/missile/ActiOn_17.jpg,t/Pictures/missile/ActiOn_32.jpg,t/Pictures/missile/ActiOn_84.jpg,t/Pictures/missile/ActiOn_5.jpg,t/Pictures/missile/ActiOn_13.jpg,t/Pictures/missile/ActiOn_85.jpg,t/Pictures/missile/ActiOn_81.jpg,t/Pictures/missile/ActiOn_82.jpg,t/Pictures/missile/ActiOn_72.jpg,t/Pictures/missile/ActiOn_18.jpg,t/Pictures/missile/ActiOn_56.png,t/Pictures/missile/ActiOn_60.jpg,t/Pictures/missile/ActiOn_14.jpg,t/Pictures/missile/ActiOn_76.jpg,t/Pictures/missile/ActiOn_3.jpg,t/Pictures/missile/ActiOn_22.jpg,t/Pictures/missile/ActiOn_8.jpg,t/Pictures/missile/ActiOn_33.jpg,t/Pictures/missile/ActiOn_46.jpg,t/Pictures/missile/ActiOn_77.jpg,t/Pictures/missile/ActiOn_75.jpg,t/Pictures/missile/ActiOn_29.jpg,t/Pictures/missile/ActiOn_65.jpg,t/Pictures/missile/ActiOn_63.jpg,t/Pictures/missile/ActiOn_24.jpg,t/Pictures/missile/ActiOn_69.jpg,t/Pictures/missile/ActiOn_68.jpg,t/Pictures/missile/ActiOn_51.jpg,t/Pictures/missile/ActiOn_80.jpg,t/Pictures/missile/ActiOn_21.jpg,t/Pictures/missile/ActiOn_86.jpg,t/Pictures/missile/ActiOn_1.jpg,t/Pictures/missile/ActiOn_34.jpg,t/Pictures/missile/ActiOn_43.jpg,t/Pictures/missile/ActiOn_79.jpg,t/Pictures/missile/ActiOn_92.jpg,t/Pictures/missile/ActiOn_36.jpg,t/Pictures/missile/ActiOn_16.jpg,t/Pictures/missile/ActiOn_38.jpg,t/Pictures/missile/ActiOn_53.jpg,t/Pictures/missile/ActiOn_64.jpg,t/Pictures/missile/ActiOn_93.jpg,t/Pictures/missile/ActiOn_15.png,t/Pictures/missile/ActiOn_26.jpg,t/Pictures/missile/ActiOn_25.jpg,t/Pictures/missile/ActiOn_48.jpg,t/Pictures/missile/ActiOn_87.jpg,t/Pictures/missile/ActiOn_42.jpg,t/Pictures/missile/ActiOn_39.jpg,t/Pictures/missile/ActiOn_50.jpg,t/Pictures/missile/ActiOn_19.jpg,t/Pictures/missile/ActiOn_70.jpg,t/Pictures/missile/ActiOn_89.jpg,t/Pictures/missile/ActiOn_27.jpg,t/Pictures/missile/ActiOn_47.jpg,t/Pictures/missile/ActiOn_54.jpg,t/Pictures/missile/ActiOn_10.jpg
libpng warning: iCCP: known incorrect sRGB profile
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
libpng warning: iCCP: known incorrect sRGB profile
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
coleval=1639248880.2083	
neuroval=662712104	
coleval=1586295052.0833	
neuroval=646979832	
coleval=2105416875	
neuroval=789638760	
coleval=655284375	
neuroval=759807984	
coleval=2184408479.0039	
neuroval=693838568	
coleval=1744102617.1875	
neuroval=709883248	
coleval=2740661250	
neuroval=545757336	
coleval=1413733857.4219	
neuroval=779934376	
coleval=1371164121.4453	
neuroval=762796536	
coleval=1388869951.1719	
neuroval=645203704	
coleval=1017380625	
neuroval=617233992	
coleval=2576374116.6992	
neuroval=547215592	
coleval=2376056250	
neuroval=598018584	
coleval=722077500	
neuroval=744669112	
coleval=1278530625	
neuroval=918245936	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=395454375	
neuroval=577528728	
coleval=2091028125	
neuroval=502337056	
coleval=1266230625	
neuroval=739143680	
coleval=728923125	
neuroval=647951528	
coleval=1077669177.2461	
neuroval=759392472	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1938050364.5833	
neuroval=511002848	
coleval=2142516250	
neuroval=620994520	
coleval=618979726.56813	
neuroval=579617744	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1018646250	
neuroval=558889856	
coleval=1654775625	
neuroval=846261112	
coleval=1841733750	
neuroval=694324040	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1711243125	
neuroval=556606256	
coleval=2465424375	
neuroval=811109496	
coleval=1461893674.7814	
neuroval=721030392	
coleval=968961052.04335	
neuroval=623352824	
coleval=706271250	
neuroval=829421208	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_66.jpg"
      2 : "t/Pictures/missile/ActiOn_19.jpg"
      3 : "t/Pictures/missile/ActiOn_21.jpg"
      4 : "t/Pictures/missile/ActiOn_35.jpg"
      5 : "t/Pictures/missile/ActiOn_31.png"
    }
  2 : 972983103
}
coleval=2857308750	
neuroval=610002544	
coleval=1756649936.3207	
neuroval=627823096	
coleval=774931875	
neuroval=491334848	
coleval=1426702500	
neuroval=615437256	
coleval=706018125	
neuroval=692596672	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=395454375	
neuroval=577528728	
coleval=277087500	
neuroval=619134000	
coleval=796593750	
neuroval=612409984	
coleval=2109020625	
neuroval=642082552	
coleval=1914573750	
neuroval=707839920	
coleval=2097650625	
neuroval=669286792	
coleval=618979726.56813	
neuroval=579617744	
coleval=848952416.56698	
neuroval=539067776	
coleval=1327299113.6935	
neuroval=596248632	
coleval=1800177910.7983	
neuroval=652105096	
coleval=2017017262.8372	
neuroval=670087632	
coleval=1997337985.7807	
neuroval=609805304	
coleval=728923125	
neuroval=647951528	
coleval=707949375	
neuroval=496767168	
coleval=1093953007.8125	
neuroval=518306904	
coleval=1337546757.8125	
neuroval=503035816	
coleval=1013595195.3125	
neuroval=582853040	
coleval=963226679.6875	
neuroval=525907992	
coleval=655284375	
neuroval=759807984	
coleval=489684375	
neuroval=781829072	
coleval=883923750	
neuroval=653583264	
coleval=461415000	
neuroval=661005560	
coleval=1577917500	
neuroval=676952232	
coleval=1786717500	
neuroval=654931144	
coleval=722077500	
neuroval=744669112	
coleval=1659464482.3594	
neuroval=900483912	
coleval=1779168984.1172	
neuroval=766001072	
coleval=724803750	
neuroval=661232512	
coleval=665960625	
neuroval=695044512	
coleval=354076875	
neuroval=634794088	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_66.jpg"
      2 : "t/Pictures/missile/ActiOn_41.jpg"
      3 : "t/Pictures/missile/ActiOn_21.jpg"
      4 : "t/Pictures/missile/ActiOn_35.jpg"
      5 : "t/Pictures/missile/ActiOn_31.png"
    }
  2 : 896221500
}
coleval=829627170.41016	
neuroval=581837608	
coleval=977576250	
neuroval=515865432	
coleval=2425524375	
neuroval=643788896	
coleval=1240410000	
neuroval=601152424	
coleval=1096396867.6814	
neuroval=660467584	
coleval=277087500	
neuroval=619134000	
coleval=250391250	
neuroval=684891368	
coleval=814493844.25451	
neuroval=709676120	
coleval=436691250	
neuroval=584330752	
coleval=843840681.15234	
neuroval=567681392	
coleval=859453286.13281	
neuroval=639071640	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=395454375	
neuroval=577528728	
coleval=336583125	
neuroval=564598568	
coleval=558986250	
neuroval=536779336	
coleval=1430220000	
neuroval=581951688	
coleval=1257436875	
neuroval=541401720	
coleval=1234173750	
neuroval=558113856	
coleval=354076875	
neuroval=634794088	
coleval=689548125	
neuroval=655682584	
coleval=889286250	
neuroval=675480784	
coleval=542647500	
neuroval=624560136	
coleval=1574536875	
neuroval=627118368	
coleval=1966385625	
neuroval=589350432	
coleval=461415000	
neuroval=661005560	
coleval=475734375	
neuroval=587440000	
coleval=438900000	
neuroval=616492880	
coleval=945316875	
neuroval=609070584	
coleval=957311250	
neuroval=594176072	
coleval=1358456250	
neuroval=590639952	
coleval=618979726.56813	
neuroval=579617744	
coleval=939623681.35903	
neuroval=591407536	
coleval=1475982534.6697	
neuroval=621693920	
coleval=1428880543.4339	
neuroval=582087592	
coleval=1840907107.621	
neuroval=715648888	
coleval=2012520958.1495	
neuroval=834308824	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_66.jpg"
      2 : "t/Pictures/missile/ActiOn_41.jpg"
      3 : "t/Pictures/missile/ActiOn_21.jpg"
      4 : "t/Pictures/missile/ActiOn_35.jpg"
      5 : "t/Pictures/missile/ActiOn_31.png"
    }
  2 : 896221500
}
coleval=1135440872.7891	
neuroval=647658480	
coleval=389820000	
neuroval=596050896	
coleval=2256667500	
neuroval=792384592	
coleval=1689269042.1716	
neuroval=791422168	
coleval=2018999414.0625	
neuroval=740962384	
coleval=277087500	
neuroval=619134000	
coleval=1594688614.1953	
neuroval=783390024	
coleval=1729991488.8047	
neuroval=687518184	
coleval=1669976077.4766	
neuroval=727908600	
coleval=1124304380.6016	
neuroval=694772912	
coleval=1066655898.668	
neuroval=637815248	
coleval=336583125	
neuroval=564598568	
coleval=268381875	
neuroval=625782304	
coleval=806831250	
neuroval=668119672	
coleval=929212500	
neuroval=581156160	
coleval=272287500	
neuroval=645568720	
coleval=450795000	
neuroval=637125568	
coleval=250391250	
neuroval=684891368	
coleval=394899375	
neuroval=678028056	
coleval=385717500	
neuroval=649791000	
coleval=309768750	
neuroval=606572800	
coleval=573238125	
neuroval=656274616	
coleval=659051250	
neuroval=741450712	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=395454375	
neuroval=577528728	
coleval=1312576875	
neuroval=570799280	
coleval=1132500000	
neuroval=650283496	
coleval=1840456875	
neuroval=644272328	
coleval=1140661875	
neuroval=592518808	
coleval=1132500000	
neuroval=650283496	
coleval=354076875	
neuroval=634794088	
coleval=708148125	
neuroval=604129992	
coleval=1229055000	
neuroval=612544896	
coleval=721185000	
neuroval=692625320	
coleval=708124492.1875	
neuroval=677216760	
coleval=903564648.4375	
neuroval=720434960	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_66.jpg"
      2 : "t/Pictures/missile/ActiOn_54.jpg"
      3 : "t/Pictures/missile/ActiOn_21.jpg"
      4 : "t/Pictures/missile/ActiOn_35.jpg"
      5 : "t/Pictures/missile/ActiOn_31.png"
    }
  2 : 894164179
}
coleval=1206078822.1102	
neuroval=673652816	
coleval=463048125	
neuroval=559598416	
coleval=1425523828.125	
neuroval=552956200	
coleval=2429128164.0625	
neuroval=481403296	
coleval=413224064.94141	
neuroval=787381328	
coleval=268381875	
neuroval=625782304	
coleval=822170520.83333	
neuroval=629366448	
coleval=865901908.11527	
neuroval=645283968	
coleval=1264835372.0399	
neuroval=633242736	
coleval=931232444.36297	
neuroval=665434152	
coleval=932693270.85079	
neuroval=699708728	
coleval=277087500	
neuroval=619134000	
coleval=370248750	
neuroval=565109816	
coleval=607383750	
neuroval=615091520	
coleval=1154906250	
neuroval=643651936	
coleval=1208707500	
neuroval=599696208	
coleval=309594375	
neuroval=525245432	
coleval=336583125	
neuroval=564598568	
coleval=518445000	
neuroval=670192448	
coleval=885526263.02083	
neuroval=729434840	
coleval=676916054.6875	
neuroval=704765592	
coleval=775170273.4375	
neuroval=617802080	
coleval=872911679.6875	
neuroval=511875192	
coleval=309768750	
neuroval=606572800	
coleval=314671875	
neuroval=562617072	
coleval=764405625	
neuroval=743178288	
coleval=2002396210.9375	
neuroval=683853136	
coleval=2346128945.3125	
neuroval=700492296	
coleval=2427888554.6875	
neuroval=520581624	
coleval=272287500	
neuroval=645568720	
coleval=665201250	
neuroval=597770032	
coleval=1008758371.582	
neuroval=574554480	
coleval=709638610.83984	
neuroval=571671536	
coleval=933746433.10547	
neuroval=799819288	
coleval=859289003.90625	
neuroval=827700472	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_14.jpg"
      2 : "t/Pictures/missile/ActiOn_13.jpg"
      3 : "t/Pictures/missile/ActiOn_21.jpg"
      4 : "t/Pictures/missile/ActiOn_32.jpg"
      5 : "t/Pictures/missile/ActiOn_31.png"
    }
  2 : 834839807
}
coleval=2165779075.0378	
neuroval=765709376	
coleval=1787435856.9502	
neuroval=915407032	
coleval=1205256621.0938	
neuroval=599627544	
coleval=1190197824.7901	
neuroval=700593440	
coleval=1166422452.5489	
neuroval=778664568	
coleval=309594375	
neuroval=525245432	
coleval=398420625	
neuroval=535959592	
coleval=787438125	
neuroval=435065968	
coleval=1585044981.2109	
neuroval=504066440	
coleval=1303019928.8119	
neuroval=676534592	
coleval=1953055325.4801	
neuroval=741978424	
coleval=314671875	
neuroval=562617072	
coleval=1337514748.0867	
neuroval=696596192	
coleval=1364774720.1849	
neuroval=847385616	
coleval=1851969078.4439	
neuroval=912894328	
coleval=1961590374.9469	
neuroval=1019573968	
coleval=1853453441.3531	
neuroval=987355368	
coleval=268381875	
neuroval=625782304	
coleval=546286875	
neuroval=576296088	
coleval=696502981.77083	
neuroval=645044240	
coleval=1205917122.3958	
neuroval=582945392	
coleval=740640000	
neuroval=579872496	
coleval=1207392480.4688	
neuroval=563816496	
coleval=277087500	
neuroval=619134000	
coleval=148743750	
neuroval=698618216	
coleval=418006210.9375	
neuroval=677021864	
coleval=693933398.4375	
neuroval=605603072	
coleval=968488125	
neuroval=608942984	
coleval=1111301250	
neuroval=649572048	
coleval=336583125	
neuroval=564598568	
coleval=787001250	
neuroval=569631832	
coleval=1435475625	
neuroval=592154392	
coleval=1312989375	
neuroval=637663912	
coleval=1269241875	
neuroval=632711224	
coleval=1173730899.0964	
neuroval=685348576	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_14.jpg"
      2 : "t/Pictures/missile/ActiOn_13.jpg"
      3 : "t/Pictures/missile/ActiOn_21.jpg"
      4 : "t/Pictures/missile/ActiOn_32.jpg"
      5 : "t/Pictures/missile/ActiOn_31.png"
    }
  2 : 834839807
}
coleval=1463986875	
neuroval=535997736	
coleval=1057800000	
neuroval=766927296	
coleval=2010236250	
neuroval=650442080	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2208536250	
neuroval=586795448	
coleval=806332730.78763	
neuroval=851941344	
coleval=309594375	
neuroval=525245432	
coleval=782083125	
neuroval=482807648	
coleval=529306875	
neuroval=520194592	
coleval=1519156875	
neuroval=489276000	
coleval=1647934398.4508	
neuroval=591864296	
coleval=1354063125	
neuroval=508220672	
coleval=148743750	
neuroval=698618216	
coleval=237125625	
neuroval=665404400	
coleval=239988750	
neuroval=621493128	
coleval=364912500	
neuroval=644178784	
coleval=678354375	
neuroval=679146496	
coleval=894198750	
neuroval=648267360	
coleval=314671875	
neuroval=562617072	
coleval=2184169843.75	
neuroval=566109720	
coleval=358006875	
neuroval=572891920	
coleval=1108258125	
neuroval=739430272	
coleval=1986781875	
neuroval=758847792	
coleval=2181729375	
neuroval=537326416	
coleval=268381875	
neuroval=625782304	
coleval=1361602500	
neuroval=572408824	
coleval=1544004375	
neuroval=619827640	
coleval=2063310000	
neuroval=645192656	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2458336875	
neuroval=592793264	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2651390625	
neuroval=575263024	
coleval=277087500	
neuroval=619134000	
coleval=820796250	
neuroval=675893568	
coleval=1227521250	
neuroval=724670240	
coleval=2375077500	
neuroval=786099328	
coleval=1625865000	
neuroval=823486272	
coleval=501690000	
neuroval=802958848	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_14.jpg"
      2 : "t/Pictures/missile/ActiOn_13.jpg"
      3 : "t/Pictures/missile/ActiOn_21.jpg"
      4 : "t/Pictures/missile/ActiOn_32.jpg"
      5 : "t/Pictures/missile/ActiOn_31.png"
    }
  2 : 834839807
}
coleval=890870625	
neuroval=643651016	
coleval=1306114901.2005	
neuroval=567646832	
coleval=837444807.06804	
neuroval=795373176	
coleval=918148125	
neuroval=626830288	
coleval=1571203125	
neuroval=725580288	
coleval=309594375	
neuroval=525245432	
coleval=273045000	
neuroval=576812336	
coleval=940081875	
neuroval=625954840	
coleval=1366065000	
neuroval=583013048	
coleval=1505180625	
neuroval=621504840	
coleval=807153750	
neuroval=645739504	
coleval=148743750	
neuroval=698618216	
coleval=325462500	
neuroval=769985352	
coleval=926311875	
neuroval=839656536	
coleval=1001850000	
neuroval=724376072	
coleval=808294889.85513	
neuroval=615824512	
coleval=1329773799.121	
neuroval=622890640	
coleval=239988750	
neuroval=621493128	
coleval=152371875	
neuroval=654706944	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=423660000	
neuroval=669271168	
coleval=751629619.85073	
neuroval=770546552	
coleval=779821136.60649	
neuroval=750188104	
coleval=736448944.22367	
neuroval=771264504	
coleval=314671875	
neuroval=562617072	
coleval=773602500	
neuroval=546653744	
coleval=889663125	
neuroval=630864504	
coleval=854630150.08031	
neuroval=651444768	
coleval=788454375	
neuroval=617586200	
coleval=800557500	
neuroval=633989840	
coleval=268381875	
neuroval=625782304	
coleval=356071875	
neuroval=536361512	
coleval=440381250	
neuroval=645881000	
coleval=733966875	
neuroval=653458376	
coleval=839823750	
neuroval=653125368	
coleval=1990282500	
neuroval=726931424	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_66.jpg"
      2 : "t/Pictures/missile/ActiOn_41.jpg"
      3 : "t/Pictures/missile/ActiOn_76.jpg"
      4 : "t/Pictures/missile/ActiOn_35.jpg"
      5 : "t/Pictures/missile/ActiOn_86.jpg"
    }
  2 : 807078819
}
coleval=1031574375	
neuroval=652576024	
coleval=2291752812.5	
neuroval=697725016	
coleval=1405614074.8675	
neuroval=642319120	
coleval=1972357060.5469	
neuroval=588139720	
coleval=1649628418.1016	
neuroval=820738832	
coleval=152371875	
neuroval=654706944	
coleval=228316875	
neuroval=603140040	
coleval=697051875	
neuroval=621571256	
coleval=454471875	
neuroval=618684760	
coleval=467105625	
neuroval=648750512	
coleval=147318750	
neuroval=690103552	
coleval=309594375	
neuroval=525245432	
coleval=1816173750	
neuroval=564423760	
coleval=1759999669.4105	
neuroval=585004024	
coleval=1668192038.0589	
neuroval=615485824	
coleval=977690612.27765	
neuroval=664355376	
coleval=972950625	
neuroval=728805512	
coleval=148743750	
neuroval=698618216	
coleval=1278829086.9141	
neuroval=667680624	
coleval=1631334514.1602	
neuroval=673395616	
coleval=1706052780.7617	
neuroval=607508504	
coleval=1809571165.7208	
neuroval=723348112	
coleval=1689640145.6396	
neuroval=682668416	
coleval=273045000	
neuroval=576812336	
coleval=1650417429.1992	
neuroval=589319224	
coleval=2017922182.6172	
neuroval=638964232	
coleval=1991152946.7773	
neuroval=571574032	
coleval=2412895891.1133	
neuroval=576607296	
coleval=1984122341.3086	
neuroval=701697432	
coleval=239988750	
neuroval=621493128	
coleval=374604375	
neuroval=630922248	
coleval=1418833125	
neuroval=660594816	
coleval=1174267500	
neuroval=683478688	
coleval=1634022163.2188	
neuroval=759686832	
coleval=1607520648.375	
neuroval=675462272	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_66.jpg"
      2 : "t/Pictures/missile/ActiOn_41.jpg"
      3 : "t/Pictures/missile/ActiOn_76.jpg"
      4 : "t/Pictures/missile/ActiOn_35.jpg"
      5 : "t/Pictures/missile/ActiOn_86.jpg"
    }
  2 : 807078819
}
coleval=2187172820.6048	
neuroval=724646712	
coleval=934545000	
neuroval=532102544	
coleval=517423125	
neuroval=630125144	
coleval=820717500	
neuroval=784574448	
coleval=1419547500	
neuroval=608162136	
coleval=152371875	
neuroval=654706944	
coleval=657787500	
neuroval=814084640	
coleval=1433257500	
neuroval=878051928	
coleval=1173047947.5579	
neuroval=929073320	
coleval=1909163015.9173	
neuroval=936304384	
coleval=1845460012.2901	
neuroval=756393712	
coleval=228316875	
neuroval=603140040	
coleval=264675000	
neuroval=653240624	
coleval=1446706875	
neuroval=573694936	
coleval=1406011875	
neuroval=609505984	
coleval=1660276875	
neuroval=572972552	
coleval=1532662500	
neuroval=528359112	
coleval=309594375	
neuroval=525245432	
coleval=2464485000	
neuroval=551277912	
coleval=2457901875	
neuroval=589045848	
coleval=2390619375	
neuroval=602750888	
coleval=875698125	
neuroval=487297616	
coleval=716985000	
neuroval=507769560	
coleval=147318750	
neuroval=690103552	
coleval=723675000	
neuroval=624413712	
coleval=320622421.875	
neuroval=633621840	
coleval=248655000	
neuroval=621734352	
coleval=200340180.38247	
neuroval=631842728	
coleval=697051875	
neuroval=621571256	
coleval=148743750	
neuroval=698618216	
coleval=406507500	
neuroval=597724592	
coleval=417174375	
neuroval=644868176	
coleval=715573125	
neuroval=639191632	
coleval=2271163125	
neuroval=686300512	
coleval=1104845625	
neuroval=615536696	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_66.jpg"
      2 : "t/Pictures/missile/ActiOn_41.jpg"
      3 : "t/Pictures/missile/ActiOn_76.jpg"
      4 : "t/Pictures/missile/ActiOn_35.jpg"
      5 : "t/Pictures/missile/ActiOn_86.jpg"
    }
  2 : 807078819
}
coleval=1519848200.1328	
neuroval=686141640	
coleval=891041779.10156	
neuroval=732157672	
coleval=1457394375	
neuroval=687094920	
coleval=592995000	
neuroval=546841064	
coleval=989671875	
neuroval=636608944	
coleval=152371875	
neuroval=654706944	
coleval=915446250	
neuroval=594172808	
coleval=1014870000	
neuroval=597734784	
coleval=1437504375	
neuroval=630185712	
coleval=1473292500	
neuroval=604200032	
coleval=1414955625	
neuroval=561063944	
coleval=228316875	
neuroval=603140040	
coleval=245437500	
neuroval=728333744	
coleval=472190625	
neuroval=804009320	
coleval=1010345625	
neuroval=870661552	
coleval=1158013125	
neuroval=827823640	
coleval=1100791875	
neuroval=780800864	
coleval=200340180.38247	
neuroval=631842728	
coleval=535621984.63519	
neuroval=621106664	
coleval=905026749.5677	
neuroval=680642720	
coleval=950093645.15039	
neuroval=717488448	
coleval=1221148354.785	
neuroval=620253128	
coleval=1706773896.7772	
neuroval=640481376	
coleval=309594375	
neuroval=525245432	
coleval=523721250	
neuroval=456876232	
coleval=1179855000	
neuroval=495439032	
coleval=588646875	
neuroval=491806048	
coleval=440790000	
neuroval=502520208	
coleval=489390000	
neuroval=468708208	
coleval=147318750	
neuroval=690103552	
coleval=159840000	
neuroval=646147824	
coleval=351620625	
neuroval=684639616	
coleval=645926250	
neuroval=702618672	
coleval=944589375	
neuroval=728728336	
coleval=968381250	
neuroval=693331728	
{
  1 : 
    {
      1 : "t/Pictures/missile/ActiOn_21.jpg"
      2 : "t/Pictures/missile/ActiOn_13.jpg"
      3 : "t/Pictures/missile/ActiOn_76.jpg"
      4 : "t/Pictures/missile/ActiOn_35.jpg"
      5 : "t/Pictures/missile/ActiOn_86.jpg"
    }
  2 : 805987824
}
selected:	
t/Pictures/missile/ActiOn_21.jpg	
t/Pictures/missile/ActiOn_13.jpg	
t/Pictures/missile/ActiOn_76.jpg	
t/Pictures/missile/ActiOn_35.jpg	
t/Pictures/missile/ActiOn_86.jpg	
t/Pictures/missile/ActiOn_21.jpg,t/Pictures/missile/ActiOn_13.jpg,t/Pictures/missile/ActiOn_76.jpg,t/Pictures/missile/ActiOn_35.jpg,t/Pictures/missile/ActiOn_86.jpg	
writing selected	
t/Pictures/missile/ActiOn_21.jpg	
t/Pictures/missile/ActiOn_13.jpg	
t/Pictures/missile/ActiOn_76.jpg	
t/Pictures/missile/ActiOn_35.jpg	
t/Pictures/missile/ActiOn_86.jpg	
done writing selector	
2428093	
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
Setting up style layer  	2	:	relu1_1	
Setting up style layer  	7	:	relu2_1	
Setting up style layer  	12	:	relu3_1	
Setting up style layer  	21	:	relu4_1	
Setting up content layer	23	:	relu4_2	
Setting up style layer  	30	:	relu5_1	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
Running optimization with L-BFGS	
 512
  43
  64
[torch.LongStorage of size 3]

49773343.920135	
<optim.lbfgs> 	creating recyclable direction/step/history buffers	
 512
  43
  64
[torch.LongStorage of size 3]

49773280.243684	
 512
  43
  64
[torch.LongStorage of size 3]

28909338.324051	
 512
  43
  64
[torch.LongStorage of size 3]

22432186.139984	
 512
  43
  64
[torch.LongStorage of size 3]

18028827.12738	
 512
  43
  64
[torch.LongStorage of size 3]

13632009.165268	
 512
  43
  64
[torch.LongStorage of size 3]

12588705.502777	
 512
  43
  64
[torch.LongStorage of size 3]

10769418.699684	
 512
  43
  64
[torch.LongStorage of size 3]

9927203.1139374	
 512
  43
  64
[torch.LongStorage of size 3]

8825023.5628891	
 512
  43
  64
[torch.LongStorage of size 3]

7936118.4556961	
 512
  43
  64
[torch.LongStorage of size 3]

7105768.3101082	
 512
  43
  64
[torch.LongStorage of size 3]

6493929.4475174	
 512
  43
  64
[torch.LongStorage of size 3]

5882167.5139236	
 512
  43
  64
[torch.LongStorage of size 3]

5362301.9371796	
 512
  43
  64
[torch.LongStorage of size 3]

4896383.3461189	
 512
  43
  64
[torch.LongStorage of size 3]

4511664.3287659	
 512
  43
  64
[torch.LongStorage of size 3]

4192097.8361702	
 512
  43
  64
[torch.LongStorage of size 3]

3955766.8470764	
 512
  43
  64
[torch.LongStorage of size 3]

3729000.5836105	
 512
  43
  64
[torch.LongStorage of size 3]

3521819.9670219	
 512
  43
  64
[torch.LongStorage of size 3]

3278736.3397598	
 512
  43
  64
[torch.LongStorage of size 3]

3115605.729847	
 512
  43
  64
[torch.LongStorage of size 3]

2945839.0766335	
 512
  43
  64
[torch.LongStorage of size 3]

2769472.4306488	
 512
  43
  64
[torch.LongStorage of size 3]

2708209.5646095	
 512
  43
  64
[torch.LongStorage of size 3]

2623461.7200279	
 512
  43
  64
[torch.LongStorage of size 3]

2552964.1202164	
 512
  43
  64
[torch.LongStorage of size 3]

2495265.8302689	
 512
  43
  64
[torch.LongStorage of size 3]

2385734.51437	
 512
  43
  64
[torch.LongStorage of size 3]

2292047.9261398	
 512
  43
  64
[torch.LongStorage of size 3]

2227917.2655487	
 512
  43
  64
[torch.LongStorage of size 3]

2179353.2891273	
 512
  43
  64
[torch.LongStorage of size 3]

2129101.0174942	
 512
  43
  64
[torch.LongStorage of size 3]

2076351.6265869	
 512
  43
  64
[torch.LongStorage of size 3]

2016563.7263489	
 512
  43
  64
[torch.LongStorage of size 3]

1990977.0903206	
 512
  43
  64
[torch.LongStorage of size 3]

1941393.428154	
 512
  43
  64
[torch.LongStorage of size 3]

1898068.6061859	
 512
  43
  64
[torch.LongStorage of size 3]

1864133.1597519	
 512
  43
  64
[torch.LongStorage of size 3]

1835617.631073	
 512
  43
  64
[torch.LongStorage of size 3]

1794244.6026802	
 512
  43
  64
[torch.LongStorage of size 3]

1765841.0618782	
 512
  43
  64
[torch.LongStorage of size 3]

1735672.4079514	
 512
  43
  64
[torch.LongStorage of size 3]

1710066.7674637	
 512
  43
  64
[torch.LongStorage of size 3]

1678339.2503738	
 512
  43
  64
[torch.LongStorage of size 3]

1672028.7142563	
 512
  43
  64
[torch.LongStorage of size 3]

1643633.6051369	
 512
  43
  64
[torch.LongStorage of size 3]

1624403.0055618	
 512
  43
  64
[torch.LongStorage of size 3]

1612725.6069946	
 512
  43
  64
[torch.LongStorage of size 3]

1587102.6480865	
 512
  43
  64
[torch.LongStorage of size 3]

1555468.5585403	
 512
  43
  64
[torch.LongStorage of size 3]

1540027.4096298	
 512
  43
  64
[torch.LongStorage of size 3]

1523757.7131081	
 512
  43
  64
[torch.LongStorage of size 3]

1509992.3969269	
 512
  43
  64
[torch.LongStorage of size 3]

1501799.4572067	
 512
  43
  64
[torch.LongStorage of size 3]

1486662.5978851	
 512
  43
  64
[torch.LongStorage of size 3]

1464943.5221481	
 512
  43
  64
[torch.LongStorage of size 3]

1443082.6287079	
 512
  43
  64
[torch.LongStorage of size 3]

1428465.7344437	
 512
  43
  64
[torch.LongStorage of size 3]

1421995.0985527	
 512
  43
  64
[torch.LongStorage of size 3]

1409722.1097183	
 512
  43
  64
[torch.LongStorage of size 3]

1398194.4233704	
 512
  43
  64
[torch.LongStorage of size 3]

1378156.4262581	
 512
  43
  64
[torch.LongStorage of size 3]

1359689.8660088	
 512
  43
  64
[torch.LongStorage of size 3]

1352434.329834	
 512
  43
  64
[torch.LongStorage of size 3]

1342837.4417686	
 512
  43
  64
[torch.LongStorage of size 3]

1329522.9530716	
 512
  43
  64
[torch.LongStorage of size 3]

1323693.1714821	
 512
  43
  64
[torch.LongStorage of size 3]

1312138.844471	
 512
  43
  64
[torch.LongStorage of size 3]

1299623.2220268	
 512
  43
  64
[torch.LongStorage of size 3]

1291991.0709763	
 512
  43
  64
[torch.LongStorage of size 3]

1310645.4171562	
 512
  43
  64
[torch.LongStorage of size 3]

1278578.4540749	
 512
  43
  64
[torch.LongStorage of size 3]

1272953.5074043	
 512
  43
  64
[torch.LongStorage of size 3]

1323883.4922981	
 512
  43
  64
[torch.LongStorage of size 3]

1257516.0502243	
 512
  43
  64
[torch.LongStorage of size 3]

1250723.8180351	
 512
  43
  64
[torch.LongStorage of size 3]

1288066.7051888	
 512
  43
  64
[torch.LongStorage of size 3]

1234253.4253311	
 512
  43
  64
[torch.LongStorage of size 3]

1227465.7373238	
 512
  43
  64
[torch.LongStorage of size 3]

1245310.9475708	
 512
  43
  64
[torch.LongStorage of size 3]

1210737.9576111	
 512
  43
  64
[torch.LongStorage of size 3]

1205001.2990761	
 512
  43
  64
[torch.LongStorage of size 3]

1194816.2352753	
 512
  43
  64
[torch.LongStorage of size 3]

1185417.6180458	
 512
  43
  64
[torch.LongStorage of size 3]

1174326.7691422	
 512
  43
  64
[torch.LongStorage of size 3]

1169910.1594543	
 512
  43
  64
[torch.LongStorage of size 3]

1159901.748848	
 512
  43
  64
[torch.LongStorage of size 3]

1153727.407589	
 512
  43
  64
[torch.LongStorage of size 3]

1152658.248558	
 512
  43
  64
[torch.LongStorage of size 3]

1144317.5021172	
 512
  43
  64
[torch.LongStorage of size 3]

1140164.2073631	
 512
  43
  64
[torch.LongStorage of size 3]

1140744.836483	
 512
  43
  64
[torch.LongStorage of size 3]

1126491.6607094	
 512
  43
  64
[torch.LongStorage of size 3]

1122039.9066353	
 512
  43
  64
[torch.LongStorage of size 3]

1135636.5494919	
 512
  43
  64
[torch.LongStorage of size 3]

1113355.9885216	
 512
  43
  64
[torch.LongStorage of size 3]

1109575.4662323	
 512
  43
  64
[torch.LongStorage of size 3]

1115292.3928642	
 512
  43
  64
[torch.LongStorage of size 3]

1098435.2686691	
 512
  43
  64
[torch.LongStorage of size 3]

1094502.1466446	
 512
  43
  64
[torch.LongStorage of size 3]

1116231.2065506	
 512
  43
  64
[torch.LongStorage of size 3]

1080900.8018875	
 512
  43
  64
[torch.LongStorage of size 3]

1076179.4075775	
 512
  43
  64
[torch.LongStorage of size 3]

1077748.0772018	
 512
  43
  64
[torch.LongStorage of size 3]

1065468.7163162	
 512
  43
  64
[torch.LongStorage of size 3]

1062229.2638206	
 512
  43
  64
[torch.LongStorage of size 3]

1055661.7184639	
 512
  43
  64
[torch.LongStorage of size 3]

1050308.4387589	
 512
  43
  64
[torch.LongStorage of size 3]

1039663.1009865	
 512
  43
  64
[torch.LongStorage of size 3]

1041678.2608986	
 512
  43
  64
[torch.LongStorage of size 3]

1033352.7889442	
 512
  43
  64
[torch.LongStorage of size 3]

1036059.5799637	
 512
  43
  64
[torch.LongStorage of size 3]

1027886.9793701	
 512
  43
  64
[torch.LongStorage of size 3]

1025826.2702751	
 512
  43
  64
[torch.LongStorage of size 3]

1020587.3414421	
 512
  43
  64
[torch.LongStorage of size 3]

1014990.816555	
 512
  43
  64
[torch.LongStorage of size 3]

1010536.6883087	
 512
  43
  64
[torch.LongStorage of size 3]

1005663.8716316	
 512
  43
  64
[torch.LongStorage of size 3]

1002058.4049416	
 512
  43
  64
[torch.LongStorage of size 3]

998911.94444656	
 512
  43
  64
[torch.LongStorage of size 3]

994831.60539627	
 512
  43
  64
[torch.LongStorage of size 3]

991160.28829575	
 512
  43
  64
[torch.LongStorage of size 3]

985944.14415359	
 512
  43
  64
[torch.LongStorage of size 3]

980985.67090988	
 512
  43
  64
[torch.LongStorage of size 3]

977004.78321075	
 512
  43
  64
[torch.LongStorage of size 3]

975050.05695343	
 512
  43
  64
[torch.LongStorage of size 3]

971317.00359344	
 512
  43
  64
[torch.LongStorage of size 3]

968738.9159584	
 512
  43
  64
[torch.LongStorage of size 3]

964393.62136841	
 512
  43
  64
[torch.LongStorage of size 3]

958999.41282272	
 512
  43
  64
[torch.LongStorage of size 3]

954970.39710999	
 512
  43
  64
[torch.LongStorage of size 3]

952748.37921143	
 512
  43
  64
[torch.LongStorage of size 3]

948985.68731308	
 512
  43
  64
[torch.LongStorage of size 3]

949893.07971954	
 512
  43
  64
[torch.LongStorage of size 3]

944240.68473816	
 512
  43
  64
[torch.LongStorage of size 3]

941981.13462448	
 512
  43
  64
[torch.LongStorage of size 3]

939238.55018616	
 512
  43
  64
[torch.LongStorage of size 3]

935971.60453796	
 512
  43
  64
[torch.LongStorage of size 3]

932976.98289871	
 512
  43
  64
[torch.LongStorage of size 3]

928388.13936234	
 512
  43
  64
[torch.LongStorage of size 3]

925293.24930191	
 512
  43
  64
[torch.LongStorage of size 3]

923376.29833221	
 512
  43
  64
[torch.LongStorage of size 3]

921698.48310471	
 512
  43
  64
[torch.LongStorage of size 3]

919663.29278946	
 512
  43
  64
[torch.LongStorage of size 3]

917973.63157272	
 512
  43
  64
[torch.LongStorage of size 3]

913872.85680771	
 512
  43
  64
[torch.LongStorage of size 3]

912201.5977478	
 512
  43
  64
[torch.LongStorage of size 3]

910586.44693375	
 512
  43
  64
[torch.LongStorage of size 3]

908948.98851395	
 512
  43
  64
[torch.LongStorage of size 3]

904392.91887283	
 512
  43
  64
[torch.LongStorage of size 3]

901104.0146637	
 512
  43
  64
[torch.LongStorage of size 3]

897729.88931656	
 512
  43
  64
[torch.LongStorage of size 3]

896745.26128769	
 512
  43
  64
[torch.LongStorage of size 3]

894279.21760559	
 512
  43
  64
[torch.LongStorage of size 3]

891894.03635025	
 512
  43
  64
[torch.LongStorage of size 3]

889044.52955246	
 512
  43
  64
[torch.LongStorage of size 3]

886478.27827454	
 512
  43
  64
[torch.LongStorage of size 3]

884335.63913345	
 512
  43
  64
[torch.LongStorage of size 3]

882928.2019043	
 512
  43
  64
[torch.LongStorage of size 3]

881127.91511536	
 512
  43
  64
[torch.LongStorage of size 3]

879468.8908577	
 512
  43
  64
[torch.LongStorage of size 3]

877706.5284729	
 512
  43
  64
[torch.LongStorage of size 3]

875847.94319153	
 512
  43
  64
[torch.LongStorage of size 3]

873749.51786041	
 512
  43
  64
[torch.LongStorage of size 3]

871023.41974258	
 512
  43
  64
[torch.LongStorage of size 3]

869206.73578262	
 512
  43
  64
[torch.LongStorage of size 3]

867992.35391617	
 512
  43
  64
[torch.LongStorage of size 3]

867471.74310684	
 512
  43
  64
[torch.LongStorage of size 3]

865501.47827148	
 512
  43
  64
[torch.LongStorage of size 3]

864484.2524147	
 512
  43
  64
[torch.LongStorage of size 3]

861987.83906937	
 512
  43
  64
[torch.LongStorage of size 3]

859843.58453751	
 512
  43
  64
[torch.LongStorage of size 3]

857304.17554855	
 512
  43
  64
[torch.LongStorage of size 3]

855334.22462463	
 512
  43
  64
[torch.LongStorage of size 3]

854091.72616959	
 512
  43
  64
[torch.LongStorage of size 3]

852339.29101944	
 512
  43
  64
[torch.LongStorage of size 3]

850452.73488998	
 512
  43
  64
[torch.LongStorage of size 3]

848594.10432816	
 512
  43
  64
[torch.LongStorage of size 3]

847807.65415192	
 512
  43
  64
[torch.LongStorage of size 3]

846259.21049118	
 512
  43
  64
[torch.LongStorage of size 3]

845128.3099556	
 512
  43
  64
[torch.LongStorage of size 3]

842862.8827858	
 512
  43
  64
[torch.LongStorage of size 3]

841227.42069244	
 512
  43
  64
[torch.LongStorage of size 3]

839840.24303436	
 512
  43
  64
[torch.LongStorage of size 3]

838779.59724426	
 512
  43
  64
[torch.LongStorage of size 3]

837570.03551483	
 512
  43
  64
[torch.LongStorage of size 3]

835300.22809982	
 512
  43
  64
[torch.LongStorage of size 3]

834299.22071457	
 512
  43
  64
[torch.LongStorage of size 3]

833276.15159988	
 512
  43
  64
[torch.LongStorage of size 3]

832645.38698196	
 512
  43
  64
[torch.LongStorage of size 3]

831837.62706757	
 512
  43
  64
[torch.LongStorage of size 3]

830965.52312851	
 512
  43
  64
[torch.LongStorage of size 3]

829720.8609581	
 512
  43
  64
[torch.LongStorage of size 3]

827652.55420685	
 512
  43
  64
[torch.LongStorage of size 3]

826300.83532333	
 512
  43
  64
[torch.LongStorage of size 3]

825300.99006653	
 512
  43
  64
[torch.LongStorage of size 3]

824261.25850677	
 512
  43
  64
[torch.LongStorage of size 3]

823485.01304626	
 512
  43
  64
[torch.LongStorage of size 3]

822538.13505173	
 512
  43
  64
[torch.LongStorage of size 3]

821591.32266998	
 512
  43
  64
[torch.LongStorage of size 3]

820417.65035629	
 512
  43
  64
[torch.LongStorage of size 3]

819440.43836594	
 512
  43
  64
[torch.LongStorage of size 3]

818276.25667572	
 512
  43
  64
[torch.LongStorage of size 3]

816861.30218506	
 512
  43
  64
[torch.LongStorage of size 3]

815801.29592896	
 512
  43
  64
[torch.LongStorage of size 3]

815118.72930527	
 512
  43
  64
[torch.LongStorage of size 3]

814046.5829277	
 512
  43
  64
[torch.LongStorage of size 3]

813021.87538147	
 512
  43
  64
[torch.LongStorage of size 3]

811701.63070679	
 512
  43
  64
[torch.LongStorage of size 3]

810531.56028748	
 512
  43
  64
[torch.LongStorage of size 3]

809477.96375275	
 512
  43
  64
[torch.LongStorage of size 3]

808202.96396255	
 512
  43
  64
[torch.LongStorage of size 3]

808592.91332245	
 512
  43
  64
[torch.LongStorage of size 3]

806770.86328506	
 512
  43
  64
[torch.LongStorage of size 3]

806208.98412704	
 512
  43
  64
[torch.LongStorage of size 3]

805325.50094604	
 512
  43
  64
[torch.LongStorage of size 3]

804367.30390549	
 512
  43
  64
[torch.LongStorage of size 3]

802687.90525436	
 512
  43
  64
[torch.LongStorage of size 3]

801776.67598724	
 512
  43
  64
[torch.LongStorage of size 3]

801038.96379471	
 512
  43
  64
[torch.LongStorage of size 3]

800429.77991104	
 512
  43
  64
[torch.LongStorage of size 3]

799875.51218033	
 512
  43
  64
[torch.LongStorage of size 3]

799031.05241776	
 512
  43
  64
[torch.LongStorage of size 3]

798369.67157364	
 512
  43
  64
[torch.LongStorage of size 3]

797069.96572495	
 512
  43
  64
[torch.LongStorage of size 3]

795941.70692444	
 512
  43
  64
[torch.LongStorage of size 3]

795009.88307953	
 512
  43
  64
[torch.LongStorage of size 3]

794081.37142181	
 512
  43
  64
[torch.LongStorage of size 3]

793443.94489288	
 512
  43
  64
[torch.LongStorage of size 3]

792632.60299683	
 512
  43
  64
[torch.LongStorage of size 3]

791678.21834564	
 512
  43
  64
[torch.LongStorage of size 3]

790632.28719711	
 512
  43
  64
[torch.LongStorage of size 3]

789967.42696762	
 512
  43
  64
[torch.LongStorage of size 3]

789335.29039383	
 512
  43
  64
[torch.LongStorage of size 3]

788273.89686584	
 512
  43
  64
[torch.LongStorage of size 3]

787748.23102951	
 512
  43
  64
[torch.LongStorage of size 3]

787069.37299728	
 512
  43
  64
[torch.LongStorage of size 3]

786446.03128433	
 512
  43
  64
[torch.LongStorage of size 3]

786065.42009354	
 512
  43
  64
[torch.LongStorage of size 3]

785269.15672302	
 512
  43
  64
[torch.LongStorage of size 3]

784199.99549866	
 512
  43
  64
[torch.LongStorage of size 3]

783196.05098724	
 512
  43
  64
[torch.LongStorage of size 3]

782524.98472214	
 512
  43
  64
[torch.LongStorage of size 3]

782135.6757164	
 512
  43
  64
[torch.LongStorage of size 3]

781411.5896225	
 512
  43
  64
[torch.LongStorage of size 3]

780672.99568176	
 512
  43
  64
[torch.LongStorage of size 3]

779730.69324493	
 512
  43
  64
[torch.LongStorage of size 3]

779286.18341446	
 512
  43
  64
[torch.LongStorage of size 3]

778799.65358734	
 512
  43
  64
[torch.LongStorage of size 3]

778390.44933319	
 512
  43
  64
[torch.LongStorage of size 3]

777460.19350052	
 512
  43
  64
[torch.LongStorage of size 3]

776361.94940567	
 512
  43
  64
[torch.LongStorage of size 3]

775313.82541656	
 512
  43
  64
[torch.LongStorage of size 3]

774546.38021469	
 512
  43
  64
[torch.LongStorage of size 3]

774117.01034546	
 512
  43
  64
[torch.LongStorage of size 3]

773632.98406601	
 512
  43
  64
[torch.LongStorage of size 3]

772978.72718811	
 512
  43
  64
[torch.LongStorage of size 3]

772561.10567093	
 512
  43
  64
[torch.LongStorage of size 3]

772037.38874435	
 512
  43
  64
[torch.LongStorage of size 3]

771458.07739258	
 512
  43
  64
[torch.LongStorage of size 3]

770624.6862793	
 512
  43
  64
[torch.LongStorage of size 3]

769858.44141006	
 512
  43
  64
[torch.LongStorage of size 3]

769288.396492	
 512
  43
  64
[torch.LongStorage of size 3]

768889.71752167	
 512
  43
  64
[torch.LongStorage of size 3]

768367.09779739	
 512
  43
  64
[torch.LongStorage of size 3]

767845.77514648	
 512
  43
  64
[torch.LongStorage of size 3]

767099.8515892	
 512
  43
  64
[torch.LongStorage of size 3]

766621.38483047	
 512
  43
  64
[torch.LongStorage of size 3]

765669.99933243	
 512
  43
  64
[torch.LongStorage of size 3]

764824.39237595	
 512
  43
  64
[torch.LongStorage of size 3]

764147.22751617	
 512
  43
  64
[torch.LongStorage of size 3]

763521.53385162	
 512
  43
  64
[torch.LongStorage of size 3]

762908.5326004	
 512
  43
  64
[torch.LongStorage of size 3]

762417.78945923	
 512
  43
  64
[torch.LongStorage of size 3]

761866.5174675	
 512
  43
  64
[torch.LongStorage of size 3]

761398.97733688	
 512
  43
  64
[torch.LongStorage of size 3]

761032.94418335	
 512
  43
  64
[torch.LongStorage of size 3]

760483.19934845	
 512
  43
  64
[torch.LongStorage of size 3]

759644.51869965	
 512
  43
  64
[torch.LongStorage of size 3]

758952.88486481	
 512
  43
  64
[torch.LongStorage of size 3]

758500.38276672	
 512
  43
  64
[torch.LongStorage of size 3]

757827.73864746	
 512
  43
  64
[torch.LongStorage of size 3]

757299.7045517	
 512
  43
  64
[torch.LongStorage of size 3]

756900.13380051	
 512
  43
  64
[torch.LongStorage of size 3]

756529.02074814	
 512
  43
  64
[torch.LongStorage of size 3]

756128.04231644	
 512
  43
  64
[torch.LongStorage of size 3]

755703.5030365	
 512
  43
  64
[torch.LongStorage of size 3]

754936.64270401	
 512
  43
  64
[torch.LongStorage of size 3]

754131.711483	
 512
  43
  64
[torch.LongStorage of size 3]

753513.41911316	
 512
  43
  64
[torch.LongStorage of size 3]

753000.99382401	
 512
  43
  64
[torch.LongStorage of size 3]

752331.45488739	
 512
  43
  64
[torch.LongStorage of size 3]

751972.93861389	
 512
  43
  64
[torch.LongStorage of size 3]

751395.14230728	
 512
  43
  64
[torch.LongStorage of size 3]

750959.76495743	
 512
  43
  64
[torch.LongStorage of size 3]

750378.11323166	
 512
  43
  64
[torch.LongStorage of size 3]

749738.38813782	
 512
  43
  64
[torch.LongStorage of size 3]

749236.76168442	
 512
  43
  64
[torch.LongStorage of size 3]

748800.09469986	
 512
  43
  64
[torch.LongStorage of size 3]

748330.53218842	
 512
  43
  64
[torch.LongStorage of size 3]

747855.81256866	
 512
  43
  64
[torch.LongStorage of size 3]

747314.18493271	
 512
  43
  64
[torch.LongStorage of size 3]

746520.85021973	
 512
  43
  64
[torch.LongStorage of size 3]

745907.63530731	
 512
  43
  64
[torch.LongStorage of size 3]

745243.57440948	
 512
  43
  64
[torch.LongStorage of size 3]

744943.23564529	
 512
  43
  64
[torch.LongStorage of size 3]

744408.64429474	
 512
  43
  64
[torch.LongStorage of size 3]

743938.23436737	
 512
  43
  64
[torch.LongStorage of size 3]

743480.64376831	
 512
  43
  64
[torch.LongStorage of size 3]

742945.53937912	
 512
  43
  64
[torch.LongStorage of size 3]

742281.95680618	
 512
  43
  64
[torch.LongStorage of size 3]

741799.71700668	
 512
  43
  64
[torch.LongStorage of size 3]

741395.54662704	
 512
  43
  64
[torch.LongStorage of size 3]

741046.24771118	
 512
  43
  64
[torch.LongStorage of size 3]

740673.31214905	
 512
  43
  64
[torch.LongStorage of size 3]

740255.04026413	
 512
  43
  64
[torch.LongStorage of size 3]

739578.20308685	
 512
  43
  64
[torch.LongStorage of size 3]

738921.68363571	
 512
  43
  64
[torch.LongStorage of size 3]

738383.4413147	
 512
  43
  64
[torch.LongStorage of size 3]

738055.23519516	
 512
  43
  64
[torch.LongStorage of size 3]

737775.07577896	
 512
  43
  64
[torch.LongStorage of size 3]

737423.26351166	
 512
  43
  64
[torch.LongStorage of size 3]

736772.8401947	
 512
  43
  64
[torch.LongStorage of size 3]

736160.72780609	
 512
  43
  64
[torch.LongStorage of size 3]

735786.74501419	
 512
  43
  64
[torch.LongStorage of size 3]

735480.10616302	
 512
  43
  64
[torch.LongStorage of size 3]

735015.19948959	
 512
  43
  64
[torch.LongStorage of size 3]

734420.08735657	
 512
  43
  64
[torch.LongStorage of size 3]

734003.78793716	
 512
  43
  64
[torch.LongStorage of size 3]

733692.74089813	
 512
  43
  64
[torch.LongStorage of size 3]

733271.28744125	
Iteration 333 / 1000	
  Content 1 loss: 549832.031250	
  Style 1 loss: 7415.399933	
  Style 2 loss: 19674.649048	
  Style 3 loss: 8794.551849	
  Style 4 loss: 146667.041016	
  Style 5 loss: 887.614346	
  Total loss: 733271.287441	
s/s.jpg_out_prepost_333.png	
 512
  43
  64
[torch.LongStorage of size 3]

732868.19469452	
 512
  43
  64
[torch.LongStorage of size 3]

732278.81954193	
 512
  43
  64
[torch.LongStorage of size 3]

731738.59674454	
 512
  43
  64
[torch.LongStorage of size 3]

731279.21203613	
 512
  43
  64
[torch.LongStorage of size 3]

730959.36122894	
 512
  43
  64
[torch.LongStorage of size 3]

730535.08911133	
 512
  43
  64
[torch.LongStorage of size 3]

730170.40807724	
 512
  43
  64
[torch.LongStorage of size 3]

729769.73398209	
 512
  43
  64
[torch.LongStorage of size 3]

729351.17231369	
 512
  43
  64
[torch.LongStorage of size 3]

729008.57301712	
 512
  43
  64
[torch.LongStorage of size 3]

728611.79933548	
 512
  43
  64
[torch.LongStorage of size 3]

728100.54712296	
 512
  43
  64
[torch.LongStorage of size 3]

727655.38562775	
 512
  43
  64
[torch.LongStorage of size 3]

727311.39503479	
 512
  43
  64
[torch.LongStorage of size 3]

726939.4168663	
 512
  43
  64
[torch.LongStorage of size 3]

726585.52585602	
 512
  43
  64
[torch.LongStorage of size 3]

726241.68380737	
 512
  43
  64
[torch.LongStorage of size 3]

725895.31448364	
 512
  43
  64
[torch.LongStorage of size 3]

725528.61667633	
 512
  43
  64
[torch.LongStorage of size 3]

725119.52001572	
 512
  43
  64
[torch.LongStorage of size 3]

724753.7625885	
 512
  43
  64
[torch.LongStorage of size 3]

724402.98303604	
 512
  43
  64
[torch.LongStorage of size 3]

723891.41769409	
 512
  43
  64
[torch.LongStorage of size 3]

723587.37394333	
 512
  43
  64
[torch.LongStorage of size 3]

723307.70442963	
 512
  43
  64
[torch.LongStorage of size 3]

723034.76837158	
 512
  43
  64
[torch.LongStorage of size 3]

722799.42193985	
 512
  43
  64
[torch.LongStorage of size 3]

722487.52906799	
 512
  43
  64
[torch.LongStorage of size 3]

721966.92140579	
 512
  43
  64
[torch.LongStorage of size 3]

721490.86324692	
 512
  43
  64
[torch.LongStorage of size 3]

721069.47120667	
 512
  43
  64
[torch.LongStorage of size 3]

720783.53006363	
 512
  43
  64
[torch.LongStorage of size 3]

720499.78181839	
 512
  43
  64
[torch.LongStorage of size 3]

720121.31557465	
 512
  43
  64
[torch.LongStorage of size 3]

719832.79928207	
 512
  43
  64
[torch.LongStorage of size 3]

719553.25119019	
 512
  43
  64
[torch.LongStorage of size 3]

719303.95133972	
 512
  43
  64
[torch.LongStorage of size 3]

719086.62143707	
 512
  43
  64
[torch.LongStorage of size 3]

718621.92918777	
 512
  43
  64
[torch.LongStorage of size 3]

718238.74734879	
 512
  43
  64
[torch.LongStorage of size 3]

717993.77542496	
 512
  43
  64
[torch.LongStorage of size 3]

717626.10555649	
 512
  43
  64
[torch.LongStorage of size 3]

717335.75548172	
 512
  43
  64
[torch.LongStorage of size 3]

716991.62595749	
 512
  43
  64
[torch.LongStorage of size 3]

716694.52316284	
 512
  43
  64
[torch.LongStorage of size 3]

716411.37266159	
 512
  43
  64
[torch.LongStorage of size 3]

716133.57456207	
 512
  43
  64
[torch.LongStorage of size 3]

715741.76250458	
 512
  43
  64
[torch.LongStorage of size 3]

715417.1805954	
 512
  43
  64
[torch.LongStorage of size 3]

715159.81674194	
 512
  43
  64
[torch.LongStorage of size 3]

714832.36431122	
 512
  43
  64
[torch.LongStorage of size 3]

714505.07038116	
 512
  43
  64
[torch.LongStorage of size 3]

714132.39681244	
 512
  43
  64
[torch.LongStorage of size 3]

713837.95545578	
 512
  43
  64
[torch.LongStorage of size 3]

713584.70815659	
 512
  43
  64
[torch.LongStorage of size 3]

713308.77418518	
 512
  43
  64
[torch.LongStorage of size 3]

713062.44478226	
 512
  43
  64
[torch.LongStorage of size 3]

712848.09337616	
 512
  43
  64
[torch.LongStorage of size 3]

712541.39678955	
 512
  43
  64
[torch.LongStorage of size 3]

712248.05585861	
 512
  43
  64
[torch.LongStorage of size 3]

711972.26083755	
 512
  43
  64
[torch.LongStorage of size 3]

711683.1070137	
 512
  43
  64
[torch.LongStorage of size 3]

711486.62446976	
 512
  43
  64
[torch.LongStorage of size 3]

711279.14489746	
 512
  43
  64
[torch.LongStorage of size 3]

711009.73674774	
 512
  43
  64
[torch.LongStorage of size 3]

710779.15424347	
 512
  43
  64
[torch.LongStorage of size 3]

710554.72915649	
 512
  43
  64
[torch.LongStorage of size 3]

710218.75699997	
 512
  43
  64
[torch.LongStorage of size 3]

709955.21116257	
 512
  43
  64
[torch.LongStorage of size 3]

709682.42637634	
 512
  43
  64
[torch.LongStorage of size 3]

709513.43994141	
 512
  43
  64
[torch.LongStorage of size 3]

709264.40626144	
 512
  43
  64
[torch.LongStorage of size 3]

709038.95029068	
 512
  43
  64
[torch.LongStorage of size 3]

708844.88536835	
 512
  43
  64
[torch.LongStorage of size 3]

708661.49326324	
 512
  43
  64
[torch.LongStorage of size 3]

708449.75952148	
 512
  43
  64
[torch.LongStorage of size 3]

708187.88431168	
 512
  43
  64
[torch.LongStorage of size 3]

707886.96773529	
 512
  43
  64
[torch.LongStorage of size 3]

707736.15301132	
 512
  43
  64
[torch.LongStorage of size 3]

707518.19282532	
 512
  43
  64
[torch.LongStorage of size 3]

707276.09220505	
 512
  43
  64
[torch.LongStorage of size 3]

707056.0111618	
 512
  43
  64
[torch.LongStorage of size 3]

706881.03118896	
 512
  43
  64
[torch.LongStorage of size 3]

706672.64060974	
 512
  43
  64
[torch.LongStorage of size 3]

706520.63669205	
 512
  43
  64
[torch.LongStorage of size 3]

706334.10686493	
 512
  43
  64
[torch.LongStorage of size 3]

706097.75447845	
 512
  43
  64
[torch.LongStorage of size 3]

705885.29661179	
 512
  43
  64
[torch.LongStorage of size 3]

705679.6267128	
 512
  43
  64
[torch.LongStorage of size 3]

705444.62984085	
 512
  43
  64
[torch.LongStorage of size 3]

705237.69363403	
 512
  43
  64
[torch.LongStorage of size 3]

705032.01828003	
 512
  43
  64
[torch.LongStorage of size 3]

704789.33153152	
 512
  43
  64
[torch.LongStorage of size 3]

704569.53428268	
 512
  43
  64
[torch.LongStorage of size 3]

704367.69329071	
 512
  43
  64
[torch.LongStorage of size 3]

704223.51360321	
 512
  43
  64
[torch.LongStorage of size 3]

704097.37840652	
 512
  43
  64
[torch.LongStorage of size 3]

703915.39764404	
 512
  43
  64
[torch.LongStorage of size 3]

703705.37145615	
 512
  43
  64
[torch.LongStorage of size 3]

703470.98730087	
 512
  43
  64
[torch.LongStorage of size 3]

703236.92382812	
 512
  43
  64
[torch.LongStorage of size 3]

703090.98247528	
 512
  43
  64
[torch.LongStorage of size 3]

702972.03325272	
 512
  43
  64
[torch.LongStorage of size 3]

702785.27919769	
 512
  43
  64
[torch.LongStorage of size 3]

702557.60967255	
 512
  43
  64
[torch.LongStorage of size 3]

702364.40517426	
 512
  43
  64
[torch.LongStorage of size 3]

702215.09410858	
 512
  43
  64
[torch.LongStorage of size 3]

702080.82576752	
 512
  43
  64
[torch.LongStorage of size 3]

701901.27029419	
 512
  43
  64
[torch.LongStorage of size 3]

701669.28890228	
 512
  43
  64
[torch.LongStorage of size 3]

701458.18346024	
 512
  43
  64
[torch.LongStorage of size 3]

701330.74636459	
 512
  43
  64
[torch.LongStorage of size 3]

701206.26068115	
 512
  43
  64
[torch.LongStorage of size 3]

701053.93444061	
 512
  43
  64
[torch.LongStorage of size 3]

700842.70277023	
 512
  43
  64
[torch.LongStorage of size 3]

700639.34391022	
 512
  43
  64
[torch.LongStorage of size 3]

700494.35541153	
 512
  43
  64
[torch.LongStorage of size 3]

700341.00721359	
 512
  43
  64
[torch.LongStorage of size 3]

700162.59222031	
 512
  43
  64
[torch.LongStorage of size 3]

699972.62834549	
 512
  43
  64
[torch.LongStorage of size 3]

699809.53741074	
 512
  43
  64
[torch.LongStorage of size 3]

699647.99451828	
 512
  43
  64
[torch.LongStorage of size 3]

699444.38022614	
 512
  43
  64
[torch.LongStorage of size 3]

699347.51468658	
 512
  43
  64
[torch.LongStorage of size 3]

699183.1537056	
 512
  43
  64
[torch.LongStorage of size 3]

699044.12334442	
 512
  43
  64
[torch.LongStorage of size 3]

698902.14172363	
 512
  43
  64
[torch.LongStorage of size 3]

698730.46041489	
 512
  43
  64
[torch.LongStorage of size 3]

698583.90464783	
 512
  43
  64
[torch.LongStorage of size 3]

698480.61519623	
 512
  43
  64
[torch.LongStorage of size 3]

698359.72486496	
 512
  43
  64
[torch.LongStorage of size 3]

698229.52547073	
 512
  43
  64
[torch.LongStorage of size 3]

698098.50645065	
 512
  43
  64
[torch.LongStorage of size 3]

697962.58394241	
 512
  43
  64
[torch.LongStorage of size 3]

697824.76074219	
 512
  43
  64
[torch.LongStorage of size 3]

697644.43893433	
 512
  43
  64
[torch.LongStorage of size 3]

697454.4990921	
 512
  43
  64
[torch.LongStorage of size 3]

697345.08773804	
 512
  43
  64
[torch.LongStorage of size 3]

697221.13451004	
 512
  43
  64
[torch.LongStorage of size 3]

697071.51691437	
 512
  43
  64
[torch.LongStorage of size 3]

696898.76085281	
 512
  43
  64
[torch.LongStorage of size 3]

696740.47843933	
 512
  43
  64
[torch.LongStorage of size 3]

696628.21817398	
 512
  43
  64
[torch.LongStorage of size 3]

696482.15175629	
 512
  43
  64
[torch.LongStorage of size 3]

696330.69856644	
 512
  43
  64
[torch.LongStorage of size 3]

696190.15024185	
 512
  43
  64
[torch.LongStorage of size 3]

696077.6770401	
 512
  43
  64
[torch.LongStorage of size 3]

696000.30277252	
 512
  43
  64
[torch.LongStorage of size 3]

695850.38497925	
 512
  43
  64
[torch.LongStorage of size 3]

695687.87412643	
 512
  43
  64
[torch.LongStorage of size 3]

695558.89774323	
 512
  43
  64
[torch.LongStorage of size 3]

695418.49220276	
 512
  43
  64
[torch.LongStorage of size 3]

695313.31249237	
 512
  43
  64
[torch.LongStorage of size 3]

695198.2336235	
 512
  43
  64
[torch.LongStorage of size 3]

695064.90587234	
 512
  43
  64
[torch.LongStorage of size 3]

694932.49828339	
 512
  43
  64
[torch.LongStorage of size 3]

694819.26527023	
 512
  43
  64
[torch.LongStorage of size 3]

694719.00720596	
 512
  43
  64
[torch.LongStorage of size 3]

694595.39953232	
 512
  43
  64
[torch.LongStorage of size 3]

694440.1140213	
 512
  43
  64
[torch.LongStorage of size 3]

694333.1593132	
 512
  43
  64
[torch.LongStorage of size 3]

694247.70534515	
 512
  43
  64
[torch.LongStorage of size 3]

694141.78022385	
 512
  43
  64
[torch.LongStorage of size 3]

694047.05818176	
 512
  43
  64
[torch.LongStorage of size 3]

693920.68626404	
 512
  43
  64
[torch.LongStorage of size 3]

693790.91077805	
 512
  43
  64
[torch.LongStorage of size 3]

693662.60454178	
 512
  43
  64
[torch.LongStorage of size 3]

693583.23579788	
 512
  43
  64
[torch.LongStorage of size 3]

693482.63191223	
 512
  43
  64
[torch.LongStorage of size 3]

693385.13525009	
 512
  43
  64
[torch.LongStorage of size 3]

693229.54919815	
 512
  43
  64
[torch.LongStorage of size 3]

693095.4168129	
 512
  43
  64
[torch.LongStorage of size 3]

692990.73442459	
 512
  43
  64
[torch.LongStorage of size 3]

692891.55193329	
 512
  43
  64
[torch.LongStorage of size 3]

692758.32040787	
 512
  43
  64
[torch.LongStorage of size 3]

692649.54967499	
 512
  43
  64
[torch.LongStorage of size 3]

692516.90151215	
 512
  43
  64
[torch.LongStorage of size 3]

692403.33608627	
 512
  43
  64
[torch.LongStorage of size 3]

692277.26068497	
 512
  43
  64
[torch.LongStorage of size 3]

692183.30095291	
 512
  43
  64
[torch.LongStorage of size 3]

692103.09911728	
 512
  43
  64
[torch.LongStorage of size 3]

692003.46502304	
 512
  43
  64
[torch.LongStorage of size 3]

691898.86793137	
 512
  43
  64
[torch.LongStorage of size 3]

691804.00371552	
 512
  43
  64
[torch.LongStorage of size 3]

691720.73471069	
 512
  43
  64
[torch.LongStorage of size 3]

691637.37947464	
 512
  43
  64
[torch.LongStorage of size 3]

691566.13290787	
 512
  43
  64
[torch.LongStorage of size 3]

691445.04453659	
 512
  43
  64
[torch.LongStorage of size 3]

691356.21463776	
 512
  43
  64
[torch.LongStorage of size 3]

691281.47220612	
 512
  43
  64
[torch.LongStorage of size 3]

691205.99292755	
 512
  43
  64
[torch.LongStorage of size 3]

691124.76202011	
 512
  43
  64
[torch.LongStorage of size 3]

690997.1439743	
 512
  43
  64
[torch.LongStorage of size 3]

690888.27989578	
 512
  43
  64
[torch.LongStorage of size 3]

690770.06708145	
 512
  43
  64
[torch.LongStorage of size 3]

690697.89522171	
 512
  43
  64
[torch.LongStorage of size 3]

690615.76797485	
 512
  43
  64
[torch.LongStorage of size 3]

690522.89907455	
 512
  43
  64
[torch.LongStorage of size 3]

690433.50206375	
 512
  43
  64
[torch.LongStorage of size 3]

690332.53221512	
 512
  43
  64
[torch.LongStorage of size 3]

690239.3614006	
 512
  43
  64
[torch.LongStorage of size 3]

690130.25579453	
 512
  43
  64
[torch.LongStorage of size 3]

690067.32936859	
 512
  43
  64
[torch.LongStorage of size 3]

689984.94840622	
 512
  43
  64
[torch.LongStorage of size 3]

689896.86937332	
 512
  43
  64
[torch.LongStorage of size 3]

689798.93253326	
 512
  43
  64
[torch.LongStorage of size 3]

689724.12059784	
 512
  43
  64
[torch.LongStorage of size 3]

689646.85344696	
 512
  43
  64
[torch.LongStorage of size 3]

689565.94051361	
 512
  43
  64
[torch.LongStorage of size 3]

689476.71930313	
 512
  43
  64
[torch.LongStorage of size 3]

689385.94280243	
 512
  43
  64
[torch.LongStorage of size 3]

689301.45862579	
 512
  43
  64
[torch.LongStorage of size 3]

689215.24772644	
 512
  43
  64
[torch.LongStorage of size 3]

689140.38473129	
 512
  43
  64
[torch.LongStorage of size 3]

689051.51609421	
 512
  43
  64
[torch.LongStorage of size 3]

688957.84671783	
 512
  43
  64
[torch.LongStorage of size 3]

688857.13705063	
 512
  43
  64
[torch.LongStorage of size 3]

688767.39692688	
 512
  43
  64
[torch.LongStorage of size 3]

688672.39393234	
 512
  43
  64
[torch.LongStorage of size 3]

688593.17991257	
 512
  43
  64
[torch.LongStorage of size 3]

688503.06064606	
 512
  43
  64
[torch.LongStorage of size 3]

688410.84129333	
 512
  43
  64
[torch.LongStorage of size 3]

688356.06245041	
 512
  43
  64
[torch.LongStorage of size 3]

688249.01906967	
 512
  43
  64
[torch.LongStorage of size 3]

688178.04019928	
 512
  43
  64
[torch.LongStorage of size 3]

688107.33400345	
 512
  43
  64
[torch.LongStorage of size 3]

688045.40519714	
 512
  43
  64
[torch.LongStorage of size 3]

687952.39801407	
 512
  43
  64
[torch.LongStorage of size 3]

687855.66646576	
 512
  43
  64
[torch.LongStorage of size 3]

687767.80719757	
 512
  43
  64
[torch.LongStorage of size 3]

687689.81946945	
 512
  43
  64
[torch.LongStorage of size 3]

687621.64579391	
 512
  43
  64
[torch.LongStorage of size 3]

687554.18638229	
 512
  43
  64
[torch.LongStorage of size 3]

687475.41391373	
 512
  43
  64
[torch.LongStorage of size 3]

687427.37379074	
 512
  43
  64
[torch.LongStorage of size 3]

687386.69834137	
 512
  43
  64
[torch.LongStorage of size 3]

687329.32151794	
 512
  43
  64
[torch.LongStorage of size 3]

687254.76396561	
 512
  43
  64
[torch.LongStorage of size 3]

687181.52723312	
 512
  43
  64
[torch.LongStorage of size 3]

687112.72115707	
 512
  43
  64
[torch.LongStorage of size 3]

687037.25664139	
 512
  43
  64
[torch.LongStorage of size 3]

686964.28379059	
 512
  43
  64
[torch.LongStorage of size 3]

686886.40911102	
 512
  43
  64
[torch.LongStorage of size 3]

686831.82819366	
 512
  43
  64
[torch.LongStorage of size 3]

686768.59781265	
 512
  43
  64
[torch.LongStorage of size 3]

686697.46070862	
 512
  43
  64
[torch.LongStorage of size 3]

686613.51701736	
 512
  43
  64
[torch.LongStorage of size 3]

686541.04942322	
 512
  43
  64
[torch.LongStorage of size 3]

686455.34580231	
 512
  43
  64
[torch.LongStorage of size 3]

686402.18069077	
 512
  43
  64
[torch.LongStorage of size 3]

686339.4475174	
 512
  43
  64
[torch.LongStorage of size 3]

686272.12783813	
 512
  43
  64
[torch.LongStorage of size 3]

686197.03170776	
 512
  43
  64
[torch.LongStorage of size 3]

686131.10467911	
 512
  43
  64
[torch.LongStorage of size 3]

686070.06464005	
 512
  43
  64
[torch.LongStorage of size 3]

686026.11507416	
 512
  43
  64
[torch.LongStorage of size 3]

685967.22858429	
 512
  43
  64
[torch.LongStorage of size 3]

685893.04803848	
 512
  43
  64
[torch.LongStorage of size 3]

685822.32229233	
 512
  43
  64
[torch.LongStorage of size 3]

685763.0210495	
 512
  43
  64
[torch.LongStorage of size 3]

685701.43821716	
 512
  43
  64
[torch.LongStorage of size 3]

685641.68212891	
 512
  43
  64
[torch.LongStorage of size 3]

685575.883255	
 512
  43
  64
[torch.LongStorage of size 3]

685528.39700699	
 512
  43
  64
[torch.LongStorage of size 3]

685472.80574799	
 512
  43
  64
[torch.LongStorage of size 3]

685419.28211212	
 512
  43
  64
[torch.LongStorage of size 3]

685344.25416946	
 512
  43
  64
[torch.LongStorage of size 3]

685288.21022034	
 512
  43
  64
[torch.LongStorage of size 3]

685229.53269958	
 512
  43
  64
[torch.LongStorage of size 3]

685181.34443283	
 512
  43
  64
[torch.LongStorage of size 3]

685116.81253433	
 512
  43
  64
[torch.LongStorage of size 3]

685069.20303345	
 512
  43
  64
[torch.LongStorage of size 3]

684996.82941437	
 512
  43
  64
[torch.LongStorage of size 3]

684947.34191895	
 512
  43
  64
[torch.LongStorage of size 3]

684884.33616638	
 512
  43
  64
[torch.LongStorage of size 3]

684813.12602997	
 512
  43
  64
[torch.LongStorage of size 3]

684755.13216019	
 512
  43
  64
[torch.LongStorage of size 3]

684698.78978729	
 512
  43
  64
[torch.LongStorage of size 3]

684649.39336777	
 512
  43
  64
[torch.LongStorage of size 3]

684576.26104355	
 512
  43
  64
[torch.LongStorage of size 3]

684537.39004135	
 512
  43
  64
[torch.LongStorage of size 3]

684474.78696823	
 512
  43
  64
[torch.LongStorage of size 3]

684427.79455185	
 512
  43
  64
[torch.LongStorage of size 3]

684371.0643959	
 512
  43
  64
[torch.LongStorage of size 3]

684315.69490433	
 512
  43
  64
[torch.LongStorage of size 3]

684261.02882385	
 512
  43
  64
[torch.LongStorage of size 3]

684210.42253494	
 512
  43
  64
[torch.LongStorage of size 3]

684157.22732544	
 512
  43
  64
[torch.LongStorage of size 3]

684114.4004631	
 512
  43
  64
[torch.LongStorage of size 3]

684063.40015411	
 512
  43
  64
[torch.LongStorage of size 3]

684007.02539444	
 512
  43
  64
[torch.LongStorage of size 3]

683948.51486206	
 512
  43
  64
[torch.LongStorage of size 3]

683905.79156876	
 512
  43
  64
[torch.LongStorage of size 3]

683873.47822189	
 512
  43
  64
[torch.LongStorage of size 3]

683826.60369873	
 512
  43
  64
[torch.LongStorage of size 3]

683760.27429581	
 512
  43
  64
[torch.LongStorage of size 3]

683693.58568192	
 512
  43
  64
[torch.LongStorage of size 3]

683626.21709824	
 512
  43
  64
[torch.LongStorage of size 3]

683582.53288269	
 512
  43
  64
[torch.LongStorage of size 3]

683528.16305161	
 512
  43
  64
[torch.LongStorage of size 3]

683476.82857513	
 512
  43
  64
[torch.LongStorage of size 3]

683424.01506424	
 512
  43
  64
[torch.LongStorage of size 3]

683358.4674263	
 512
  43
  64
[torch.LongStorage of size 3]

683300.83486557	
 512
  43
  64
[torch.LongStorage of size 3]

683236.36459351	
 512
  43
  64
[torch.LongStorage of size 3]

683206.80818558	
 512
  43
  64
[torch.LongStorage of size 3]

683164.38045502	
 512
  43
  64
[torch.LongStorage of size 3]

683115.14785767	
 512
  43
  64
[torch.LongStorage of size 3]

683064.04006958	
 512
  43
  64
[torch.LongStorage of size 3]

683012.91236877	
 512
  43
  64
[torch.LongStorage of size 3]

682950.63138962	
 512
  43
  64
[torch.LongStorage of size 3]

682905.57813644	
 512
  43
  64
[torch.LongStorage of size 3]

682852.50255585	
 512
  43
  64
[torch.LongStorage of size 3]

682800.43991089	
 512
  43
  64
[torch.LongStorage of size 3]

682750.29806137	
 512
  43
  64
[torch.LongStorage of size 3]

682695.9094429	
 512
  43
  64
[torch.LongStorage of size 3]

682659.60361481	
 512
  43
  64
[torch.LongStorage of size 3]

682621.23434067	
 512
  43
  64
[torch.LongStorage of size 3]

682574.07669067	
 512
  43
  64
[torch.LongStorage of size 3]

682514.42424774	
 512
  43
  64
[torch.LongStorage of size 3]

682457.72281647	
 512
  43
  64
[torch.LongStorage of size 3]

682396.28520966	
 512
  43
  64
[torch.LongStorage of size 3]

682352.34268188	
 512
  43
  64
[torch.LongStorage of size 3]

682299.07281876	
 512
  43
  64
[torch.LongStorage of size 3]

682249.34005737	
 512
  43
  64
[torch.LongStorage of size 3]

682196.47686005	
 512
  43
  64
[torch.LongStorage of size 3]

682144.3914032	
 512
  43
  64
[torch.LongStorage of size 3]

682089.21783447	
 512
  43
  64
[torch.LongStorage of size 3]

682044.3106842	
 512
  43
  64
[torch.LongStorage of size 3]

681994.65530396	
 512
  43
  64
[torch.LongStorage of size 3]

681953.82392883	
 512
  43
  64
[torch.LongStorage of size 3]

681895.52455902	
 512
  43
  64
[torch.LongStorage of size 3]

681862.64389038	
Iteration 666 / 1000	
  Content 1 loss: 537521.796875	
  Style 1 loss: 1376.342964	
  Style 2 loss: 6142.359543	
  Style 3 loss: 6658.582306	
  Style 4 loss: 129262.487793	
  Style 5 loss: 901.074409	
  Total loss: 681862.643890	
s/s.jpg_out_prepost_666.png	
 512
  43
  64
[torch.LongStorage of size 3]

681800.51054001	
 512
  43
  64
[torch.LongStorage of size 3]

681762.72073746	
 512
  43
  64
[torch.LongStorage of size 3]

681737.26991653	
 512
  43
  64
[torch.LongStorage of size 3]

681696.47066116	
 512
  43
  64
[torch.LongStorage of size 3]

681655.76852798	
 512
  43
  64
[torch.LongStorage of size 3]

681619.21892166	
 512
  43
  64
[torch.LongStorage of size 3]

681579.68488693	
 512
  43
  64
[torch.LongStorage of size 3]

681544.49047089	
 512
  43
  64
[torch.LongStorage of size 3]

681497.16732025	
 512
  43
  64
[torch.LongStorage of size 3]

681448.72671127	
 512
  43
  64
[torch.LongStorage of size 3]

681397.23155975	
 512
  43
  64
[torch.LongStorage of size 3]

681344.29765701	
 512
  43
  64
[torch.LongStorage of size 3]

681291.92489624	
 512
  43
  64
[torch.LongStorage of size 3]

681257.36560822	
 512
  43
  64
[torch.LongStorage of size 3]

681216.63766861	
 512
  43
  64
[torch.LongStorage of size 3]

681176.24227524	
 512
  43
  64
[torch.LongStorage of size 3]

681133.02650452	
 512
  43
  64
[torch.LongStorage of size 3]

681084.2455101	
 512
  43
  64
[torch.LongStorage of size 3]

681029.3860054	
 512
  43
  64
[torch.LongStorage of size 3]

680984.59022522	
 512
  43
  64
[torch.LongStorage of size 3]

680939.84354019	
 512
  43
  64
[torch.LongStorage of size 3]

680896.88072205	
 512
  43
  64
[torch.LongStorage of size 3]

680845.93420029	
 512
  43
  64
[torch.LongStorage of size 3]

680820.14959335	
 512
  43
  64
[torch.LongStorage of size 3]

680765.08001328	
 512
  43
  64
[torch.LongStorage of size 3]

680725.2085495	
 512
  43
  64
[torch.LongStorage of size 3]

680687.20876694	
 512
  43
  64
[torch.LongStorage of size 3]

680656.49610519	
 512
  43
  64
[torch.LongStorage of size 3]

680622.88599014	
 512
  43
  64
[torch.LongStorage of size 3]

680586.55658722	
 512
  43
  64
[torch.LongStorage of size 3]

680547.81251907	
 512
  43
  64
[torch.LongStorage of size 3]

680504.20291901	
 512
  43
  64
[torch.LongStorage of size 3]

680460.94392776	
 512
  43
  64
[torch.LongStorage of size 3]

680433.63248825	
 512
  43
  64
[torch.LongStorage of size 3]

680405.03765106	
 512
  43
  64
[torch.LongStorage of size 3]

680364.82355118	
 512
  43
  64
[torch.LongStorage of size 3]

680331.51184082	
 512
  43
  64
[torch.LongStorage of size 3]

680285.625	
 512
  43
  64
[torch.LongStorage of size 3]

680254.2707634	
 512
  43
  64
[torch.LongStorage of size 3]

680211.30315781	
 512
  43
  64
[torch.LongStorage of size 3]

680182.31998444	
 512
  43
  64
[torch.LongStorage of size 3]

680147.59738922	
 512
  43
  64
[torch.LongStorage of size 3]

680108.26328278	
 512
  43
  64
[torch.LongStorage of size 3]

680073.76317978	
 512
  43
  64
[torch.LongStorage of size 3]

680036.52786255	
 512
  43
  64
[torch.LongStorage of size 3]

680014.04191971	
 512
  43
  64
[torch.LongStorage of size 3]

679985.32312393	
 512
  43
  64
[torch.LongStorage of size 3]

679959.82498169	
 512
  43
  64
[torch.LongStorage of size 3]

679921.8258667	
 512
  43
  64
[torch.LongStorage of size 3]

679888.06245804	
 512
  43
  64
[torch.LongStorage of size 3]

679849.11678314	
 512
  43
  64
[torch.LongStorage of size 3]

679816.78735733	
 512
  43
  64
[torch.LongStorage of size 3]

679773.57023239	
 512
  43
  64
[torch.LongStorage of size 3]

679744.17928696	
 512
  43
  64
[torch.LongStorage of size 3]

679706.80984497	
 512
  43
  64
[torch.LongStorage of size 3]

679669.4402504	
 512
  43
  64
[torch.LongStorage of size 3]

679636.39780045	
 512
  43
  64
[torch.LongStorage of size 3]

679600.84589005	
 512
  43
  64
[torch.LongStorage of size 3]

679572.98685074	
 512
  43
  64
[torch.LongStorage of size 3]

679549.47330475	
 512
  43
  64
[torch.LongStorage of size 3]

679517.55163193	
 512
  43
  64
[torch.LongStorage of size 3]

679489.73171234	
 512
  43
  64
[torch.LongStorage of size 3]

679456.72548294	
 512
  43
  64
[torch.LongStorage of size 3]

679430.18280029	
 512
  43
  64
[torch.LongStorage of size 3]

679405.55458069	
 512
  43
  64
[torch.LongStorage of size 3]

679373.01761627	
 512
  43
  64
[torch.LongStorage of size 3]

679336.32108688	
 512
  43
  64
[torch.LongStorage of size 3]

679297.90456772	
 512
  43
  64
[torch.LongStorage of size 3]

679263.46569061	
 512
  43
  64
[torch.LongStorage of size 3]

679226.38767242	
 512
  43
  64
[torch.LongStorage of size 3]

679201.10845566	
 512
  43
  64
[torch.LongStorage of size 3]

679160.58872223	
 512
  43
  64
[torch.LongStorage of size 3]

679133.59872818	
 512
  43
  64
[torch.LongStorage of size 3]

679103.05967331	
 512
  43
  64
[torch.LongStorage of size 3]

679069.60012436	
 512
  43
  64
[torch.LongStorage of size 3]

679034.33866501	
 512
  43
  64
[torch.LongStorage of size 3]

679000.31497955	
 512
  43
  64
[torch.LongStorage of size 3]

678966.96819305	
 512
  43
  64
[torch.LongStorage of size 3]

678943.28420639	
 512
  43
  64
[torch.LongStorage of size 3]

678922.06775665	
 512
  43
  64
[torch.LongStorage of size 3]

678892.73794174	
 512
  43
  64
[torch.LongStorage of size 3]

678860.79799652	
 512
  43
  64
[torch.LongStorage of size 3]

678828.30575943	
 512
  43
  64
[torch.LongStorage of size 3]

678794.19065475	
 512
  43
  64
[torch.LongStorage of size 3]

678769.84931946	
 512
  43
  64
[torch.LongStorage of size 3]

678744.36029434	
 512
  43
  64
[torch.LongStorage of size 3]

678717.27487564	
 512
  43
  64
[torch.LongStorage of size 3]

678689.56539154	
 512
  43
  64
[torch.LongStorage of size 3]

678658.52563858	
 512
  43
  64
[torch.LongStorage of size 3]

678622.17323303	
 512
  43
  64
[torch.LongStorage of size 3]

678592.33007431	
 512
  43
  64
[torch.LongStorage of size 3]

678555.90135574	
 512
  43
  64
[torch.LongStorage of size 3]

678531.53877258	
 512
  43
  64
[torch.LongStorage of size 3]

678494.24625397	
 512
  43
  64
[torch.LongStorage of size 3]

678466.93101883	
 512
  43
  64
[torch.LongStorage of size 3]

678438.10188293	
 512
  43
  64
[torch.LongStorage of size 3]

678407.95497894	
 512
  43
  64
[torch.LongStorage of size 3]

678378.71955872	
 512
  43
  64
[torch.LongStorage of size 3]

678347.05871582	
 512
  43
  64
[torch.LongStorage of size 3]

678317.15896606	
 512
  43
  64
[torch.LongStorage of size 3]

678286.83307648	
 512
  43
  64
[torch.LongStorage of size 3]

678256.02710724	
 512
  43
  64
[torch.LongStorage of size 3]

678230.11472702	
 512
  43
  64
[torch.LongStorage of size 3]

678194.72932816	
 512
  43
  64
[torch.LongStorage of size 3]

678180.33269882	
 512
  43
  64
[torch.LongStorage of size 3]

678156.85625076	
 512
  43
  64
[torch.LongStorage of size 3]

678128.57910156	
 512
  43
  64
[torch.LongStorage of size 3]

678101.46682739	
 512
  43
  64
[torch.LongStorage of size 3]

678076.9893074	
 512
  43
  64
[torch.LongStorage of size 3]

678058.61848831	
 512
  43
  64
[torch.LongStorage of size 3]

678036.54628754	
 512
  43
  64
[torch.LongStorage of size 3]

678009.52896118	
 512
  43
  64
[torch.LongStorage of size 3]

677981.59412384	
 512
  43
  64
[torch.LongStorage of size 3]

677949.04333115	
 512
  43
  64
[torch.LongStorage of size 3]

677927.88066864	
 512
  43
  64
[torch.LongStorage of size 3]

677896.03599548	
 512
  43
  64
[torch.LongStorage of size 3]

677871.81661606	
 512
  43
  64
[torch.LongStorage of size 3]

677844.21714783	
 512
  43
  64
[torch.LongStorage of size 3]

677817.88202286	
 512
  43
  64
[torch.LongStorage of size 3]

677788.0828476	
 512
  43
  64
[torch.LongStorage of size 3]

677760.58942795	
 512
  43
  64
[torch.LongStorage of size 3]

677727.56071091	
 512
  43
  64
[torch.LongStorage of size 3]

677708.51417542	
 512
  43
  64
[torch.LongStorage of size 3]

677677.33463287	
 512
  43
  64
[torch.LongStorage of size 3]

677653.53580475	
 512
  43
  64
[torch.LongStorage of size 3]

677626.19878769	
 512
  43
  64
[torch.LongStorage of size 3]

677600.89927673	
 512
  43
  64
[torch.LongStorage of size 3]

677568.54776382	
 512
  43
  64
[torch.LongStorage of size 3]

677542.13720322	
 512
  43
  64
[torch.LongStorage of size 3]

677511.71657562	
 512
  43
  64
[torch.LongStorage of size 3]

677483.41959	
 512
  43
  64
[torch.LongStorage of size 3]

677461.84474945	
 512
  43
  64
[torch.LongStorage of size 3]

677437.09859848	
 512
  43
  64
[torch.LongStorage of size 3]

677416.70860291	
 512
  43
  64
[torch.LongStorage of size 3]

677393.01614761	
 512
  43
  64
[torch.LongStorage of size 3]

677366.14654541	
 512
  43
  64
[torch.LongStorage of size 3]

677337.48706818	
 512
  43
  64
[torch.LongStorage of size 3]

677313.5502243	
 512
  43
  64
[torch.LongStorage of size 3]

677287.00872421	
 512
  43
  64
[torch.LongStorage of size 3]

677269.1837883	
 512
  43
  64
[torch.LongStorage of size 3]

677244.17043686	
 512
  43
  64
[torch.LongStorage of size 3]

677220.72338104	
 512
  43
  64
[torch.LongStorage of size 3]

677195.7286644	
 512
  43
  64
[torch.LongStorage of size 3]

677175.51467896	
 512
  43
  64
[torch.LongStorage of size 3]

677150.18333435	
 512
  43
  64
[torch.LongStorage of size 3]

677134.48947906	
 512
  43
  64
[torch.LongStorage of size 3]

677117.27926254	
 512
  43
  64
[torch.LongStorage of size 3]

677095.29754639	
 512
  43
  64
[torch.LongStorage of size 3]

677074.99288559	
 512
  43
  64
[torch.LongStorage of size 3]

677055.30250549	
 512
  43
  64
[torch.LongStorage of size 3]

677037.79340744	
 512
  43
  64
[torch.LongStorage of size 3]

677016.68521881	
 512
  43
  64
[torch.LongStorage of size 3]

676995.56991577	
 512
  43
  64
[torch.LongStorage of size 3]

676967.01292038	
 512
  43
  64
[torch.LongStorage of size 3]

676948.52201462	
 512
  43
  64
[torch.LongStorage of size 3]

676923.73468399	
 512
  43
  64
[torch.LongStorage of size 3]

676902.69954681	
 512
  43
  64
[torch.LongStorage of size 3]

676877.87658691	
 512
  43
  64
[torch.LongStorage of size 3]

676856.12913132	
 512
  43
  64
[torch.LongStorage of size 3]

676831.58220291	
 512
  43
  64
[torch.LongStorage of size 3]

676813.03565979	
 512
  43
  64
[torch.LongStorage of size 3]

676788.15128326	
 512
  43
  64
[torch.LongStorage of size 3]

676772.17855453	
 512
  43
  64
[torch.LongStorage of size 3]

676751.70606613	
 512
  43
  64
[torch.LongStorage of size 3]

676729.87976074	
 512
  43
  64
[torch.LongStorage of size 3]

676707.84856796	
 512
  43
  64
[torch.LongStorage of size 3]

676686.55801773	
 512
  43
  64
[torch.LongStorage of size 3]

676665.13002396	
 512
  43
  64
[torch.LongStorage of size 3]

676648.60248566	
 512
  43
  64
[torch.LongStorage of size 3]

676626.60751343	
 512
  43
  64
[torch.LongStorage of size 3]

676609.15458679	
 512
  43
  64
[torch.LongStorage of size 3]

676587.1799469	
 512
  43
  64
[torch.LongStorage of size 3]

676568.04302216	
 512
  43
  64
[torch.LongStorage of size 3]

676545.53070068	
 512
  43
  64
[torch.LongStorage of size 3]

676525.6083107	
 512
  43
  64
[torch.LongStorage of size 3]

676501.10342026	
 512
  43
  64
[torch.LongStorage of size 3]

676483.01347733	
 512
  43
  64
[torch.LongStorage of size 3]

676458.12501907	
 512
  43
  64
[torch.LongStorage of size 3]

676440.62988281	
 512
  43
  64
[torch.LongStorage of size 3]

676419.37383652	
 512
  43
  64
[torch.LongStorage of size 3]

676399.38163757	
 512
  43
  64
[torch.LongStorage of size 3]

676379.13589478	
 512
  43
  64
[torch.LongStorage of size 3]

676362.07878113	
 512
  43
  64
[torch.LongStorage of size 3]

676342.72230148	
 512
  43
  64
[torch.LongStorage of size 3]

676321.84194565	
 512
  43
  64
[torch.LongStorage of size 3]

676297.81873703	
 512
  43
  64
[torch.LongStorage of size 3]

676274.263134	
 512
  43
  64
[torch.LongStorage of size 3]

676252.75953293	
 512
  43
  64
[torch.LongStorage of size 3]

676235.17644882	
 512
  43
  64
[torch.LongStorage of size 3]

676217.37289429	
 512
  43
  64
[torch.LongStorage of size 3]

676196.21086121	
 512
  43
  64
[torch.LongStorage of size 3]

676181.53167725	
 512
  43
  64
[torch.LongStorage of size 3]

676153.71921539	
 512
  43
  64
[torch.LongStorage of size 3]

676133.92501831	
 512
  43
  64
[torch.LongStorage of size 3]

676111.00320816	
 512
  43
  64
[torch.LongStorage of size 3]

676090.65481186	
 512
  43
  64
[torch.LongStorage of size 3]

676068.09625626	
 512
  43
  64
[torch.LongStorage of size 3]

676047.58554459	
 512
  43
  64
[torch.LongStorage of size 3]

676026.20203018	
 512
  43
  64
[torch.LongStorage of size 3]

676005.0394249	
 512
  43
  64
[torch.LongStorage of size 3]

675982.90821075	
 512
  43
  64
[torch.LongStorage of size 3]

675962.12627411	
 512
  43
  64
[torch.LongStorage of size 3]

675941.639328	
 512
  43
  64
[torch.LongStorage of size 3]

675918.19477081	
 512
  43
  64
[torch.LongStorage of size 3]

675897.89850235	
 512
  43
  64
[torch.LongStorage of size 3]

675875.55198669	
 512
  43
  64
[torch.LongStorage of size 3]

675857.65882492	
 512
  43
  64
[torch.LongStorage of size 3]

675833.08986664	
 512
  43
  64
[torch.LongStorage of size 3]

675815.61977386	
 512
  43
  64
[torch.LongStorage of size 3]

675793.78065109	
 512
  43
  64
[torch.LongStorage of size 3]

675774.35338974	
 512
  43
  64
[torch.LongStorage of size 3]

675758.06837082	
 512
  43
  64
[torch.LongStorage of size 3]

675739.90236282	
 512
  43
  64
[torch.LongStorage of size 3]

675725.28478622	
 512
  43
  64
[torch.LongStorage of size 3]

675708.77738953	
 512
  43
  64
[torch.LongStorage of size 3]

675688.90842438	
 512
  43
  64
[torch.LongStorage of size 3]

675670.42615891	
 512
  43
  64
[torch.LongStorage of size 3]

675647.20165253	
 512
  43
  64
[torch.LongStorage of size 3]

675629.53918457	
 512
  43
  64
[torch.LongStorage of size 3]

675607.86567688	
 512
  43
  64
[torch.LongStorage of size 3]

675591.12430573	
 512
  43
  64
[torch.LongStorage of size 3]

675569.38352585	
 512
  43
  64
[torch.LongStorage of size 3]

675552.95465469	
 512
  43
  64
[torch.LongStorage of size 3]

675537.87540436	
 512
  43
  64
[torch.LongStorage of size 3]

675522.06787109	
 512
  43
  64
[torch.LongStorage of size 3]

675505.49179077	
 512
  43
  64
[torch.LongStorage of size 3]

675487.69651413	
 512
  43
  64
[torch.LongStorage of size 3]

675468.38256836	
 512
  43
  64
[torch.LongStorage of size 3]

675453.62277985	
 512
  43
  64
[torch.LongStorage of size 3]

675433.78240585	
 512
  43
  64
[torch.LongStorage of size 3]

675417.57764816	
 512
  43
  64
[torch.LongStorage of size 3]

675397.31254578	
 512
  43
  64
[torch.LongStorage of size 3]

675379.32041168	
 512
  43
  64
[torch.LongStorage of size 3]

675361.89170837	
 512
  43
  64
[torch.LongStorage of size 3]

675342.89680481	
 512
  43
  64
[torch.LongStorage of size 3]

675325.30609131	
 512
  43
  64
[torch.LongStorage of size 3]

675306.07774734	
 512
  43
  64
[torch.LongStorage of size 3]

675288.54026794	
 512
  43
  64
[torch.LongStorage of size 3]

675270.38269043	
 512
  43
  64
[torch.LongStorage of size 3]

675256.19686127	
 512
  43
  64
[torch.LongStorage of size 3]

675237.91564941	
 512
  43
  64
[torch.LongStorage of size 3]

675222.86495209	
 512
  43
  64
[torch.LongStorage of size 3]

675204.52049255	
 512
  43
  64
[torch.LongStorage of size 3]

675188.49693298	
 512
  43
  64
[torch.LongStorage of size 3]

675169.42735672	
 512
  43
  64
[torch.LongStorage of size 3]

675152.77229309	
 512
  43
  64
[torch.LongStorage of size 3]

675136.26447678	
 512
  43
  64
[torch.LongStorage of size 3]

675120.05630493	
 512
  43
  64
[torch.LongStorage of size 3]

675106.30605698	
 512
  43
  64
[torch.LongStorage of size 3]

675092.58613586	
 512
  43
  64
[torch.LongStorage of size 3]

675075.7318306	
 512
  43
  64
[torch.LongStorage of size 3]

675062.30880737	
 512
  43
  64
[torch.LongStorage of size 3]

675043.83478165	
 512
  43
  64
[torch.LongStorage of size 3]

675029.59335327	
 512
  43
  64
[torch.LongStorage of size 3]

675012.44409561	
 512
  43
  64
[torch.LongStorage of size 3]

674994.99576569	
 512
  43
  64
[torch.LongStorage of size 3]

674977.04687119	
 512
  43
  64
[torch.LongStorage of size 3]

674964.65826035	
 512
  43
  64
[torch.LongStorage of size 3]

674948.26057434	
 512
  43
  64
[torch.LongStorage of size 3]

674934.34335709	
 512
  43
  64
[torch.LongStorage of size 3]

674918.49443436	
 512
  43
  64
[torch.LongStorage of size 3]

674901.81558609	
 512
  43
  64
[torch.LongStorage of size 3]

674883.59718323	
 512
  43
  64
[torch.LongStorage of size 3]

674866.58432007	
 512
  43
  64
[torch.LongStorage of size 3]

674850.91880798	
 512
  43
  64
[torch.LongStorage of size 3]

674833.39607239	
 512
  43
  64
[torch.LongStorage of size 3]

674816.89186096	
 512
  43
  64
[torch.LongStorage of size 3]

674800.82328796	
 512
  43
  64
[torch.LongStorage of size 3]

674783.53359222	
 512
  43
  64
[torch.LongStorage of size 3]

674768.11353683	
 512
  43
  64
[torch.LongStorage of size 3]

674751.4849472	
 512
  43
  64
[torch.LongStorage of size 3]

674740.18659592	
 512
  43
  64
[torch.LongStorage of size 3]

674724.76501465	
 512
  43
  64
[torch.LongStorage of size 3]

674710.14909744	
 512
  43
  64
[torch.LongStorage of size 3]

674693.788414	
 512
  43
  64
[torch.LongStorage of size 3]

674677.61846542	
 512
  43
  64
[torch.LongStorage of size 3]

674660.9500885	
 512
  43
  64
[torch.LongStorage of size 3]

674647.82453537	
 512
  43
  64
[torch.LongStorage of size 3]

674628.35626602	
 512
  43
  64
[torch.LongStorage of size 3]

674616.10275269	
 512
  43
  64
[torch.LongStorage of size 3]

674600.66616058	
 512
  43
  64
[torch.LongStorage of size 3]

674584.03366089	
 512
  43
  64
[torch.LongStorage of size 3]

674570.65763474	
 512
  43
  64
[torch.LongStorage of size 3]

674553.65907669	
 512
  43
  64
[torch.LongStorage of size 3]

674540.68258286	
 512
  43
  64
[torch.LongStorage of size 3]

674523.77252579	
 512
  43
  64
[torch.LongStorage of size 3]

674510.53794861	
 512
  43
  64
[torch.LongStorage of size 3]

674498.16617966	
 512
  43
  64
[torch.LongStorage of size 3]

674481.95426941	
 512
  43
  64
[torch.LongStorage of size 3]

674468.63481522	
 512
  43
  64
[torch.LongStorage of size 3]

674452.86912918	
 512
  43
  64
[torch.LongStorage of size 3]

674439.08269882	
 512
  43
  64
[torch.LongStorage of size 3]

674426.04513168	
 512
  43
  64
[torch.LongStorage of size 3]

674411.00595474	
 512
  43
  64
[torch.LongStorage of size 3]

674397.39156723	
 512
  43
  64
[torch.LongStorage of size 3]

674381.87362671	
 512
  43
  64
[torch.LongStorage of size 3]

674367.56847382	
 512
  43
  64
[torch.LongStorage of size 3]

674352.68348694	
 512
  43
  64
[torch.LongStorage of size 3]

674338.69739532	
 512
  43
  64
[torch.LongStorage of size 3]

674323.02490234	
 512
  43
  64
[torch.LongStorage of size 3]

674309.01117325	
 512
  43
  64
[torch.LongStorage of size 3]

674294.67218399	
 512
  43
  64
[torch.LongStorage of size 3]

674279.96061325	
 512
  43
  64
[torch.LongStorage of size 3]

674264.50260162	
 512
  43
  64
[torch.LongStorage of size 3]

674249.87255096	
 512
  43
  64
[torch.LongStorage of size 3]

674235.90200424	
 512
  43
  64
[torch.LongStorage of size 3]

674218.78534317	
 512
  43
  64
[torch.LongStorage of size 3]

674208.83975983	
 512
  43
  64
[torch.LongStorage of size 3]

674190.95104218	
 512
  43
  64
[torch.LongStorage of size 3]

674177.38908768	
 512
  43
  64
[torch.LongStorage of size 3]

674160.48183441	
 512
  43
  64
[torch.LongStorage of size 3]

674145.52869797	
 512
  43
  64
[torch.LongStorage of size 3]

674130.8253479	
 512
  43
  64
[torch.LongStorage of size 3]

674116.21219635	
 512
  43
  64
[torch.LongStorage of size 3]

674102.03453064	
 512
  43
  64
[torch.LongStorage of size 3]

674088.37722778	
 512
  43
  64
[torch.LongStorage of size 3]

674072.79474258	
 512
  43
  64
[torch.LongStorage of size 3]

674059.87321854	
 512
  43
  64
[torch.LongStorage of size 3]

674044.87815857	
 512
  43
  64
[torch.LongStorage of size 3]

674034.34394836	
 512
  43
  64
[torch.LongStorage of size 3]

674022.98595428	
 512
  43
  64
[torch.LongStorage of size 3]

674010.31764984	
 512
  43
  64
[torch.LongStorage of size 3]

673997.00206757	
 512
  43
  64
[torch.LongStorage of size 3]

673982.25631714	
 512
  43
  64
[torch.LongStorage of size 3]

673967.60477066	
 512
  43
  64
[torch.LongStorage of size 3]

673955.74953079	
 512
  43
  64
[torch.LongStorage of size 3]

673942.43558884	
 512
  43
  64
[torch.LongStorage of size 3]

673931.22169495	
 512
  43
  64
[torch.LongStorage of size 3]

673918.35693359	
 512
  43
  64
[torch.LongStorage of size 3]

673907.53837585	
 512
  43
  64
[torch.LongStorage of size 3]

673892.61528015	
 512
  43
  64
[torch.LongStorage of size 3]

673880.70449829	
 512
  43
  64
[torch.LongStorage of size 3]

673866.1060524	
Iteration 999 / 1000	
  Content 1 loss: 534784.843750	
  Style 1 loss: 811.715984	
  Style 2 loss: 4662.239456	
  Style 3 loss: 6317.911911	
  Style 4 loss: 126379.882812	
  Style 5 loss: 909.512138	
  Total loss: 673866.106052	
s/s.jpg_out_prepost_999.png	
 512
  43
  64
[torch.LongStorage of size 3]

673853.0789566	
s/s.jpg_out_prepost_1000.png	
<optim.lbfgs> 	reached max number of iterations	
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0804 20:01:58.866861   840 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0804 20:01:58.866930   840 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0804 20:01:58.866945   840 _caffe.cpp:142] Net('./zhang/colorization/models/colorization_deploy_v2.prototxt', 1, weights='./zhang/colorization/models/colorization_release_v2.caffemodel')
I0804 20:01:58.868610   840 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_deploy_v2.prototxt
I0804 20:01:58.868638   840 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 20:01:58.868913   840 net.cpp:51] Initializing net from parameters: 
name: "LtoAB"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data_l"
  type: "Input"
  top: "data_l"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "bw_conv1_1"
  type: "Convolution"
  bottom: "data_l"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_2norm"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_2norm"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_2norm"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_2norm"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_3norm"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_3norm"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_3norm"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_3norm"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_3norm"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_3norm"
  top: "conv6_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv6_3"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "conv6_3"
  top: "conv6_3"
}
layer {
  name: "conv6_3norm"
  type: "BatchNorm"
  bottom: "conv6_3"
  top: "conv6_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_3norm"
  top: "conv7_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv7_3"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "conv7_3"
  top: "conv7_3"
}
layer {
  name: "conv7_3norm"
  type: "BatchNorm"
  bottom: "conv7_3"
  top: "conv7_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv8_1"
  type: "Deconvolution"
  bottom: "conv7_3norm"
  top: "conv8_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    stride: 2
    dilation: 1
  }
}
layer {
  name: "relu8_1"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_2"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv8_3"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_3"
  type: "ReLU"
  bottom: "conv8_3"
  top: "conv8_3"
}
layer {
  name: "conv8_313"
  type: "Convolution"
  bottom: "conv8_3"
  top: "conv8_313"
  convolution_param {
    num_output: 313
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv8_313_rh"
  type: "Scale"
  bottom: "conv8_313"
  top: "conv8_313_rh"
  scale_param {
    filler {
      type: "constant"
      value: 2.606
    }
    bias_term: false
  }
}
layer {
  name: "class8_313_rh"
  type: "Softmax"
  bottom: "conv8_313_rh"
  top: "class8_313_rh"
}
layer {
  name: "class8_ab"
  type: "Convolution"
  bottom: "class8_313_rh"
  top: "class8_ab"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "Silence"
  type: "Silence"
  bottom: "class8_ab"
}
I0804 20:01:58.869092   840 layer_factory.hpp:77] Creating layer data_l
I0804 20:01:58.869113   840 net.cpp:84] Creating Layer data_l
I0804 20:01:58.869127   840 net.cpp:380] data_l -> data_l
I0804 20:01:58.879452   840 net.cpp:122] Setting up data_l
I0804 20:01:58.879498   840 net.cpp:129] Top shape: 1 1 224 224 (50176)
I0804 20:01:58.879510   840 net.cpp:137] Memory required for data: 200704
I0804 20:01:58.879523   840 layer_factory.hpp:77] Creating layer bw_conv1_1
I0804 20:01:58.879546   840 net.cpp:84] Creating Layer bw_conv1_1
I0804 20:01:58.879559   840 net.cpp:406] bw_conv1_1 <- data_l
I0804 20:01:58.879573   840 net.cpp:380] bw_conv1_1 -> conv1_1
I0804 20:01:58.881481   840 net.cpp:122] Setting up bw_conv1_1
I0804 20:01:58.881512   840 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 20:01:58.881525   840 net.cpp:137] Memory required for data: 13045760
I0804 20:01:58.881543   840 layer_factory.hpp:77] Creating layer relu1_1
I0804 20:01:58.881561   840 net.cpp:84] Creating Layer relu1_1
I0804 20:01:58.881572   840 net.cpp:406] relu1_1 <- conv1_1
I0804 20:01:58.881587   840 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0804 20:01:58.881602   840 net.cpp:122] Setting up relu1_1
I0804 20:01:58.881613   840 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 20:01:58.881623   840 net.cpp:137] Memory required for data: 25890816
I0804 20:01:58.881633   840 layer_factory.hpp:77] Creating layer conv1_2
I0804 20:01:58.881647   840 net.cpp:84] Creating Layer conv1_2
I0804 20:01:58.881659   840 net.cpp:406] conv1_2 <- conv1_1
I0804 20:01:58.881672   840 net.cpp:380] conv1_2 -> conv1_2
I0804 20:01:58.882738   840 net.cpp:122] Setting up conv1_2
I0804 20:01:58.882761   840 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 20:01:58.882772   840 net.cpp:137] Memory required for data: 29102080
I0804 20:01:58.882789   840 layer_factory.hpp:77] Creating layer relu1_2
I0804 20:01:58.882804   840 net.cpp:84] Creating Layer relu1_2
I0804 20:01:58.882815   840 net.cpp:406] relu1_2 <- conv1_2
I0804 20:01:58.882829   840 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0804 20:01:58.882843   840 net.cpp:122] Setting up relu1_2
I0804 20:01:58.882855   840 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 20:01:58.882865   840 net.cpp:137] Memory required for data: 32313344
I0804 20:01:58.882875   840 layer_factory.hpp:77] Creating layer conv1_2norm
I0804 20:01:58.882889   840 net.cpp:84] Creating Layer conv1_2norm
I0804 20:01:58.882900   840 net.cpp:406] conv1_2norm <- conv1_2
I0804 20:01:58.882917   840 net.cpp:380] conv1_2norm -> conv1_2norm
I0804 20:01:58.883116   840 net.cpp:122] Setting up conv1_2norm
I0804 20:01:58.883129   840 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 20:01:58.883157   840 net.cpp:137] Memory required for data: 35524608
I0804 20:01:58.883175   840 layer_factory.hpp:77] Creating layer conv2_1
I0804 20:01:58.883191   840 net.cpp:84] Creating Layer conv2_1
I0804 20:01:58.883203   840 net.cpp:406] conv2_1 <- conv1_2norm
I0804 20:01:58.883214   840 net.cpp:380] conv2_1 -> conv2_1
I0804 20:01:58.884305   840 net.cpp:122] Setting up conv2_1
I0804 20:01:58.884330   840 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 20:01:58.884342   840 net.cpp:137] Memory required for data: 41947136
I0804 20:01:58.884358   840 layer_factory.hpp:77] Creating layer relu2_1
I0804 20:01:58.884372   840 net.cpp:84] Creating Layer relu2_1
I0804 20:01:58.884383   840 net.cpp:406] relu2_1 <- conv2_1
I0804 20:01:58.884395   840 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0804 20:01:58.884409   840 net.cpp:122] Setting up relu2_1
I0804 20:01:58.884421   840 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 20:01:58.884431   840 net.cpp:137] Memory required for data: 48369664
I0804 20:01:58.884441   840 layer_factory.hpp:77] Creating layer conv2_2
I0804 20:01:58.884459   840 net.cpp:84] Creating Layer conv2_2
I0804 20:01:58.884469   840 net.cpp:406] conv2_2 <- conv2_1
I0804 20:01:58.884482   840 net.cpp:380] conv2_2 -> conv2_2
I0804 20:01:58.885635   840 net.cpp:122] Setting up conv2_2
I0804 20:01:58.885661   840 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 20:01:58.885673   840 net.cpp:137] Memory required for data: 49975296
I0804 20:01:58.885686   840 layer_factory.hpp:77] Creating layer relu2_2
I0804 20:01:58.885702   840 net.cpp:84] Creating Layer relu2_2
I0804 20:01:58.885713   840 net.cpp:406] relu2_2 <- conv2_2
I0804 20:01:58.885725   840 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0804 20:01:58.885740   840 net.cpp:122] Setting up relu2_2
I0804 20:01:58.885751   840 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 20:01:58.885761   840 net.cpp:137] Memory required for data: 51580928
I0804 20:01:58.885772   840 layer_factory.hpp:77] Creating layer conv2_2norm
I0804 20:01:58.885787   840 net.cpp:84] Creating Layer conv2_2norm
I0804 20:01:58.885798   840 net.cpp:406] conv2_2norm <- conv2_2
I0804 20:01:58.885810   840 net.cpp:380] conv2_2norm -> conv2_2norm
I0804 20:01:58.886009   840 net.cpp:122] Setting up conv2_2norm
I0804 20:01:58.886023   840 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 20:01:58.886034   840 net.cpp:137] Memory required for data: 53186560
I0804 20:01:58.886049   840 layer_factory.hpp:77] Creating layer conv3_1
I0804 20:01:58.886065   840 net.cpp:84] Creating Layer conv3_1
I0804 20:01:58.886075   840 net.cpp:406] conv3_1 <- conv2_2norm
I0804 20:01:58.886088   840 net.cpp:380] conv3_1 -> conv3_1
I0804 20:01:58.886507   840 net.cpp:122] Setting up conv3_1
I0804 20:01:58.886523   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.886533   840 net.cpp:137] Memory required for data: 56397824
I0804 20:01:58.886546   840 layer_factory.hpp:77] Creating layer relu3_1
I0804 20:01:58.886560   840 net.cpp:84] Creating Layer relu3_1
I0804 20:01:58.886570   840 net.cpp:406] relu3_1 <- conv3_1
I0804 20:01:58.886582   840 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0804 20:01:58.886595   840 net.cpp:122] Setting up relu3_1
I0804 20:01:58.886607   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.886617   840 net.cpp:137] Memory required for data: 59609088
I0804 20:01:58.886627   840 layer_factory.hpp:77] Creating layer conv3_2
I0804 20:01:58.886642   840 net.cpp:84] Creating Layer conv3_2
I0804 20:01:58.886652   840 net.cpp:406] conv3_2 <- conv3_1
I0804 20:01:58.886664   840 net.cpp:380] conv3_2 -> conv3_2
I0804 20:01:58.888217   840 net.cpp:122] Setting up conv3_2
I0804 20:01:58.888243   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.888254   840 net.cpp:137] Memory required for data: 62820352
I0804 20:01:58.888273   840 layer_factory.hpp:77] Creating layer relu3_2
I0804 20:01:58.888288   840 net.cpp:84] Creating Layer relu3_2
I0804 20:01:58.888298   840 net.cpp:406] relu3_2 <- conv3_2
I0804 20:01:58.888312   840 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0804 20:01:58.888345   840 net.cpp:122] Setting up relu3_2
I0804 20:01:58.888356   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.888367   840 net.cpp:137] Memory required for data: 66031616
I0804 20:01:58.888377   840 layer_factory.hpp:77] Creating layer conv3_3
I0804 20:01:58.888391   840 net.cpp:84] Creating Layer conv3_3
I0804 20:01:58.888402   840 net.cpp:406] conv3_3 <- conv3_2
I0804 20:01:58.888417   840 net.cpp:380] conv3_3 -> conv3_3
I0804 20:01:58.890002   840 net.cpp:122] Setting up conv3_3
I0804 20:01:58.890034   840 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 20:01:58.890046   840 net.cpp:137] Memory required for data: 66834432
I0804 20:01:58.890060   840 layer_factory.hpp:77] Creating layer relu3_3
I0804 20:01:58.890079   840 net.cpp:84] Creating Layer relu3_3
I0804 20:01:58.890091   840 net.cpp:406] relu3_3 <- conv3_3
I0804 20:01:58.890105   840 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0804 20:01:58.890117   840 net.cpp:122] Setting up relu3_3
I0804 20:01:58.890130   840 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 20:01:58.890139   840 net.cpp:137] Memory required for data: 67637248
I0804 20:01:58.890151   840 layer_factory.hpp:77] Creating layer conv3_3norm
I0804 20:01:58.890163   840 net.cpp:84] Creating Layer conv3_3norm
I0804 20:01:58.890174   840 net.cpp:406] conv3_3norm <- conv3_3
I0804 20:01:58.890188   840 net.cpp:380] conv3_3norm -> conv3_3norm
I0804 20:01:58.890379   840 net.cpp:122] Setting up conv3_3norm
I0804 20:01:58.890393   840 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 20:01:58.890404   840 net.cpp:137] Memory required for data: 68440064
I0804 20:01:58.890419   840 layer_factory.hpp:77] Creating layer conv4_1
I0804 20:01:58.890436   840 net.cpp:84] Creating Layer conv4_1
I0804 20:01:58.890449   840 net.cpp:406] conv4_1 <- conv3_3norm
I0804 20:01:58.890460   840 net.cpp:380] conv4_1 -> conv4_1
I0804 20:01:58.893183   840 net.cpp:122] Setting up conv4_1
I0804 20:01:58.893225   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.893237   840 net.cpp:137] Memory required for data: 70045696
I0804 20:01:58.893252   840 layer_factory.hpp:77] Creating layer relu4_1
I0804 20:01:58.893270   840 net.cpp:84] Creating Layer relu4_1
I0804 20:01:58.893281   840 net.cpp:406] relu4_1 <- conv4_1
I0804 20:01:58.893295   840 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0804 20:01:58.893309   840 net.cpp:122] Setting up relu4_1
I0804 20:01:58.893321   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.893332   840 net.cpp:137] Memory required for data: 71651328
I0804 20:01:58.893342   840 layer_factory.hpp:77] Creating layer conv4_2
I0804 20:01:58.893358   840 net.cpp:84] Creating Layer conv4_2
I0804 20:01:58.893368   840 net.cpp:406] conv4_2 <- conv4_1
I0804 20:01:58.893381   840 net.cpp:380] conv4_2 -> conv4_2
I0804 20:01:58.898423   840 net.cpp:122] Setting up conv4_2
I0804 20:01:58.898468   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.898480   840 net.cpp:137] Memory required for data: 73256960
I0804 20:01:58.898496   840 layer_factory.hpp:77] Creating layer relu4_2
I0804 20:01:58.898512   840 net.cpp:84] Creating Layer relu4_2
I0804 20:01:58.898524   840 net.cpp:406] relu4_2 <- conv4_2
I0804 20:01:58.898538   840 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0804 20:01:58.898553   840 net.cpp:122] Setting up relu4_2
I0804 20:01:58.898566   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.898576   840 net.cpp:137] Memory required for data: 74862592
I0804 20:01:58.898586   840 layer_factory.hpp:77] Creating layer conv4_3
I0804 20:01:58.898600   840 net.cpp:84] Creating Layer conv4_3
I0804 20:01:58.898612   840 net.cpp:406] conv4_3 <- conv4_2
I0804 20:01:58.898625   840 net.cpp:380] conv4_3 -> conv4_3
I0804 20:01:58.903658   840 net.cpp:122] Setting up conv4_3
I0804 20:01:58.903704   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.903715   840 net.cpp:137] Memory required for data: 76468224
I0804 20:01:58.903731   840 layer_factory.hpp:77] Creating layer relu4_3
I0804 20:01:58.903766   840 net.cpp:84] Creating Layer relu4_3
I0804 20:01:58.903779   840 net.cpp:406] relu4_3 <- conv4_3
I0804 20:01:58.903794   840 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0804 20:01:58.903810   840 net.cpp:122] Setting up relu4_3
I0804 20:01:58.903821   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.903831   840 net.cpp:137] Memory required for data: 78073856
I0804 20:01:58.903841   840 layer_factory.hpp:77] Creating layer conv4_3norm
I0804 20:01:58.903856   840 net.cpp:84] Creating Layer conv4_3norm
I0804 20:01:58.903867   840 net.cpp:406] conv4_3norm <- conv4_3
I0804 20:01:58.903880   840 net.cpp:380] conv4_3norm -> conv4_3norm
I0804 20:01:58.904079   840 net.cpp:122] Setting up conv4_3norm
I0804 20:01:58.904093   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.904104   840 net.cpp:137] Memory required for data: 79679488
I0804 20:01:58.904119   840 layer_factory.hpp:77] Creating layer conv5_1
I0804 20:01:58.904135   840 net.cpp:84] Creating Layer conv5_1
I0804 20:01:58.904146   840 net.cpp:406] conv5_1 <- conv4_3norm
I0804 20:01:58.904160   840 net.cpp:380] conv5_1 -> conv5_1
I0804 20:01:58.909160   840 net.cpp:122] Setting up conv5_1
I0804 20:01:58.909209   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.909219   840 net.cpp:137] Memory required for data: 81285120
I0804 20:01:58.909240   840 layer_factory.hpp:77] Creating layer relu5_1
I0804 20:01:58.909260   840 net.cpp:84] Creating Layer relu5_1
I0804 20:01:58.909272   840 net.cpp:406] relu5_1 <- conv5_1
I0804 20:01:58.909286   840 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0804 20:01:58.909301   840 net.cpp:122] Setting up relu5_1
I0804 20:01:58.909312   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.909323   840 net.cpp:137] Memory required for data: 82890752
I0804 20:01:58.909333   840 layer_factory.hpp:77] Creating layer conv5_2
I0804 20:01:58.909349   840 net.cpp:84] Creating Layer conv5_2
I0804 20:01:58.909360   840 net.cpp:406] conv5_2 <- conv5_1
I0804 20:01:58.909373   840 net.cpp:380] conv5_2 -> conv5_2
I0804 20:01:58.914273   840 net.cpp:122] Setting up conv5_2
I0804 20:01:58.914320   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.914331   840 net.cpp:137] Memory required for data: 84496384
I0804 20:01:58.914347   840 layer_factory.hpp:77] Creating layer relu5_2
I0804 20:01:58.914366   840 net.cpp:84] Creating Layer relu5_2
I0804 20:01:58.914377   840 net.cpp:406] relu5_2 <- conv5_2
I0804 20:01:58.914391   840 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0804 20:01:58.914405   840 net.cpp:122] Setting up relu5_2
I0804 20:01:58.914417   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.914427   840 net.cpp:137] Memory required for data: 86102016
I0804 20:01:58.914438   840 layer_factory.hpp:77] Creating layer conv5_3
I0804 20:01:58.914454   840 net.cpp:84] Creating Layer conv5_3
I0804 20:01:58.914464   840 net.cpp:406] conv5_3 <- conv5_2
I0804 20:01:58.914477   840 net.cpp:380] conv5_3 -> conv5_3
I0804 20:01:58.919380   840 net.cpp:122] Setting up conv5_3
I0804 20:01:58.919428   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.919440   840 net.cpp:137] Memory required for data: 87707648
I0804 20:01:58.919456   840 layer_factory.hpp:77] Creating layer relu5_3
I0804 20:01:58.919471   840 net.cpp:84] Creating Layer relu5_3
I0804 20:01:58.919482   840 net.cpp:406] relu5_3 <- conv5_3
I0804 20:01:58.919497   840 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0804 20:01:58.919512   840 net.cpp:122] Setting up relu5_3
I0804 20:01:58.919524   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.919534   840 net.cpp:137] Memory required for data: 89313280
I0804 20:01:58.919544   840 layer_factory.hpp:77] Creating layer conv5_3norm
I0804 20:01:58.919560   840 net.cpp:84] Creating Layer conv5_3norm
I0804 20:01:58.919570   840 net.cpp:406] conv5_3norm <- conv5_3
I0804 20:01:58.919584   840 net.cpp:380] conv5_3norm -> conv5_3norm
I0804 20:01:58.919780   840 net.cpp:122] Setting up conv5_3norm
I0804 20:01:58.919795   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.919821   840 net.cpp:137] Memory required for data: 90918912
I0804 20:01:58.919837   840 layer_factory.hpp:77] Creating layer conv6_1
I0804 20:01:58.919857   840 net.cpp:84] Creating Layer conv6_1
I0804 20:01:58.919867   840 net.cpp:406] conv6_1 <- conv5_3norm
I0804 20:01:58.919880   840 net.cpp:380] conv6_1 -> conv6_1
I0804 20:01:58.924764   840 net.cpp:122] Setting up conv6_1
I0804 20:01:58.924811   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.924823   840 net.cpp:137] Memory required for data: 92524544
I0804 20:01:58.924839   840 layer_factory.hpp:77] Creating layer relu6_1
I0804 20:01:58.924856   840 net.cpp:84] Creating Layer relu6_1
I0804 20:01:58.924868   840 net.cpp:406] relu6_1 <- conv6_1
I0804 20:01:58.924881   840 net.cpp:367] relu6_1 -> conv6_1 (in-place)
I0804 20:01:58.924896   840 net.cpp:122] Setting up relu6_1
I0804 20:01:58.924908   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.924918   840 net.cpp:137] Memory required for data: 94130176
I0804 20:01:58.924928   840 layer_factory.hpp:77] Creating layer conv6_2
I0804 20:01:58.924944   840 net.cpp:84] Creating Layer conv6_2
I0804 20:01:58.924955   840 net.cpp:406] conv6_2 <- conv6_1
I0804 20:01:58.924968   840 net.cpp:380] conv6_2 -> conv6_2
I0804 20:01:58.929908   840 net.cpp:122] Setting up conv6_2
I0804 20:01:58.929955   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.929965   840 net.cpp:137] Memory required for data: 95735808
I0804 20:01:58.929981   840 layer_factory.hpp:77] Creating layer relu6_2
I0804 20:01:58.929997   840 net.cpp:84] Creating Layer relu6_2
I0804 20:01:58.930008   840 net.cpp:406] relu6_2 <- conv6_2
I0804 20:01:58.930023   840 net.cpp:367] relu6_2 -> conv6_2 (in-place)
I0804 20:01:58.930038   840 net.cpp:122] Setting up relu6_2
I0804 20:01:58.930050   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.930060   840 net.cpp:137] Memory required for data: 97341440
I0804 20:01:58.930070   840 layer_factory.hpp:77] Creating layer conv6_3
I0804 20:01:58.930085   840 net.cpp:84] Creating Layer conv6_3
I0804 20:01:58.930095   840 net.cpp:406] conv6_3 <- conv6_2
I0804 20:01:58.930109   840 net.cpp:380] conv6_3 -> conv6_3
I0804 20:01:58.935031   840 net.cpp:122] Setting up conv6_3
I0804 20:01:58.935078   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.935089   840 net.cpp:137] Memory required for data: 98947072
I0804 20:01:58.935106   840 layer_factory.hpp:77] Creating layer relu6_3
I0804 20:01:58.935122   840 net.cpp:84] Creating Layer relu6_3
I0804 20:01:58.935133   840 net.cpp:406] relu6_3 <- conv6_3
I0804 20:01:58.935148   840 net.cpp:367] relu6_3 -> conv6_3 (in-place)
I0804 20:01:58.935163   840 net.cpp:122] Setting up relu6_3
I0804 20:01:58.935174   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.935184   840 net.cpp:137] Memory required for data: 100552704
I0804 20:01:58.935194   840 layer_factory.hpp:77] Creating layer conv6_3norm
I0804 20:01:58.935209   840 net.cpp:84] Creating Layer conv6_3norm
I0804 20:01:58.935220   840 net.cpp:406] conv6_3norm <- conv6_3
I0804 20:01:58.935236   840 net.cpp:380] conv6_3norm -> conv6_3norm
I0804 20:01:58.935436   840 net.cpp:122] Setting up conv6_3norm
I0804 20:01:58.935449   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.935461   840 net.cpp:137] Memory required for data: 102158336
I0804 20:01:58.935474   840 layer_factory.hpp:77] Creating layer conv7_1
I0804 20:01:58.935492   840 net.cpp:84] Creating Layer conv7_1
I0804 20:01:58.935503   840 net.cpp:406] conv7_1 <- conv6_3norm
I0804 20:01:58.935514   840 net.cpp:380] conv7_1 -> conv7_1
I0804 20:01:58.940409   840 net.cpp:122] Setting up conv7_1
I0804 20:01:58.940456   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.940467   840 net.cpp:137] Memory required for data: 103763968
I0804 20:01:58.940482   840 layer_factory.hpp:77] Creating layer relu7_1
I0804 20:01:58.940498   840 net.cpp:84] Creating Layer relu7_1
I0804 20:01:58.940510   840 net.cpp:406] relu7_1 <- conv7_1
I0804 20:01:58.940541   840 net.cpp:367] relu7_1 -> conv7_1 (in-place)
I0804 20:01:58.940557   840 net.cpp:122] Setting up relu7_1
I0804 20:01:58.940569   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.940579   840 net.cpp:137] Memory required for data: 105369600
I0804 20:01:58.940589   840 layer_factory.hpp:77] Creating layer conv7_2
I0804 20:01:58.940604   840 net.cpp:84] Creating Layer conv7_2
I0804 20:01:58.940614   840 net.cpp:406] conv7_2 <- conv7_1
I0804 20:01:58.940631   840 net.cpp:380] conv7_2 -> conv7_2
I0804 20:01:58.945608   840 net.cpp:122] Setting up conv7_2
I0804 20:01:58.945654   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.945667   840 net.cpp:137] Memory required for data: 106975232
I0804 20:01:58.945683   840 layer_factory.hpp:77] Creating layer relu7_2
I0804 20:01:58.945698   840 net.cpp:84] Creating Layer relu7_2
I0804 20:01:58.945710   840 net.cpp:406] relu7_2 <- conv7_2
I0804 20:01:58.945725   840 net.cpp:367] relu7_2 -> conv7_2 (in-place)
I0804 20:01:58.945740   840 net.cpp:122] Setting up relu7_2
I0804 20:01:58.945752   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.945762   840 net.cpp:137] Memory required for data: 108580864
I0804 20:01:58.945772   840 layer_factory.hpp:77] Creating layer conv7_3
I0804 20:01:58.945787   840 net.cpp:84] Creating Layer conv7_3
I0804 20:01:58.945797   840 net.cpp:406] conv7_3 <- conv7_2
I0804 20:01:58.945813   840 net.cpp:380] conv7_3 -> conv7_3
I0804 20:01:58.950717   840 net.cpp:122] Setting up conv7_3
I0804 20:01:58.950763   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.950774   840 net.cpp:137] Memory required for data: 110186496
I0804 20:01:58.950790   840 layer_factory.hpp:77] Creating layer relu7_3
I0804 20:01:58.950809   840 net.cpp:84] Creating Layer relu7_3
I0804 20:01:58.950819   840 net.cpp:406] relu7_3 <- conv7_3
I0804 20:01:58.950832   840 net.cpp:367] relu7_3 -> conv7_3 (in-place)
I0804 20:01:58.950847   840 net.cpp:122] Setting up relu7_3
I0804 20:01:58.950860   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.950870   840 net.cpp:137] Memory required for data: 111792128
I0804 20:01:58.950880   840 layer_factory.hpp:77] Creating layer conv7_3norm
I0804 20:01:58.950894   840 net.cpp:84] Creating Layer conv7_3norm
I0804 20:01:58.950906   840 net.cpp:406] conv7_3norm <- conv7_3
I0804 20:01:58.950918   840 net.cpp:380] conv7_3norm -> conv7_3norm
I0804 20:01:58.951124   840 net.cpp:122] Setting up conv7_3norm
I0804 20:01:58.951138   840 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:01:58.951149   840 net.cpp:137] Memory required for data: 113397760
I0804 20:01:58.951164   840 layer_factory.hpp:77] Creating layer conv8_1
I0804 20:01:58.951179   840 net.cpp:84] Creating Layer conv8_1
I0804 20:01:58.951189   840 net.cpp:406] conv8_1 <- conv7_3norm
I0804 20:01:58.951202   840 net.cpp:380] conv8_1 -> conv8_1
I0804 20:01:58.955626   840 net.cpp:122] Setting up conv8_1
I0804 20:01:58.955672   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.955683   840 net.cpp:137] Memory required for data: 116609024
I0804 20:01:58.955699   840 layer_factory.hpp:77] Creating layer relu8_1
I0804 20:01:58.955715   840 net.cpp:84] Creating Layer relu8_1
I0804 20:01:58.955727   840 net.cpp:406] relu8_1 <- conv8_1
I0804 20:01:58.955741   840 net.cpp:367] relu8_1 -> conv8_1 (in-place)
I0804 20:01:58.955757   840 net.cpp:122] Setting up relu8_1
I0804 20:01:58.955770   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.955780   840 net.cpp:137] Memory required for data: 119820288
I0804 20:01:58.955790   840 layer_factory.hpp:77] Creating layer conv8_2
I0804 20:01:58.955804   840 net.cpp:84] Creating Layer conv8_2
I0804 20:01:58.955816   840 net.cpp:406] conv8_2 <- conv8_1
I0804 20:01:58.955829   840 net.cpp:380] conv8_2 -> conv8_2
I0804 20:01:58.957484   840 net.cpp:122] Setting up conv8_2
I0804 20:01:58.957512   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.957523   840 net.cpp:137] Memory required for data: 123031552
I0804 20:01:58.957538   840 layer_factory.hpp:77] Creating layer relu8_2
I0804 20:01:58.957568   840 net.cpp:84] Creating Layer relu8_2
I0804 20:01:58.957581   840 net.cpp:406] relu8_2 <- conv8_2
I0804 20:01:58.957595   840 net.cpp:367] relu8_2 -> conv8_2 (in-place)
I0804 20:01:58.957610   840 net.cpp:122] Setting up relu8_2
I0804 20:01:58.957623   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.957633   840 net.cpp:137] Memory required for data: 126242816
I0804 20:01:58.957643   840 layer_factory.hpp:77] Creating layer conv8_3
I0804 20:01:58.957657   840 net.cpp:84] Creating Layer conv8_3
I0804 20:01:58.957669   840 net.cpp:406] conv8_3 <- conv8_2
I0804 20:01:58.957681   840 net.cpp:380] conv8_3 -> conv8_3
I0804 20:01:58.959278   840 net.cpp:122] Setting up conv8_3
I0804 20:01:58.959307   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.959318   840 net.cpp:137] Memory required for data: 129454080
I0804 20:01:58.959342   840 layer_factory.hpp:77] Creating layer relu8_3
I0804 20:01:58.959357   840 net.cpp:84] Creating Layer relu8_3
I0804 20:01:58.959367   840 net.cpp:406] relu8_3 <- conv8_3
I0804 20:01:58.959381   840 net.cpp:367] relu8_3 -> conv8_3 (in-place)
I0804 20:01:58.959395   840 net.cpp:122] Setting up relu8_3
I0804 20:01:58.959408   840 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:01:58.959417   840 net.cpp:137] Memory required for data: 132665344
I0804 20:01:58.959429   840 layer_factory.hpp:77] Creating layer conv8_313
I0804 20:01:58.959442   840 net.cpp:84] Creating Layer conv8_313
I0804 20:01:58.959452   840 net.cpp:406] conv8_313 <- conv8_3
I0804 20:01:58.959465   840 net.cpp:380] conv8_313 -> conv8_313
I0804 20:01:58.960655   840 net.cpp:122] Setting up conv8_313
I0804 20:01:58.960681   840 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 20:01:58.960692   840 net.cpp:137] Memory required for data: 136591616
I0804 20:01:58.960706   840 layer_factory.hpp:77] Creating layer conv8_313_rh
I0804 20:01:58.960723   840 net.cpp:84] Creating Layer conv8_313_rh
I0804 20:01:58.960736   840 net.cpp:406] conv8_313_rh <- conv8_313
I0804 20:01:58.960749   840 net.cpp:380] conv8_313_rh -> conv8_313_rh
I0804 20:01:58.960856   840 net.cpp:122] Setting up conv8_313_rh
I0804 20:01:58.960871   840 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 20:01:58.960882   840 net.cpp:137] Memory required for data: 140517888
I0804 20:01:58.960893   840 layer_factory.hpp:77] Creating layer class8_313_rh
I0804 20:01:58.960906   840 net.cpp:84] Creating Layer class8_313_rh
I0804 20:01:58.960917   840 net.cpp:406] class8_313_rh <- conv8_313_rh
I0804 20:01:58.960930   840 net.cpp:380] class8_313_rh -> class8_313_rh
I0804 20:01:58.961017   840 net.cpp:122] Setting up class8_313_rh
I0804 20:01:58.961037   840 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 20:01:58.961048   840 net.cpp:137] Memory required for data: 144444160
I0804 20:01:58.961058   840 layer_factory.hpp:77] Creating layer class8_ab
I0804 20:01:58.961073   840 net.cpp:84] Creating Layer class8_ab
I0804 20:01:58.961084   840 net.cpp:406] class8_ab <- class8_313_rh
I0804 20:01:58.961097   840 net.cpp:380] class8_ab -> class8_ab
I0804 20:01:58.961338   840 net.cpp:122] Setting up class8_ab
I0804 20:01:58.961352   840 net.cpp:129] Top shape: 1 2 56 56 (6272)
I0804 20:01:58.961364   840 net.cpp:137] Memory required for data: 144469248
I0804 20:01:58.961376   840 layer_factory.hpp:77] Creating layer Silence
I0804 20:01:58.961390   840 net.cpp:84] Creating Layer Silence
I0804 20:01:58.961401   840 net.cpp:406] Silence <- class8_ab
I0804 20:01:58.961412   840 net.cpp:122] Setting up Silence
I0804 20:01:58.961423   840 net.cpp:137] Memory required for data: 144469248
I0804 20:01:58.961433   840 net.cpp:200] Silence does not need backward computation.
I0804 20:01:58.961444   840 net.cpp:200] class8_ab does not need backward computation.
I0804 20:01:58.961454   840 net.cpp:200] class8_313_rh does not need backward computation.
I0804 20:01:58.961465   840 net.cpp:200] conv8_313_rh does not need backward computation.
I0804 20:01:58.961475   840 net.cpp:200] conv8_313 does not need backward computation.
I0804 20:01:58.961503   840 net.cpp:200] relu8_3 does not need backward computation.
I0804 20:01:58.961514   840 net.cpp:200] conv8_3 does not need backward computation.
I0804 20:01:58.961525   840 net.cpp:200] relu8_2 does not need backward computation.
I0804 20:01:58.961535   840 net.cpp:200] conv8_2 does not need backward computation.
I0804 20:01:58.961546   840 net.cpp:200] relu8_1 does not need backward computation.
I0804 20:01:58.961556   840 net.cpp:200] conv8_1 does not need backward computation.
I0804 20:01:58.961567   840 net.cpp:200] conv7_3norm does not need backward computation.
I0804 20:01:58.961578   840 net.cpp:200] relu7_3 does not need backward computation.
I0804 20:01:58.961589   840 net.cpp:200] conv7_3 does not need backward computation.
I0804 20:01:58.961599   840 net.cpp:200] relu7_2 does not need backward computation.
I0804 20:01:58.961611   840 net.cpp:200] conv7_2 does not need backward computation.
I0804 20:01:58.961621   840 net.cpp:200] relu7_1 does not need backward computation.
I0804 20:01:58.961630   840 net.cpp:200] conv7_1 does not need backward computation.
I0804 20:01:58.961642   840 net.cpp:200] conv6_3norm does not need backward computation.
I0804 20:01:58.961652   840 net.cpp:200] relu6_3 does not need backward computation.
I0804 20:01:58.961663   840 net.cpp:200] conv6_3 does not need backward computation.
I0804 20:01:58.961673   840 net.cpp:200] relu6_2 does not need backward computation.
I0804 20:01:58.961683   840 net.cpp:200] conv6_2 does not need backward computation.
I0804 20:01:58.961694   840 net.cpp:200] relu6_1 does not need backward computation.
I0804 20:01:58.961704   840 net.cpp:200] conv6_1 does not need backward computation.
I0804 20:01:58.961714   840 net.cpp:200] conv5_3norm does not need backward computation.
I0804 20:01:58.961725   840 net.cpp:200] relu5_3 does not need backward computation.
I0804 20:01:58.961735   840 net.cpp:200] conv5_3 does not need backward computation.
I0804 20:01:58.961746   840 net.cpp:200] relu5_2 does not need backward computation.
I0804 20:01:58.961756   840 net.cpp:200] conv5_2 does not need backward computation.
I0804 20:01:58.961766   840 net.cpp:200] relu5_1 does not need backward computation.
I0804 20:01:58.961777   840 net.cpp:200] conv5_1 does not need backward computation.
I0804 20:01:58.961787   840 net.cpp:200] conv4_3norm does not need backward computation.
I0804 20:01:58.961798   840 net.cpp:200] relu4_3 does not need backward computation.
I0804 20:01:58.961809   840 net.cpp:200] conv4_3 does not need backward computation.
I0804 20:01:58.961819   840 net.cpp:200] relu4_2 does not need backward computation.
I0804 20:01:58.961832   840 net.cpp:200] conv4_2 does not need backward computation.
I0804 20:01:58.961843   840 net.cpp:200] relu4_1 does not need backward computation.
I0804 20:01:58.961853   840 net.cpp:200] conv4_1 does not need backward computation.
I0804 20:01:58.961863   840 net.cpp:200] conv3_3norm does not need backward computation.
I0804 20:01:58.961874   840 net.cpp:200] relu3_3 does not need backward computation.
I0804 20:01:58.961884   840 net.cpp:200] conv3_3 does not need backward computation.
I0804 20:01:58.961894   840 net.cpp:200] relu3_2 does not need backward computation.
I0804 20:01:58.961905   840 net.cpp:200] conv3_2 does not need backward computation.
I0804 20:01:58.961915   840 net.cpp:200] relu3_1 does not need backward computation.
I0804 20:01:58.961925   840 net.cpp:200] conv3_1 does not need backward computation.
I0804 20:01:58.961936   840 net.cpp:200] conv2_2norm does not need backward computation.
I0804 20:01:58.961946   840 net.cpp:200] relu2_2 does not need backward computation.
I0804 20:01:58.961957   840 net.cpp:200] conv2_2 does not need backward computation.
I0804 20:01:58.961967   840 net.cpp:200] relu2_1 does not need backward computation.
I0804 20:01:58.961978   840 net.cpp:200] conv2_1 does not need backward computation.
I0804 20:01:58.961988   840 net.cpp:200] conv1_2norm does not need backward computation.
I0804 20:01:58.961999   840 net.cpp:200] relu1_2 does not need backward computation.
I0804 20:01:58.962020   840 net.cpp:200] conv1_2 does not need backward computation.
I0804 20:01:58.962031   840 net.cpp:200] relu1_1 does not need backward computation.
I0804 20:01:58.962041   840 net.cpp:200] bw_conv1_1 does not need backward computation.
I0804 20:01:58.962052   840 net.cpp:200] data_l does not need backward computation.
I0804 20:01:58.962085   840 net.cpp:255] Network initialization done.
I0804 20:01:59.048565   840 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_release_v2.caffemodel
I0804 20:01:59.048619   840 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 20:01:59.048635   840 net.cpp:744] Ignoring source layer img
I0804 20:01:59.048651   840 net.cpp:744] Ignoring source layer img_lab
I0804 20:01:59.048662   840 net.cpp:744] Ignoring source layer img_slice
I0804 20:01:59.048672   840 net.cpp:744] Ignoring source layer data_l_meansub
I0804 20:01:59.048683   840 net.cpp:744] Ignoring source layer data_ab_ss
I0804 20:01:59.048693   840 net.cpp:744] Ignoring source layer data_ab_ss_data_ab_ss_0_split
I0804 20:01:59.048703   840 net.cpp:744] Ignoring source layer ab_enc
I0804 20:01:59.048713   840 net.cpp:744] Ignoring source layer gt_ab_313_ab_enc_0_split
I0804 20:01:59.048723   840 net.cpp:744] Ignoring source layer ab_pb
I0804 20:01:59.048733   840 net.cpp:744] Ignoring source layer ab_pb
I0804 20:01:59.048743   840 net.cpp:744] Ignoring source layer pb_nongray
I0804 20:01:59.069959   840 net.cpp:744] Ignoring source layer PriorBoost8
I0804 20:01:59.069984   840 net.cpp:744] Ignoring source layer SoftmaxLoss8
/home/thijser/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.
  warn("The default mode, 'constant', will be changed to 'reflect' in "
/home/thijser/.local/lib/python2.7/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 54 pixels
  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
killing all other torch instances
/home/thijser/torch/install/bin/luajit: no process found
https://www.google.co.in/search?q=miniature+pinscher&safe=off&source=lnms&tbm=isch&num=25
there are total 100 images
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
th imageSelector.lua -avaible_images t/Pictures/miniature+pinscher/ActiOn_23.jpg,t/Pictures/miniature+pinscher/ActiOn_35.jpg,t/Pictures/miniature+pinscher/ActiOn_67.jpg,t/Pictures/miniature+pinscher/ActiOn_61.jpg,t/Pictures/miniature+pinscher/ActiOn_91.jpg,t/Pictures/miniature+pinscher/ActiOn_7.jpg,t/Pictures/miniature+pinscher/ActiOn_59.jpg,t/Pictures/miniature+pinscher/ActiOn_40.jpg,t/Pictures/miniature+pinscher/ActiOn_98.jpg,t/Pictures/miniature+pinscher/ActiOn_11.jpg,t/Pictures/miniature+pinscher/ActiOn_90.jpg,t/Pictures/miniature+pinscher/ActiOn_74.jpg,t/Pictures/miniature+pinscher/ActiOn_44.jpg,t/Pictures/miniature+pinscher/ActiOn_6.jpg,t/Pictures/miniature+pinscher/ActiOn_2.jpg,t/Pictures/miniature+pinscher/ActiOn_9.jpg,t/Pictures/miniature+pinscher/ActiOn_88.jpg,t/Pictures/miniature+pinscher/ActiOn_94.jpg,t/Pictures/miniature+pinscher/ActiOn_57.jpg,t/Pictures/miniature+pinscher/ActiOn_62.jpg,t/Pictures/miniature+pinscher/ActiOn_20.jpg,t/Pictures/miniature+pinscher/ActiOn_96.jpg,t/Pictures/miniature+pinscher/ActiOn_95.jpg,t/Pictures/miniature+pinscher/ActiOn_41.jpg,t/Pictures/miniature+pinscher/ActiOn_4.jpg,t/Pictures/miniature+pinscher/ActiOn_28.jpg,t/Pictures/miniature+pinscher/ActiOn_83.jpg,t/Pictures/miniature+pinscher/ActiOn_49.jpg,t/Pictures/miniature+pinscher/ActiOn_52.jpg,t/Pictures/miniature+pinscher/ActiOn_78.jpg,t/Pictures/miniature+pinscher/ActiOn_97.jpg,t/Pictures/miniature+pinscher/ActiOn_37.jpg,t/Pictures/miniature+pinscher/ActiOn_55.jpg,t/Pictures/miniature+pinscher/ActiOn_73.jpg,t/Pictures/miniature+pinscher/ActiOn_66.jpg,t/Pictures/miniature+pinscher/ActiOn_17.jpg,t/Pictures/miniature+pinscher/ActiOn_32.jpg,t/Pictures/miniature+pinscher/ActiOn_84.jpg,t/Pictures/miniature+pinscher/ActiOn_5.jpg,t/Pictures/miniature+pinscher/ActiOn_31.jpg,t/Pictures/miniature+pinscher/ActiOn_13.jpg,t/Pictures/miniature+pinscher/ActiOn_60.png,t/Pictures/miniature+pinscher/ActiOn_85.jpg,t/Pictures/miniature+pinscher/ActiOn_81.jpg,t/Pictures/miniature+pinscher/ActiOn_82.jpg,t/Pictures/miniature+pinscher/ActiOn_72.jpg,t/Pictures/miniature+pinscher/ActiOn_18.jpg,t/Pictures/miniature+pinscher/ActiOn_14.jpg,t/Pictures/miniature+pinscher/ActiOn_76.jpg,t/Pictures/miniature+pinscher/ActiOn_3.jpg,t/Pictures/miniature+pinscher/ActiOn_22.jpg,t/Pictures/miniature+pinscher/ActiOn_8.jpg,t/Pictures/miniature+pinscher/ActiOn_16.png,t/Pictures/miniature+pinscher/ActiOn_33.jpg,t/Pictures/miniature+pinscher/ActiOn_46.jpg,t/Pictures/miniature+pinscher/ActiOn_77.jpg,t/Pictures/miniature+pinscher/ActiOn_75.jpg,t/Pictures/miniature+pinscher/ActiOn_29.jpg,t/Pictures/miniature+pinscher/ActiOn_65.jpg,t/Pictures/miniature+pinscher/ActiOn_63.jpg,t/Pictures/miniature+pinscher/ActiOn_100.jpg,t/Pictures/miniature+pinscher/ActiOn_24.jpg,t/Pictures/miniature+pinscher/ActiOn_69.jpg,t/Pictures/miniature+pinscher/ActiOn_15.jpg,t/Pictures/miniature+pinscher/ActiOn_51.jpg,t/Pictures/miniature+pinscher/ActiOn_80.jpg,t/Pictures/miniature+pinscher/ActiOn_21.jpg,t/Pictures/miniature+pinscher/ActiOn_86.jpg,t/Pictures/miniature+pinscher/ActiOn_56.jpg,t/Pictures/miniature+pinscher/ActiOn_1.jpg,t/Pictures/miniature+pinscher/ActiOn_34.jpg,t/Pictures/miniature+pinscher/ActiOn_99.jpg,t/Pictures/miniature+pinscher/ActiOn_43.jpg,t/Pictures/miniature+pinscher/ActiOn_79.jpg,t/Pictures/miniature+pinscher/ActiOn_92.jpg,t/Pictures/miniature+pinscher/ActiOn_12.jpg,t/Pictures/miniature+pinscher/ActiOn_36.jpg,t/Pictures/miniature+pinscher/ActiOn_38.jpg,t/Pictures/miniature+pinscher/ActiOn_53.jpg,t/Pictures/miniature+pinscher/ActiOn_64.jpg,t/Pictures/miniature+pinscher/ActiOn_26.jpg,t/Pictures/miniature+pinscher/ActiOn_25.jpg,t/Pictures/miniature+pinscher/ActiOn_30.png,t/Pictures/miniature+pinscher/ActiOn_48.jpg,t/Pictures/miniature+pinscher/ActiOn_87.jpg,t/Pictures/miniature+pinscher/ActiOn_71.jpg,t/Pictures/miniature+pinscher/ActiOn_39.jpg,t/Pictures/miniature+pinscher/ActiOn_50.jpg,t/Pictures/miniature+pinscher/ActiOn_19.jpg,t/Pictures/miniature+pinscher/ActiOn_70.jpg,t/Pictures/miniature+pinscher/ActiOn_89.jpg,t/Pictures/miniature+pinscher/ActiOn_47.jpg,t/Pictures/miniature+pinscher/ActiOn_54.jpg,t/Pictures/miniature+pinscher/ActiOn_10.jpg
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
coleval=1263310247.0341	
neuroval=1848090352	
coleval=1823212237.0547	
neuroval=1306510848	
coleval=1760652842.3672	
neuroval=2076209824	
coleval=969677082.65188	
neuroval=1343741952	
coleval=1340555605.2695	
neuroval=1506471184	
coleval=1386408275.8191	
neuroval=1829437632	
coleval=363873790.45759	
neuroval=1624368672	
coleval=1473137292.6322	
neuroval=1922013920	
coleval=1284742317.9408	
neuroval=1432380176	
coleval=2063370281.3404	
neuroval=1549388592	
coleval=1471773559.9899	
neuroval=1748124032	
coleval=1813466250	
neuroval=1647678400	
coleval=2229823125	
neuroval=1458094848	
coleval=1814773125	
neuroval=1460598128	
coleval=1101448903.3896	
neuroval=1394272576	
coleval=1125183887.48	
neuroval=1800473344	
coleval=2598658034.9062	
neuroval=1407527088	
coleval=912430969.74198	
neuroval=1684493232	
coleval=1113030000	
neuroval=1401094320	
coleval=3619293362.8178	
neuroval=1773502288	
coleval=957047855.74777	
neuroval=1403822576	
coleval=1126529573.9294	
neuroval=1539032352	
coleval=2496705000	
neuroval=2012260976	
coleval=659106011.03992	
neuroval=1991962048	
coleval=1453088679.3472	
neuroval=1801335664	
coleval=1119279530.1649	
neuroval=1484401072	
coleval=1573106030.3546	
neuroval=1701949424	
coleval=1455244104.8841	
neuroval=2050737792	
coleval=1183901250	
neuroval=1830516848	
coleval=1262375280.1811	
neuroval=1454761008	
coleval=357323491.09123	
neuroval=1922919328	
coleval=2295825828.7073	
neuroval=2048558144	
coleval=2966621250	
neuroval=1538559568	
coleval=357501827.36699	
neuroval=1469845520	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_43.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_16.png"
      3 : "t/Pictures/miniature+pinscher/ActiOn_88.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_7.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_63.jpg"
    }
  2 : 1827347347.367
}
coleval=311237721.04742	
neuroval=1801253008	
coleval=591300853.6341	
neuroval=1682114112	
coleval=646299352.41284	
neuroval=1837702384	
coleval=1287031731.7708	
neuroval=1803584112	
coleval=3080353242.885	
neuroval=1455477456	
coleval=357501827.36699	
neuroval=1469845520	
coleval=221242552.15519	
neuroval=1512764688	
coleval=277666074.56847	
neuroval=1496251312	
coleval=1250742297.8924	
neuroval=1477682032	
coleval=424179456.42136	
neuroval=1622426128	
coleval=388024387.68087	
neuroval=1729148272	
coleval=363873790.45759	
neuroval=1624368672	
coleval=489162449.07924	
neuroval=1522920304	
coleval=612060741.48996	
neuroval=1612307472	
coleval=302173732.56138	
neuroval=1563603792	
coleval=299495860.45161	
neuroval=1702688384	
coleval=303883001.49909	
neuroval=1608242080	
coleval=357323491.09123	
neuroval=1922919328	
coleval=324832386.09801	
neuroval=2015930176	
coleval=668473361.47785	
neuroval=1930441472	
coleval=494651395.26048	
neuroval=1817451520	
coleval=1145306584.6162	
neuroval=1721309872	
coleval=391757000.139	
neuroval=1740870992	
coleval=969677082.65188	
neuroval=1343741952	
coleval=1140339753.9812	
neuroval=1820087984	
coleval=754035298.55836	
neuroval=1798988256	
coleval=818972171.97863	
neuroval=1891412576	
coleval=758022560.73667	
neuroval=1829188064	
coleval=749345625	
neuroval=1868696080	
coleval=957047855.74777	
neuroval=1403822576	
coleval=898251492.04799	
neuroval=1433947664	
coleval=1403863582.5893	
neuroval=1472153968	
coleval=1353610663.923	
neuroval=1583066384	
coleval=1434851032.3661	
neuroval=1470498352	
coleval=1926025913.923	
neuroval=1450571184	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_43.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_16.png"
      3 : "t/Pictures/miniature+pinscher/ActiOn_88.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_7.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_73.jpg"
    }
  2 : 1734007240.1552
}
coleval=1041924375	
neuroval=1548393600	
coleval=1991881875	
neuroval=1515665456	
coleval=1219495168.6555	
neuroval=1705842000	
coleval=411987742.65748	
neuroval=1735192848	
coleval=531157377.23214	
neuroval=1629834816	
coleval=221242552.15519	
neuroval=1512764688	
coleval=417609657.40688	
neuroval=1540472960	
coleval=521956040.36458	
neuroval=1504959200	
coleval=1203224358.724	
neuroval=1620256416	
coleval=803416649.73958	
neuroval=1616387088	
coleval=1104221250	
neuroval=1607699632	
coleval=277666074.56847	
neuroval=1496251312	
coleval=325909868.96221	
neuroval=1420214016	
coleval=374394714.51308	
neuroval=1486680960	
coleval=543061875	
neuroval=1506822848	
coleval=1372989375	
neuroval=1448232800	
coleval=1514763750	
neuroval=1459513216	
coleval=357501827.36699	
neuroval=1469845520	
coleval=1158572364.6519	
neuroval=1496978272	
coleval=1149966818.0679	
neuroval=1621500400	
coleval=1192186188.215	
neuroval=1452741040	
coleval=1232994697.6896	
neuroval=1444862960	
coleval=1955839928.5502	
neuroval=1583144208	
coleval=302173732.56138	
neuroval=1563603792	
coleval=288018822.75927	
neuroval=1714656912	
coleval=553608786.11135	
neuroval=1691672272	
coleval=473584728.38685	
neuroval=1619052912	
coleval=577727516.93094	
neuroval=1678700208	
coleval=731562863.23502	
neuroval=1772245248	
coleval=303883001.49909	
neuroval=1608242080	
coleval=341290508.51004	
neuroval=1479777968	
coleval=698084494.97768	
neuroval=1539857920	
coleval=1179126262.6266	
neuroval=1448263920	
coleval=581170106.54894	
neuroval=1377563488	
coleval=579130255.86613	
neuroval=1588418864	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_43.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_16.png"
      3 : "t/Pictures/miniature+pinscher/ActiOn_88.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_7.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_73.jpg"
    }
  2 : 1734007240.1552
}
coleval=1845584376.0279	
neuroval=1660335280	
coleval=317519627.89078	
neuroval=1740695952	
coleval=1292076124.7472	
neuroval=1903787360	
coleval=983748279.99829	
neuroval=1395820960	
coleval=2164314017.1919	
neuroval=1539554064	
coleval=221242552.15519	
neuroval=1512764688	
coleval=1191291230.9663	
neuroval=1543190160	
coleval=1852430715.3402	
neuroval=1581608960	
coleval=700962253.09099	
neuroval=1500375936	
coleval=628670152.77329	
neuroval=1483862560	
coleval=1040087396.7791	
neuroval=1765139104	
coleval=325909868.96221	
neuroval=1420214016	
coleval=242209931.01378	
neuroval=1433144944	
coleval=202402212.75207	
neuroval=1472612480	
coleval=385134935.8667	
neuroval=1498226240	
coleval=1241306682.0501	
neuroval=1600112816	
coleval=1190014395.4888	
neuroval=1709860560	
coleval=277666074.56847	
neuroval=1496251312	
coleval=292982008.15226	
neuroval=1525412464	
coleval=322700019.53125	
neuroval=1660963952	
coleval=397549129.2982	
neuroval=1481886976	
coleval=308294653.15423	
neuroval=1598377824	
coleval=453935557.44813	
neuroval=1689482944	
coleval=341290508.51004	
neuroval=1479777968	
coleval=842693648.85603	
neuroval=1662311984	
coleval=839244900.25112	
neuroval=1641644496	
coleval=1227035625	
neuroval=1603596112	
coleval=1302541683.8805	
neuroval=1602525392	
coleval=1143244187.1208	
neuroval=1363387488	
coleval=357501827.36699	
neuroval=1469845520	
coleval=1030143817.4707	
neuroval=1597548256	
coleval=826809846.34901	
neuroval=1583428096	
coleval=1050803624.8487	
neuroval=1662088928	
coleval=2387067785.1544	
neuroval=1660357360	
coleval=2387238090.9609	
neuroval=1643843984	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_8.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_2.jpg"
      3 : "t/Pictures/miniature+pinscher/ActiOn_22.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_7.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_73.jpg"
    }
  2 : 1675014692.7521
}
coleval=1055178042.4435	
neuroval=1345995968	
coleval=1325278396.4145	
neuroval=1332420960	
coleval=374418750	
neuroval=1575743488	
coleval=1306959186.8704	
neuroval=1455441312	
coleval=1505990576.0305	
neuroval=1515259408	
coleval=202402212.75207	
neuroval=1472612480	
coleval=193660650.20224	
neuroval=1552486656	
coleval=302337911.25334	
neuroval=1675028816	
coleval=817412494.17865	
neuroval=1546999392	
coleval=1117196667.6582	
neuroval=1498125440	
coleval=1267733172.3518	
neuroval=1418558688	
coleval=242209931.01378	
neuroval=1433144944	
coleval=325937053.23079	
neuroval=1390225776	
coleval=329954437.5597	
neuroval=1484192896	
coleval=309592970.2865	
neuroval=1533352992	
coleval=701507721.26107	
neuroval=1559741696	
coleval=885165308.87268	
neuroval=1374423792	
coleval=221242552.15519	
neuroval=1512764688	
coleval=876198234.18662	
neuroval=1563683968	
coleval=1831410665.0391	
neuroval=1442366768	
coleval=1250999889.6484	
neuroval=1505556496	
coleval=1347154904.8594	
neuroval=1650385200	
coleval=761328248.22656	
neuroval=1763491360	
coleval=325909868.96221	
neuroval=1420214016	
coleval=412244862.65759	
neuroval=1693633952	
coleval=672665708.26771	
neuroval=1682532336	
coleval=954754693.48216	
neuroval=1633967760	
coleval=953172934.4008	
neuroval=1718069520	
coleval=1291868418.2235	
neuroval=1402020448	
coleval=277666074.56847	
neuroval=1496251312	
coleval=1020631722.5356	
neuroval=1442852976	
coleval=1259441941.6735	
neuroval=1358071904	
coleval=1561169416.0636	
neuroval=1355605280	
coleval=1518129809.13	
neuroval=1505347216	
coleval=1670515144.2504	
neuroval=1493006672	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_8.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_2.jpg"
      3 : "t/Pictures/miniature+pinscher/ActiOn_22.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_7.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_73.jpg"
    }
  2 : 1675014692.7521
}
coleval=1947303750	
neuroval=1506185872	
coleval=567753718.305	
neuroval=1844936224	
coleval=1167415985.7701	
neuroval=1802165472	
coleval=2385028257.1615	
neuroval=1696500016	
coleval=684298277.95573	
neuroval=1264636816	
coleval=202402212.75207	
neuroval=1472612480	
coleval=1735655929.3886	
neuroval=1620617520	
coleval=1775804421.297	
neuroval=1775943568	
coleval=1728416970.8825	
neuroval=1570196272	
coleval=1838940985.8398	
neuroval=1543297616	
coleval=1280913597.0052	
neuroval=1547675376	
coleval=242209931.01378	
neuroval=1433144944	
coleval=959757207.01227	
neuroval=1516436192	
coleval=985650430.98958	
neuroval=1667997312	
coleval=961377233.20009	
neuroval=1775615808	
coleval=1369722487.7142	
neuroval=1787191968	
coleval=496374233.40935	
neuroval=1912510016	
coleval=325937053.23079	
neuroval=1390225776	
coleval=1507469943.5568	
neuroval=1383646816	
coleval=1871301598.5812	
neuroval=1591716256	
coleval=1936095000	
neuroval=1614393184	
coleval=2263162500	
neuroval=1605331584	
coleval=1412883829.0411	
neuroval=1782704192	
coleval=221242552.15519	
neuroval=1512764688	
coleval=366764592.41205	
neuroval=1637286816	
coleval=842126047.57862	
neuroval=1617551584	
coleval=1137369355.0003	
neuroval=1610097568	
coleval=1839017972.6761	
neuroval=1704639392	
coleval=2654623468.099	
neuroval=1667652960	
coleval=325909868.96221	
neuroval=1420214016	
coleval=320083977.65681	
neuroval=1469548928	
coleval=226859719.68602	
neuroval=1376826864	
coleval=259089544.27083	
neuroval=1294743792	
coleval=710095755.20833	
neuroval=1359314448	
coleval=2103188450.5208	
neuroval=1274718768	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_8.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_13.jpg"
      3 : "t/Pictures/miniature+pinscher/ActiOn_88.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_31.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_52.jpg"
    }
  2 : 1553833336.2708
}
coleval=2244865872.3958	
neuroval=1500360528	
coleval=1312468841.1458	
neuroval=1603691648	
coleval=351258742.43479	
neuroval=1618770784	
coleval=684197474.89653	
neuroval=1652334304	
coleval=851734083.65609	
neuroval=1686377632	
coleval=259089544.27083	
neuroval=1294743792	
coleval=1109730833.3333	
neuroval=1582445072	
coleval=1195478880.2083	
neuroval=1633148848	
coleval=1331155520.8333	
neuroval=1675973744	
coleval=1297023684.8958	
neuroval=1812448016	
coleval=1980235286.4583	
neuroval=1975576128	
coleval=226859719.68602	
neuroval=1376826864	
coleval=272290679.85623	
neuroval=1334197728	
coleval=264608549.00682	
neuroval=1582574160	
coleval=1220751077.9549	
neuroval=1733446528	
coleval=1856170325.5208	
neuroval=1792701344	
coleval=1965820130.2083	
neuroval=1760684736	
coleval=202402212.75207	
neuroval=1472612480	
coleval=296974245.56378	
neuroval=1377524288	
coleval=470090723.56123	
neuroval=1492954320	
coleval=420203348.85387	
neuroval=1567570176	
coleval=249763582.97975	
neuroval=1660749440	
coleval=272835198.85818	
neuroval=1676961472	
coleval=242209931.01378	
neuroval=1433144944	
coleval=484823515.22035	
neuroval=1521647232	
coleval=464238603.11097	
neuroval=1692056832	
coleval=149007595.64428	
neuroval=2116353120	
coleval=1015339815.2014	
neuroval=1586489376	
coleval=1058892274.4023	
neuroval=1580336960	
coleval=325937053.23079	
neuroval=1390225776	
coleval=607251072.03494	
neuroval=1579506960	
coleval=914121384.38547	
neuroval=1641504368	
coleval=777841319.91207	
neuroval=1532097360	
coleval=829587798.38161	
neuroval=1626064480	
coleval=1089541267.5234	
neuroval=1547688384	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_8.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_13.jpg"
      3 : "t/Pictures/miniature+pinscher/ActiOn_88.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_31.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_52.jpg"
    }
  2 : 1553833336.2708
}
coleval=2480385277.0238	
neuroval=1869385600	
coleval=566657356.58185	
neuroval=1643195600	
coleval=1040228061.7814	
neuroval=1388586464	
coleval=239620167.58169	
neuroval=1581062208	
coleval=911340669.52766	
neuroval=1613902480	
coleval=259089544.27083	
neuroval=1294743792	
coleval=315306380.20833	
neuroval=1382735984	
coleval=617383484.20908	
neuroval=1490133744	
coleval=564820882.04234	
neuroval=1480939536	
coleval=1756778778.6468	
neuroval=1518684816	
coleval=2518521604.4727	
neuroval=1607343984	
coleval=226859719.68602	
neuroval=1376826864	
coleval=389659929.34392	
neuroval=1517698896	
coleval=468821210.74634	
neuroval=1482762384	
coleval=516988840.98822	
neuroval=1536682064	
coleval=514577441.33942	
neuroval=1624151792	
coleval=665175867.63144	
neuroval=1607638416	
coleval=272290679.85623	
neuroval=1334197728	
coleval=371746953.52292	
neuroval=1476374352	
coleval=1297903435.2667	
neuroval=1317724352	
coleval=1164097234.2758	
neuroval=1499453408	
coleval=1075955908.2618	
neuroval=1247023920	
coleval=1534944051.2783	
neuroval=1204478160	
coleval=296974245.56378	
neuroval=1377524288	
coleval=1439521028.4381	
neuroval=1481573360	
coleval=1675416999.3998	
neuroval=1475533248	
coleval=1830246017.0211	
neuroval=1529924448	
coleval=2035950040.9469	
neuroval=1607263584	
coleval=1879462186.8447	
neuroval=1737481024	
coleval=202402212.75207	
neuroval=1472612480	
coleval=424577844.84137	
neuroval=1421804928	
coleval=763774999.93013	
neuroval=1644803616	
coleval=749359342.45445	
neuroval=1767345776	
coleval=1030736617.4152	
neuroval=1631815312	
coleval=458135199.21397	
neuroval=1666115344	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_8.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_13.jpg"
      3 : "t/Pictures/miniature+pinscher/ActiOn_88.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_31.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_52.jpg"
    }
  2 : 1553833336.2708
}
coleval=1543706468.5456	
neuroval=1243602480	
coleval=1470610232.141	
neuroval=1263223600	
coleval=1223164282.675	
neuroval=1906622944	
coleval=1414818445.572	
neuroval=1695358768	
coleval=1466563125	
neuroval=1232839008	
coleval=259089544.27083	
neuroval=1294743792	
coleval=209268802.08333	
neuroval=1270970736	
coleval=772898723.95833	
neuroval=1355925776	
coleval=1250842164.1565	
neuroval=1444584944	
coleval=1029218318.3051	
neuroval=1278862736	
coleval=1311936380.2083	
neuroval=1240106688	
coleval=226859719.68602	
neuroval=1376826864	
coleval=401722083.33333	
neuroval=1341313104	
coleval=398998125	
neuroval=1906481424	
coleval=290469215.56936	
neuroval=1941995184	
coleval=742622689.9894	
neuroval=1458447312	
coleval=1236810475.625	
neuroval=1299797312	
coleval=272290679.85623	
neuroval=1334197728	
coleval=993577552.97028	
neuroval=1464710128	
coleval=1334623781.9043	
neuroval=1662346688	
coleval=990223923.54585	
neuroval=1641302816	
coleval=357819727.06007	
neuroval=1625524288	
coleval=1176261575.5208	
neuroval=1705307744	
coleval=296974245.56378	
neuroval=1377524288	
coleval=285107233.34678	
neuroval=1327103040	
coleval=389610142.29791	
neuroval=1278229088	
coleval=909434833.45063	
neuroval=1317731776	
coleval=894996641.37199	
neuroval=1420953008	
coleval=906331279.79883	
neuroval=1626700304	
coleval=202402212.75207	
neuroval=1472612480	
coleval=588964827.36862	
neuroval=1462387344	
coleval=1633303094.8642	
neuroval=1324207936	
coleval=1666681741.4283	
neuroval=1783723264	
coleval=1821549530.9592	
neuroval=1214480656	
coleval=1864492500	
neuroval=1166536784	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_8.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_13.jpg"
      3 : "t/Pictures/miniature+pinscher/ActiOn_88.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_31.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_95.jpg"
    }
  2 : 1480239538.0833
}
coleval=863648843.13355	
neuroval=1631371072	
coleval=2146540583.4961	
neuroval=1608812736	
coleval=612496067.30126	
neuroval=1927762304	
coleval=232935000	
neuroval=1746209344	
coleval=1753246781.5955	
neuroval=1349265792	
coleval=209268802.08333	
neuroval=1270970736	
coleval=253870390.625	
neuroval=1350086960	
coleval=556851703.46983	
neuroval=1435998464	
coleval=269975505.45482	
neuroval=1520880608	
coleval=298248764.08726	
neuroval=1694611296	
coleval=329559105.491	
neuroval=1534531984	
coleval=259089544.27083	
neuroval=1294743792	
coleval=441764348.95833	
neuroval=1298055424	
coleval=745801341.14583	
neuroval=1381779760	
coleval=887867981.77083	
neuroval=1136690976	
coleval=955005000	
neuroval=1319683104	
coleval=2476681699.2187	
neuroval=1435979088	
coleval=226859719.68602	
neuroval=1376826864	
coleval=337686197.74109	
neuroval=1481478512	
coleval=1481865380.0449	
neuroval=1534978688	
coleval=398464853.74746	
neuroval=1742457552	
coleval=226015638.85938	
neuroval=1896985520	
coleval=556015469.05708	
neuroval=1961844928	
coleval=272290679.85623	
neuroval=1334197728	
coleval=1135473665.3473	
neuroval=1524461680	
coleval=1163387942.7083	
neuroval=1525311664	
coleval=951900755.20833	
neuroval=1577821024	
coleval=1460135295.4102	
neuroval=1535562112	
coleval=329195833.33333	
neuroval=1520714496	
coleval=285107233.34678	
neuroval=1327103040	
coleval=1616801250	
neuroval=1199557376	
coleval=1548000000	
neuroval=1315946992	
coleval=1995654976.8519	
neuroval=1229552128	
coleval=1806185545.3138	
neuroval=1433254576	
coleval=1249300890.1334	
neuroval=1332588896	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_8.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_13.jpg"
      3 : "t/Pictures/miniature+pinscher/ActiOn_88.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_31.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_95.jpg"
    }
  2 : 1480239538.0833
}
coleval=1539589688.2972	
neuroval=1678871232	
coleval=1082553564.8329	
neuroval=1564630784	
coleval=1909730625	
neuroval=1333002640	
coleval=2011711015.625	
neuroval=1820633840	
coleval=1026087275.7523	
neuroval=1599035824	
coleval=209268802.08333	
neuroval=1270970736	
coleval=263679348.95833	
neuroval=1191403984	
coleval=156538216.14583	
neuroval=1282691728	
coleval=1432139973.9583	
neuroval=1280960160	
coleval=759780872.39583	
neuroval=1363554064	
coleval=903764690.38983	
neuroval=1639836000	
coleval=259089544.27083	
neuroval=1294743792	
coleval=259093125	
neuroval=1511985232	
coleval=415811250	
neuroval=1529117264	
coleval=357856662.24888	
neuroval=1646062656	
coleval=414181351.14397	
neuroval=1590830912	
coleval=1145241184.8958	
neuroval=1950231552	
coleval=226859719.68602	
neuroval=1376826864	
coleval=204303974.98726	
neuroval=1358975760	
coleval=1261402890.2388	
neuroval=1404766544	
coleval=1635958437.1594	
neuroval=1378139024	
coleval=1883034375	
neuroval=1351240368	
coleval=1704791250	
neuroval=1380491072	
coleval=253870390.625	
neuroval=1350086960	
coleval=1279843750	
neuroval=1491391088	
coleval=1527916562.5	
neuroval=1546323264	
coleval=1715350937.5	
neuroval=1894250144	
coleval=704298515.625	
neuroval=1828981024	
coleval=1724476640.625	
neuroval=1756983680	
coleval=272290679.85623	
neuroval=1334197728	
coleval=1188172764.6436	
neuroval=1584204032	
coleval=1223254435.0564	
neuroval=1644517184	
coleval=658279428.5369	
neuroval=1613387488	
coleval=1300388366.3109	
neuroval=1754138960	
coleval=1472022841.7784	
neuroval=1698775344	
{
  1 : 
    {
      1 : "t/Pictures/miniature+pinscher/ActiOn_8.jpg"
      2 : "t/Pictures/miniature+pinscher/ActiOn_13.jpg"
      3 : "t/Pictures/miniature+pinscher/ActiOn_88.jpg"
      4 : "t/Pictures/miniature+pinscher/ActiOn_31.jpg"
      5 : "t/Pictures/miniature+pinscher/ActiOn_24.jpg"
    }
  2 : 1439229944.1458
}
selected:	
t/Pictures/miniature+pinscher/ActiOn_8.jpg	
t/Pictures/miniature+pinscher/ActiOn_13.jpg	
t/Pictures/miniature+pinscher/ActiOn_88.jpg	
t/Pictures/miniature+pinscher/ActiOn_31.jpg	
t/Pictures/miniature+pinscher/ActiOn_24.jpg	
t/Pictures/miniature+pinscher/ActiOn_8.jpg,t/Pictures/miniature+pinscher/ActiOn_13.jpg,t/Pictures/miniature+pinscher/ActiOn_88.jpg,t/Pictures/miniature+pinscher/ActiOn_31.jpg,t/Pictures/miniature+pinscher/ActiOn_24.jpg	
writing selected	
t/Pictures/miniature+pinscher/ActiOn_8.jpg	
t/Pictures/miniature+pinscher/ActiOn_13.jpg	
t/Pictures/miniature+pinscher/ActiOn_88.jpg	
t/Pictures/miniature+pinscher/ActiOn_31.jpg	
t/Pictures/miniature+pinscher/ActiOn_24.jpg	
done writing selector	
2426573	
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
Setting up style layer  	2	:	relu1_1	
Setting up style layer  	7	:	relu2_1	
Setting up style layer  	12	:	relu3_1	
Setting up style layer  	21	:	relu4_1	
Setting up content layer	23	:	relu4_2	
Setting up style layer  	30	:	relu5_1	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
Running optimization with L-BFGS	
 512
  36
  64
[torch.LongStorage of size 3]

34070822.547913	
<optim.lbfgs> 	creating recyclable direction/step/history buffers	
 512
  36
  64
[torch.LongStorage of size 3]

34070734.82056	
 512
  36
  64
[torch.LongStorage of size 3]

18177834.096985	
 512
  36
  64
[torch.LongStorage of size 3]

13180607.782898	
 512
  36
  64
[torch.LongStorage of size 3]

10051246.391449	
 512
  36
  64
[torch.LongStorage of size 3]

8243701.009903	
 512
  36
  64
[torch.LongStorage of size 3]

7012406.6718292	
 512
  36
  64
[torch.LongStorage of size 3]

5831477.1962738	
 512
  36
  64
[torch.LongStorage of size 3]

5109198.6619186	
 512
  36
  64
[torch.LongStorage of size 3]

4481179.5662689	
 512
  36
  64
[torch.LongStorage of size 3]

4174847.7140045	
 512
  36
  64
[torch.LongStorage of size 3]

3795243.3440781	
 512
  36
  64
[torch.LongStorage of size 3]

3456300.1071548	
 512
  36
  64
[torch.LongStorage of size 3]

3388606.5006256	
 512
  36
  64
[torch.LongStorage of size 3]

3144412.7776718	
 512
  36
  64
[torch.LongStorage of size 3]

3026543.0849457	
 512
  36
  64
[torch.LongStorage of size 3]

2821062.193985	
 512
  36
  64
[torch.LongStorage of size 3]

2790689.1076279	
 512
  36
  64
[torch.LongStorage of size 3]

2597334.5422363	
 512
  36
  64
[torch.LongStorage of size 3]

2542187.8692245	
 512
  36
  64
[torch.LongStorage of size 3]

2441251.4454651	
 512
  36
  64
[torch.LongStorage of size 3]

2344175.9043884	
 512
  36
  64
[torch.LongStorage of size 3]

2263638.6249161	
 512
  36
  64
[torch.LongStorage of size 3]

2194588.5976791	
 512
  36
  64
[torch.LongStorage of size 3]

2158816.8835068	
 512
  36
  64
[torch.LongStorage of size 3]

2071946.04496	
 512
  36
  64
[torch.LongStorage of size 3]

2030527.001152	
 512
  36
  64
[torch.LongStorage of size 3]

1983447.4298477	
 512
  36
  64
[torch.LongStorage of size 3]

1941071.9039917	
 512
  36
  64
[torch.LongStorage of size 3]

1899118.3699799	
 512
  36
  64
[torch.LongStorage of size 3]

1854327.7151108	
 512
  36
  64
[torch.LongStorage of size 3]

1812108.3823395	
 512
  36
  64
[torch.LongStorage of size 3]

1785414.0857697	
 512
  36
  64
[torch.LongStorage of size 3]

1740125.3264999	
 512
  36
  64
[torch.LongStorage of size 3]

1709859.9683762	
 512
  36
  64
[torch.LongStorage of size 3]

1679404.4477463	
 512
  36
  64
[torch.LongStorage of size 3]

1656741.1130524	
 512
  36
  64
[torch.LongStorage of size 3]

1630583.831749	
 512
  36
  64
[torch.LongStorage of size 3]

1608771.6962051	
 512
  36
  64
[torch.LongStorage of size 3]

1586557.6738358	
 512
  36
  64
[torch.LongStorage of size 3]

1559603.7519073	
 512
  36
  64
[torch.LongStorage of size 3]

1533350.773468	
 512
  36
  64
[torch.LongStorage of size 3]

1512448.0209732	
 512
  36
  64
[torch.LongStorage of size 3]

1500193.8529968	
 512
  36
  64
[torch.LongStorage of size 3]

1476360.321846	
 512
  36
  64
[torch.LongStorage of size 3]

1462495.2704239	
 512
  36
  64
[torch.LongStorage of size 3]

1449942.8911972	
 512
  36
  64
[torch.LongStorage of size 3]

1437526.5797424	
 512
  36
  64
[torch.LongStorage of size 3]

1428123.5391998	
 512
  36
  64
[torch.LongStorage of size 3]

1413047.463913	
 512
  36
  64
[torch.LongStorage of size 3]

1401375.7824326	
 512
  36
  64
[torch.LongStorage of size 3]

1380001.5626144	
 512
  36
  64
[torch.LongStorage of size 3]

1371805.6624985	
 512
  36
  64
[torch.LongStorage of size 3]

1360500.1197052	
 512
  36
  64
[torch.LongStorage of size 3]

1354127.5937271	
 512
  36
  64
[torch.LongStorage of size 3]

1346317.9780579	
 512
  36
  64
[torch.LongStorage of size 3]

1331646.7697144	
 512
  36
  64
[torch.LongStorage of size 3]

1318960.4983139	
 512
  36
  64
[torch.LongStorage of size 3]

1311592.2409058	
 512
  36
  64
[torch.LongStorage of size 3]

1298850.9156036	
 512
  36
  64
[torch.LongStorage of size 3]

1292682.0992279	
 512
  36
  64
[torch.LongStorage of size 3]

1285536.60923	
 512
  36
  64
[torch.LongStorage of size 3]

1274690.5643845	
 512
  36
  64
[torch.LongStorage of size 3]

1266010.2495956	
 512
  36
  64
[torch.LongStorage of size 3]

1257422.3943329	
 512
  36
  64
[torch.LongStorage of size 3]

1250402.9145432	
 512
  36
  64
[torch.LongStorage of size 3]

1244343.2068253	
 512
  36
  64
[torch.LongStorage of size 3]

1237255.1990128	
 512
  36
  64
[torch.LongStorage of size 3]

1230545.0745773	
 512
  36
  64
[torch.LongStorage of size 3]

1222491.3810349	
 512
  36
  64
[torch.LongStorage of size 3]

1214462.6974106	
 512
  36
  64
[torch.LongStorage of size 3]

1207230.4030228	
 512
  36
  64
[torch.LongStorage of size 3]

1201544.2835236	
 512
  36
  64
[torch.LongStorage of size 3]

1194308.6127472	
 512
  36
  64
[torch.LongStorage of size 3]

1187885.050354	
 512
  36
  64
[torch.LongStorage of size 3]

1179913.4527969	
 512
  36
  64
[torch.LongStorage of size 3]

1174543.0064011	
 512
  36
  64
[torch.LongStorage of size 3]

1168868.967514	
 512
  36
  64
[torch.LongStorage of size 3]

1164781.7326355	
 512
  36
  64
[torch.LongStorage of size 3]

1160291.1322784	
 512
  36
  64
[torch.LongStorage of size 3]

1154388.6742783	
 512
  36
  64
[torch.LongStorage of size 3]

1148303.9376831	
 512
  36
  64
[torch.LongStorage of size 3]

1143541.7589188	
 512
  36
  64
[torch.LongStorage of size 3]

1137997.6000595	
 512
  36
  64
[torch.LongStorage of size 3]

1134574.8196793	
 512
  36
  64
[torch.LongStorage of size 3]

1131319.8609161	
 512
  36
  64
[torch.LongStorage of size 3]

1125520.8231735	
 512
  36
  64
[torch.LongStorage of size 3]

1121257.4192429	
 512
  36
  64
[torch.LongStorage of size 3]

1116099.8651886	
 512
  36
  64
[torch.LongStorage of size 3]

1111458.1256104	
 512
  36
  64
[torch.LongStorage of size 3]

1107403.7399292	
 512
  36
  64
[torch.LongStorage of size 3]

1105133.1464767	
 512
  36
  64
[torch.LongStorage of size 3]

1100244.7177124	
 512
  36
  64
[torch.LongStorage of size 3]

1097009.6505737	
 512
  36
  64
[torch.LongStorage of size 3]

1094565.1995087	
 512
  36
  64
[torch.LongStorage of size 3]

1090497.6065826	
 512
  36
  64
[torch.LongStorage of size 3]

1087300.7807922	
 512
  36
  64
[torch.LongStorage of size 3]

1081047.9859924	
 512
  36
  64
[torch.LongStorage of size 3]

1076408.5166168	
 512
  36
  64
[torch.LongStorage of size 3]

1073708.4118652	
 512
  36
  64
[torch.LongStorage of size 3]

1070424.8138809	
 512
  36
  64
[torch.LongStorage of size 3]

1066873.3177185	
 512
  36
  64
[torch.LongStorage of size 3]

1061978.753891	
 512
  36
  64
[torch.LongStorage of size 3]

1057496.9826126	
 512
  36
  64
[torch.LongStorage of size 3]

1053819.041748	
 512
  36
  64
[torch.LongStorage of size 3]

1051802.1273422	
 512
  36
  64
[torch.LongStorage of size 3]

1048578.3379745	
 512
  36
  64
[torch.LongStorage of size 3]

1045103.1310272	
 512
  36
  64
[torch.LongStorage of size 3]

1041229.6370697	
 512
  36
  64
[torch.LongStorage of size 3]

1037502.527504	
 512
  36
  64
[torch.LongStorage of size 3]

1034225.2672577	
 512
  36
  64
[torch.LongStorage of size 3]

1030739.4665909	
 512
  36
  64
[torch.LongStorage of size 3]

1028296.6801834	
 512
  36
  64
[torch.LongStorage of size 3]

1025211.92276	
 512
  36
  64
[torch.LongStorage of size 3]

1022229.7170639	
 512
  36
  64
[torch.LongStorage of size 3]

1020244.6106339	
 512
  36
  64
[torch.LongStorage of size 3]

1017631.6621399	
 512
  36
  64
[torch.LongStorage of size 3]

1013987.6347733	
 512
  36
  64
[torch.LongStorage of size 3]

1010431.7187119	
 512
  36
  64
[torch.LongStorage of size 3]

1007690.0665665	
 512
  36
  64
[torch.LongStorage of size 3]

1005685.4468918	
 512
  36
  64
[torch.LongStorage of size 3]

1002695.2477264	
 512
  36
  64
[torch.LongStorage of size 3]

1001364.7576141	
 512
  36
  64
[torch.LongStorage of size 3]

997747.82878876	
 512
  36
  64
[torch.LongStorage of size 3]

995864.13383484	
 512
  36
  64
[torch.LongStorage of size 3]

994241.48475647	
 512
  36
  64
[torch.LongStorage of size 3]

991473.26263428	
 512
  36
  64
[torch.LongStorage of size 3]

988232.71781921	
 512
  36
  64
[torch.LongStorage of size 3]

985747.27676392	
 512
  36
  64
[torch.LongStorage of size 3]

984445.63991547	
 512
  36
  64
[torch.LongStorage of size 3]

981923.57833862	
 512
  36
  64
[torch.LongStorage of size 3]

979784.78599548	
 512
  36
  64
[torch.LongStorage of size 3]

977922.68234253	
 512
  36
  64
[torch.LongStorage of size 3]

975507.62554169	
 512
  36
  64
[torch.LongStorage of size 3]

973921.23806	
 512
  36
  64
[torch.LongStorage of size 3]

971677.98877716	
 512
  36
  64
[torch.LongStorage of size 3]

969098.98620605	
 512
  36
  64
[torch.LongStorage of size 3]

966728.59573364	
 512
  36
  64
[torch.LongStorage of size 3]

964627.49603271	
 512
  36
  64
[torch.LongStorage of size 3]

963031.967659	
 512
  36
  64
[torch.LongStorage of size 3]

960905.795784	
 512
  36
  64
[torch.LongStorage of size 3]

959276.53568268	
 512
  36
  64
[torch.LongStorage of size 3]

957155.80417633	
 512
  36
  64
[torch.LongStorage of size 3]

955022.27233887	
 512
  36
  64
[torch.LongStorage of size 3]

953332.37442017	
 512
  36
  64
[torch.LongStorage of size 3]

951337.45101929	
 512
  36
  64
[torch.LongStorage of size 3]

949248.64704132	
 512
  36
  64
[torch.LongStorage of size 3]

947565.51441193	
 512
  36
  64
[torch.LongStorage of size 3]

945843.67347717	
 512
  36
  64
[torch.LongStorage of size 3]

944195.58635712	
 512
  36
  64
[torch.LongStorage of size 3]

942568.9024353	
 512
  36
  64
[torch.LongStorage of size 3]

940650.51597595	
 512
  36
  64
[torch.LongStorage of size 3]

938664.10514832	
 512
  36
  64
[torch.LongStorage of size 3]

936947.4363327	
 512
  36
  64
[torch.LongStorage of size 3]

935289.67212677	
 512
  36
  64
[torch.LongStorage of size 3]

934000.7730484	
 512
  36
  64
[torch.LongStorage of size 3]

932203.5484314	
 512
  36
  64
[torch.LongStorage of size 3]

931389.45289612	
 512
  36
  64
[torch.LongStorage of size 3]

929787.889328	
 512
  36
  64
[torch.LongStorage of size 3]

928750.15155792	
 512
  36
  64
[torch.LongStorage of size 3]

927373.3939743	
 512
  36
  64
[torch.LongStorage of size 3]

925730.34755707	
 512
  36
  64
[torch.LongStorage of size 3]

923571.16256714	
 512
  36
  64
[torch.LongStorage of size 3]

921964.86412048	
 512
  36
  64
[torch.LongStorage of size 3]

920879.17785645	
 512
  36
  64
[torch.LongStorage of size 3]

920013.2579422	
 512
  36
  64
[torch.LongStorage of size 3]

918899.099617	
 512
  36
  64
[torch.LongStorage of size 3]

917310.71350098	
 512
  36
  64
[torch.LongStorage of size 3]

915739.69966888	
 512
  36
  64
[torch.LongStorage of size 3]

914111.86897278	
 512
  36
  64
[torch.LongStorage of size 3]

912833.17462921	
 512
  36
  64
[torch.LongStorage of size 3]

911803.65665436	
 512
  36
  64
[torch.LongStorage of size 3]

910874.10274506	
 512
  36
  64
[torch.LongStorage of size 3]

909989.78908539	
 512
  36
  64
[torch.LongStorage of size 3]

908482.53505707	
 512
  36
  64
[torch.LongStorage of size 3]

906811.18873596	
 512
  36
  64
[torch.LongStorage of size 3]

905430.36243439	
 512
  36
  64
[torch.LongStorage of size 3]

904072.49336243	
 512
  36
  64
[torch.LongStorage of size 3]

903346.52317047	
 512
  36
  64
[torch.LongStorage of size 3]

902307.61623383	
 512
  36
  64
[torch.LongStorage of size 3]

901543.28678131	
 512
  36
  64
[torch.LongStorage of size 3]

900224.69421387	
 512
  36
  64
[torch.LongStorage of size 3]

898570.31200409	
 512
  36
  64
[torch.LongStorage of size 3]

897374.10648346	
 512
  36
  64
[torch.LongStorage of size 3]

896472.17243195	
 512
  36
  64
[torch.LongStorage of size 3]

895796.96754456	
 512
  36
  64
[torch.LongStorage of size 3]

894995.02262115	
 512
  36
  64
[torch.LongStorage of size 3]

893987.45872498	
 512
  36
  64
[torch.LongStorage of size 3]

892833.16925049	
 512
  36
  64
[torch.LongStorage of size 3]

891923.79173279	
 512
  36
  64
[torch.LongStorage of size 3]

890522.70343781	
 512
  36
  64
[torch.LongStorage of size 3]

889654.44271088	
 512
  36
  64
[torch.LongStorage of size 3]

888884.95552063	
 512
  36
  64
[torch.LongStorage of size 3]

888245.1632309	
 512
  36
  64
[torch.LongStorage of size 3]

887314.29088593	
 512
  36
  64
[torch.LongStorage of size 3]

886454.95456696	
 512
  36
  64
[torch.LongStorage of size 3]

885245.23590088	
 512
  36
  64
[torch.LongStorage of size 3]

884394.83356476	
 512
  36
  64
[torch.LongStorage of size 3]

883839.82055664	
 512
  36
  64
[torch.LongStorage of size 3]

882913.87641907	
 512
  36
  64
[torch.LongStorage of size 3]

882207.74097443	
 512
  36
  64
[torch.LongStorage of size 3]

881359.67502594	
 512
  36
  64
[torch.LongStorage of size 3]

880378.87390137	
 512
  36
  64
[torch.LongStorage of size 3]

879433.00289154	
 512
  36
  64
[torch.LongStorage of size 3]

878691.76425934	
 512
  36
  64
[torch.LongStorage of size 3]

877863.07441711	
 512
  36
  64
[torch.LongStorage of size 3]

876978.44806671	
 512
  36
  64
[torch.LongStorage of size 3]

876074.78935242	
 512
  36
  64
[torch.LongStorage of size 3]

875388.09368134	
 512
  36
  64
[torch.LongStorage of size 3]

874651.86134338	
 512
  36
  64
[torch.LongStorage of size 3]

874025.4624176	
 512
  36
  64
[torch.LongStorage of size 3]

873347.70019531	
 512
  36
  64
[torch.LongStorage of size 3]

872541.19327545	
 512
  36
  64
[torch.LongStorage of size 3]

871623.19831848	
 512
  36
  64
[torch.LongStorage of size 3]

870898.81843567	
 512
  36
  64
[torch.LongStorage of size 3]

870220.65917969	
 512
  36
  64
[torch.LongStorage of size 3]

869660.17894745	
 512
  36
  64
[torch.LongStorage of size 3]

869201.63589478	
 512
  36
  64
[torch.LongStorage of size 3]

868254.09938812	
 512
  36
  64
[torch.LongStorage of size 3]

867651.22375488	
 512
  36
  64
[torch.LongStorage of size 3]

866932.82871246	
 512
  36
  64
[torch.LongStorage of size 3]

866194.40700531	
 512
  36
  64
[torch.LongStorage of size 3]

865535.31257629	
 512
  36
  64
[torch.LongStorage of size 3]

864964.1135788	
 512
  36
  64
[torch.LongStorage of size 3]

864336.17053986	
 512
  36
  64
[torch.LongStorage of size 3]

863710.12207031	
 512
  36
  64
[torch.LongStorage of size 3]

862752.41344452	
 512
  36
  64
[torch.LongStorage of size 3]

862077.79979706	
 512
  36
  64
[torch.LongStorage of size 3]

861585.94093323	
 512
  36
  64
[torch.LongStorage of size 3]

861235.36434174	
 512
  36
  64
[torch.LongStorage of size 3]

860746.26182556	
 512
  36
  64
[torch.LongStorage of size 3]

860251.88667297	
 512
  36
  64
[torch.LongStorage of size 3]

859478.46679688	
 512
  36
  64
[torch.LongStorage of size 3]

858783.17092896	
 512
  36
  64
[torch.LongStorage of size 3]

858236.5927124	
 512
  36
  64
[torch.LongStorage of size 3]

857739.31941986	
 512
  36
  64
[torch.LongStorage of size 3]

857251.23683929	
 512
  36
  64
[torch.LongStorage of size 3]

856663.44100952	
 512
  36
  64
[torch.LongStorage of size 3]

856153.30039978	
 512
  36
  64
[torch.LongStorage of size 3]

855529.08069611	
 512
  36
  64
[torch.LongStorage of size 3]

854956.87602997	
 512
  36
  64
[torch.LongStorage of size 3]

854455.5626297	
 512
  36
  64
[torch.LongStorage of size 3]

853810.67775726	
 512
  36
  64
[torch.LongStorage of size 3]

853239.95483398	
 512
  36
  64
[torch.LongStorage of size 3]

852620.49720764	
 512
  36
  64
[torch.LongStorage of size 3]

852190.12825012	
 512
  36
  64
[torch.LongStorage of size 3]

851895.63282013	
 512
  36
  64
[torch.LongStorage of size 3]

851381.50344849	
 512
  36
  64
[torch.LongStorage of size 3]

851061.86393738	
 512
  36
  64
[torch.LongStorage of size 3]

850647.34397888	
 512
  36
  64
[torch.LongStorage of size 3]

850131.45381927	
 512
  36
  64
[torch.LongStorage of size 3]

849509.16210175	
 512
  36
  64
[torch.LongStorage of size 3]

848944.9539566	
 512
  36
  64
[torch.LongStorage of size 3]

848615.05432129	
 512
  36
  64
[torch.LongStorage of size 3]

848042.11284637	
 512
  36
  64
[torch.LongStorage of size 3]

847503.09341431	
 512
  36
  64
[torch.LongStorage of size 3]

847105.76084137	
 512
  36
  64
[torch.LongStorage of size 3]

846807.89176941	
 512
  36
  64
[torch.LongStorage of size 3]

846623.25218201	
 512
  36
  64
[torch.LongStorage of size 3]

846144.90856171	
 512
  36
  64
[torch.LongStorage of size 3]

845710.16845703	
 512
  36
  64
[torch.LongStorage of size 3]

845318.22231293	
 512
  36
  64
[torch.LongStorage of size 3]

844814.5104599	
 512
  36
  64
[torch.LongStorage of size 3]

844394.19029236	
 512
  36
  64
[torch.LongStorage of size 3]

844091.06494904	
 512
  36
  64
[torch.LongStorage of size 3]

843813.92757416	
 512
  36
  64
[torch.LongStorage of size 3]

843538.77346039	
 512
  36
  64
[torch.LongStorage of size 3]

843167.14927673	
 512
  36
  64
[torch.LongStorage of size 3]

842681.13891602	
 512
  36
  64
[torch.LongStorage of size 3]

842346.0251236	
 512
  36
  64
[torch.LongStorage of size 3]

841962.21061707	
 512
  36
  64
[torch.LongStorage of size 3]

841508.89110565	
 512
  36
  64
[torch.LongStorage of size 3]

841079.44320679	
 512
  36
  64
[torch.LongStorage of size 3]

840677.80769348	
 512
  36
  64
[torch.LongStorage of size 3]

840370.86753845	
 512
  36
  64
[torch.LongStorage of size 3]

840050.87970734	
 512
  36
  64
[torch.LongStorage of size 3]

839838.14868927	
 512
  36
  64
[torch.LongStorage of size 3]

839438.31851959	
 512
  36
  64
[torch.LongStorage of size 3]

839220.68138123	
 512
  36
  64
[torch.LongStorage of size 3]

838875.09227753	
 512
  36
  64
[torch.LongStorage of size 3]

838502.86125183	
 512
  36
  64
[torch.LongStorage of size 3]

838137.70210266	
 512
  36
  64
[torch.LongStorage of size 3]

837914.62177277	
 512
  36
  64
[torch.LongStorage of size 3]

837538.13808441	
 512
  36
  64
[torch.LongStorage of size 3]

837142.92072296	
 512
  36
  64
[torch.LongStorage of size 3]

836866.18041992	
 512
  36
  64
[torch.LongStorage of size 3]

836651.76242828	
 512
  36
  64
[torch.LongStorage of size 3]

836356.68197632	
 512
  36
  64
[torch.LongStorage of size 3]

836109.06112671	
 512
  36
  64
[torch.LongStorage of size 3]

835798.37745667	
 512
  36
  64
[torch.LongStorage of size 3]

835516.47251129	
 512
  36
  64
[torch.LongStorage of size 3]

835242.62699127	
 512
  36
  64
[torch.LongStorage of size 3]

834913.32546234	
 512
  36
  64
[torch.LongStorage of size 3]

834601.75518036	
 512
  36
  64
[torch.LongStorage of size 3]

834349.27639008	
 512
  36
  64
[torch.LongStorage of size 3]

834028.20827484	
 512
  36
  64
[torch.LongStorage of size 3]

833674.26357269	
 512
  36
  64
[torch.LongStorage of size 3]

833426.4932251	
 512
  36
  64
[torch.LongStorage of size 3]

833231.07421875	
 512
  36
  64
[torch.LongStorage of size 3]

833046.45610809	
 512
  36
  64
[torch.LongStorage of size 3]

832805.78266144	
 512
  36
  64
[torch.LongStorage of size 3]

832544.45541382	
 512
  36
  64
[torch.LongStorage of size 3]

832193.19496155	
 512
  36
  64
[torch.LongStorage of size 3]

831891.73408508	
 512
  36
  64
[torch.LongStorage of size 3]

831682.60433197	
 512
  36
  64
[torch.LongStorage of size 3]

831432.8181076	
 512
  36
  64
[torch.LongStorage of size 3]

831206.6992569	
 512
  36
  64
[torch.LongStorage of size 3]

830844.37927246	
 512
  36
  64
[torch.LongStorage of size 3]

830701.7741394	
 512
  36
  64
[torch.LongStorage of size 3]

830459.62799072	
 512
  36
  64
[torch.LongStorage of size 3]

830219.81960297	
 512
  36
  64
[torch.LongStorage of size 3]

829995.23357391	
 512
  36
  64
[torch.LongStorage of size 3]

829658.00708771	
 512
  36
  64
[torch.LongStorage of size 3]

829443.6473465	
 512
  36
  64
[torch.LongStorage of size 3]

829249.21005249	
 512
  36
  64
[torch.LongStorage of size 3]

829028.99486542	
 512
  36
  64
[torch.LongStorage of size 3]

828828.27705383	
 512
  36
  64
[torch.LongStorage of size 3]

828620.43464661	
 512
  36
  64
[torch.LongStorage of size 3]

828360.36615372	
 512
  36
  64
[torch.LongStorage of size 3]

828166.2251091	
 512
  36
  64
[torch.LongStorage of size 3]

827933.25639725	
 512
  36
  64
[torch.LongStorage of size 3]

827752.70744324	
 512
  36
  64
[torch.LongStorage of size 3]

827542.50097275	
 512
  36
  64
[torch.LongStorage of size 3]

827246.40176773	
 512
  36
  64
[torch.LongStorage of size 3]

827007.53810883	
 512
  36
  64
[torch.LongStorage of size 3]

826773.55867386	
 512
  36
  64
[torch.LongStorage of size 3]

826590.78878403	
 512
  36
  64
[torch.LongStorage of size 3]

826358.80805969	
 512
  36
  64
[torch.LongStorage of size 3]

826141.73530579	
 512
  36
  64
[torch.LongStorage of size 3]

826028.46191406	
 512
  36
  64
[torch.LongStorage of size 3]

825826.01055145	
 512
  36
  64
[torch.LongStorage of size 3]

825642.5044632	
 512
  36
  64
[torch.LongStorage of size 3]

825485.32962799	
Iteration 333 / 1000	
  Content 1 loss: 640882.226562	
  Style 1 loss: 1361.572647	
  Style 2 loss: 8792.201233	
  Style 3 loss: 7178.607941	
  Style 4 loss: 165069.580078	
  Style 5 loss: 2201.141167	
  Total loss: 825485.329628	
s/KNSGUHk.jpg_out_prepost_333.png	
 512
  36
  64
[torch.LongStorage of size 3]

825255.91442108	
 512
  36
  64
[torch.LongStorage of size 3]

825016.27771378	
 512
  36
  64
[torch.LongStorage of size 3]

824847.88356781	
 512
  36
  64
[torch.LongStorage of size 3]

824734.67445374	
 512
  36
  64
[torch.LongStorage of size 3]

824575.51229477	
 512
  36
  64
[torch.LongStorage of size 3]

824369.093647	
 512
  36
  64
[torch.LongStorage of size 3]

824157.90632248	
 512
  36
  64
[torch.LongStorage of size 3]

823959.792099	
 512
  36
  64
[torch.LongStorage of size 3]

823765.22289276	
 512
  36
  64
[torch.LongStorage of size 3]

823550.99468231	
 512
  36
  64
[torch.LongStorage of size 3]

823385.5513382	
 512
  36
  64
[torch.LongStorage of size 3]

823238.58358383	
 512
  36
  64
[torch.LongStorage of size 3]

823103.7730217	
 512
  36
  64
[torch.LongStorage of size 3]

822914.74357605	
 512
  36
  64
[torch.LongStorage of size 3]

822766.87181473	
 512
  36
  64
[torch.LongStorage of size 3]

822614.25857544	
 512
  36
  64
[torch.LongStorage of size 3]

822445.90522766	
 512
  36
  64
[torch.LongStorage of size 3]

822267.14252472	
 512
  36
  64
[torch.LongStorage of size 3]

822065.52902222	
 512
  36
  64
[torch.LongStorage of size 3]

821915.9321785	
 512
  36
  64
[torch.LongStorage of size 3]

821753.69932175	
 512
  36
  64
[torch.LongStorage of size 3]

821546.31835938	
 512
  36
  64
[torch.LongStorage of size 3]

821391.26277924	
 512
  36
  64
[torch.LongStorage of size 3]

821234.52598572	
 512
  36
  64
[torch.LongStorage of size 3]

821086.74964905	
 512
  36
  64
[torch.LongStorage of size 3]

821006.39137268	
 512
  36
  64
[torch.LongStorage of size 3]

820847.0658493	
 512
  36
  64
[torch.LongStorage of size 3]

820682.10697174	
 512
  36
  64
[torch.LongStorage of size 3]

820539.67308044	
 512
  36
  64
[torch.LongStorage of size 3]

820351.83908463	
 512
  36
  64
[torch.LongStorage of size 3]

820167.08406448	
 512
  36
  64
[torch.LongStorage of size 3]

820018.46656799	
 512
  36
  64
[torch.LongStorage of size 3]

819896.62498474	
 512
  36
  64
[torch.LongStorage of size 3]

819732.4061203	
 512
  36
  64
[torch.LongStorage of size 3]

819571.36039734	
 512
  36
  64
[torch.LongStorage of size 3]

819428.76138687	
 512
  36
  64
[torch.LongStorage of size 3]

819288.38665009	
 512
  36
  64
[torch.LongStorage of size 3]

819193.29372406	
 512
  36
  64
[torch.LongStorage of size 3]

819066.54310226	
 512
  36
  64
[torch.LongStorage of size 3]

818897.61932373	
 512
  36
  64
[torch.LongStorage of size 3]

818753.04582596	
 512
  36
  64
[torch.LongStorage of size 3]

818594.39085007	
 512
  36
  64
[torch.LongStorage of size 3]

818466.8693161	
 512
  36
  64
[torch.LongStorage of size 3]

818320.2765274	
 512
  36
  64
[torch.LongStorage of size 3]

818221.00208282	
 512
  36
  64
[torch.LongStorage of size 3]

818049.73451614	
 512
  36
  64
[torch.LongStorage of size 3]

817942.45304108	
 512
  36
  64
[torch.LongStorage of size 3]

817772.49851227	
 512
  36
  64
[torch.LongStorage of size 3]

817616.57821655	
 512
  36
  64
[torch.LongStorage of size 3]

817500.30992508	
 512
  36
  64
[torch.LongStorage of size 3]

817367.60570526	
 512
  36
  64
[torch.LongStorage of size 3]

817269.2040062	
 512
  36
  64
[torch.LongStorage of size 3]

817259.08477783	
 512
  36
  64
[torch.LongStorage of size 3]

817110.83320618	
 512
  36
  64
[torch.LongStorage of size 3]

816951.02359772	
 512
  36
  64
[torch.LongStorage of size 3]

816841.19012833	
 512
  36
  64
[torch.LongStorage of size 3]

816720.79708099	
 512
  36
  64
[torch.LongStorage of size 3]

816586.06323242	
 512
  36
  64
[torch.LongStorage of size 3]

816504.25243378	
 512
  36
  64
[torch.LongStorage of size 3]

816405.36680222	
 512
  36
  64
[torch.LongStorage of size 3]

816286.57421112	
 512
  36
  64
[torch.LongStorage of size 3]

816134.04148102	
 512
  36
  64
[torch.LongStorage of size 3]

816024.75057602	
 512
  36
  64
[torch.LongStorage of size 3]

815912.69338608	
 512
  36
  64
[torch.LongStorage of size 3]

815809.3919754	
 512
  36
  64
[torch.LongStorage of size 3]

815695.49440384	
 512
  36
  64
[torch.LongStorage of size 3]

815600.47599792	
 512
  36
  64
[torch.LongStorage of size 3]

815510.83311081	
 512
  36
  64
[torch.LongStorage of size 3]

815418.64234924	
 512
  36
  64
[torch.LongStorage of size 3]

815294.1223526	
 512
  36
  64
[torch.LongStorage of size 3]

815174.09942627	
 512
  36
  64
[torch.LongStorage of size 3]

815080.71580887	
 512
  36
  64
[torch.LongStorage of size 3]

814975.45248032	
 512
  36
  64
[torch.LongStorage of size 3]

814865.85100174	
 512
  36
  64
[torch.LongStorage of size 3]

814736.09865189	
 512
  36
  64
[torch.LongStorage of size 3]

814631.94074631	
 512
  36
  64
[torch.LongStorage of size 3]

814520.38897514	
 512
  36
  64
[torch.LongStorage of size 3]

814408.97366524	
 512
  36
  64
[torch.LongStorage of size 3]

814318.9922142	
 512
  36
  64
[torch.LongStorage of size 3]

814194.69611168	
 512
  36
  64
[torch.LongStorage of size 3]

814124.66697693	
 512
  36
  64
[torch.LongStorage of size 3]

814039.82469559	
 512
  36
  64
[torch.LongStorage of size 3]

813954.74502563	
 512
  36
  64
[torch.LongStorage of size 3]

813843.22680473	
 512
  36
  64
[torch.LongStorage of size 3]

813730.20403862	
 512
  36
  64
[torch.LongStorage of size 3]

813612.28726387	
 512
  36
  64
[torch.LongStorage of size 3]

813514.27686691	
 512
  36
  64
[torch.LongStorage of size 3]

813426.34801865	
 512
  36
  64
[torch.LongStorage of size 3]

813308.26372147	
 512
  36
  64
[torch.LongStorage of size 3]

813215.37779808	
 512
  36
  64
[torch.LongStorage of size 3]

813093.7157917	
 512
  36
  64
[torch.LongStorage of size 3]

813014.66365814	
 512
  36
  64
[torch.LongStorage of size 3]

812907.76260376	
 512
  36
  64
[torch.LongStorage of size 3]

812817.55065918	
 512
  36
  64
[torch.LongStorage of size 3]

812789.3225193	
 512
  36
  64
[torch.LongStorage of size 3]

812678.29050064	
 512
  36
  64
[torch.LongStorage of size 3]

812579.20518875	
 512
  36
  64
[torch.LongStorage of size 3]

812495.70274353	
 512
  36
  64
[torch.LongStorage of size 3]

812401.97598457	
 512
  36
  64
[torch.LongStorage of size 3]

812308.82587433	
 512
  36
  64
[torch.LongStorage of size 3]

812223.76132965	
 512
  36
  64
[torch.LongStorage of size 3]

812138.09523582	
 512
  36
  64
[torch.LongStorage of size 3]

812036.30485535	
 512
  36
  64
[torch.LongStorage of size 3]

811964.17645454	
 512
  36
  64
[torch.LongStorage of size 3]

811859.74611282	
 512
  36
  64
[torch.LongStorage of size 3]

811789.87059593	
 512
  36
  64
[torch.LongStorage of size 3]

811712.73677826	
 512
  36
  64
[torch.LongStorage of size 3]

811635.29244423	
 512
  36
  64
[torch.LongStorage of size 3]

811557.40527153	
 512
  36
  64
[torch.LongStorage of size 3]

811494.94073868	
 512
  36
  64
[torch.LongStorage of size 3]

811417.48186111	
 512
  36
  64
[torch.LongStorage of size 3]

811348.23460579	
 512
  36
  64
[torch.LongStorage of size 3]

811291.70405388	
 512
  36
  64
[torch.LongStorage of size 3]

811206.95692062	
 512
  36
  64
[torch.LongStorage of size 3]

811134.8012352	
 512
  36
  64
[torch.LongStorage of size 3]

811034.4410038	
 512
  36
  64
[torch.LongStorage of size 3]

810974.38200951	
 512
  36
  64
[torch.LongStorage of size 3]

810876.40482903	
 512
  36
  64
[torch.LongStorage of size 3]

810813.62683296	
 512
  36
  64
[torch.LongStorage of size 3]

810736.89647675	
 512
  36
  64
[torch.LongStorage of size 3]

810676.62538528	
 512
  36
  64
[torch.LongStorage of size 3]

810605.39439201	
 512
  36
  64
[torch.LongStorage of size 3]

810538.22836876	
 512
  36
  64
[torch.LongStorage of size 3]

810472.70058632	
 512
  36
  64
[torch.LongStorage of size 3]

810411.91352844	
 512
  36
  64
[torch.LongStorage of size 3]

810345.69565773	
 512
  36
  64
[torch.LongStorage of size 3]

810282.30321884	
 512
  36
  64
[torch.LongStorage of size 3]

810213.32780838	
 512
  36
  64
[torch.LongStorage of size 3]

810130.45377731	
 512
  36
  64
[torch.LongStorage of size 3]

810059.48642731	
 512
  36
  64
[torch.LongStorage of size 3]

809991.04450226	
 512
  36
  64
[torch.LongStorage of size 3]

809926.48104668	
 512
  36
  64
[torch.LongStorage of size 3]

809874.43199158	
 512
  36
  64
[torch.LongStorage of size 3]

809784.00533676	
 512
  36
  64
[torch.LongStorage of size 3]

809743.68645668	
 512
  36
  64
[torch.LongStorage of size 3]

809673.94935608	
 512
  36
  64
[torch.LongStorage of size 3]

809608.80395889	
 512
  36
  64
[torch.LongStorage of size 3]

809557.55714417	
 512
  36
  64
[torch.LongStorage of size 3]

809494.94970322	
 512
  36
  64
[torch.LongStorage of size 3]

809444.601717	
 512
  36
  64
[torch.LongStorage of size 3]

809378.2948494	
 512
  36
  64
[torch.LongStorage of size 3]

809322.84007072	
 512
  36
  64
[torch.LongStorage of size 3]

809252.65060425	
 512
  36
  64
[torch.LongStorage of size 3]

809200.39432526	
 512
  36
  64
[torch.LongStorage of size 3]

809145.01107216	
 512
  36
  64
[torch.LongStorage of size 3]

809078.72112274	
 512
  36
  64
[torch.LongStorage of size 3]

809020.2568531	
 512
  36
  64
[torch.LongStorage of size 3]

808959.59005356	
 512
  36
  64
[torch.LongStorage of size 3]

808913.8520813	
 512
  36
  64
[torch.LongStorage of size 3]

808855.00946045	
 512
  36
  64
[torch.LongStorage of size 3]

808799.18151855	
 512
  36
  64
[torch.LongStorage of size 3]

808742.38277435	
 512
  36
  64
[torch.LongStorage of size 3]

808677.1184063	
 512
  36
  64
[torch.LongStorage of size 3]

808627.37727165	
 512
  36
  64
[torch.LongStorage of size 3]

808565.85634232	
 512
  36
  64
[torch.LongStorage of size 3]

808530.5654335	
 512
  36
  64
[torch.LongStorage of size 3]

808482.18352318	
 512
  36
  64
[torch.LongStorage of size 3]

808438.61710548	
 512
  36
  64
[torch.LongStorage of size 3]

808374.32750702	
 512
  36
  64
[torch.LongStorage of size 3]

808338.20540428	
 512
  36
  64
[torch.LongStorage of size 3]

808269.03357506	
 512
  36
  64
[torch.LongStorage of size 3]

808229.02010918	
 512
  36
  64
[torch.LongStorage of size 3]

808175.6867218	
 512
  36
  64
[torch.LongStorage of size 3]

808130.68516731	
 512
  36
  64
[torch.LongStorage of size 3]

808082.69622803	
 512
  36
  64
[torch.LongStorage of size 3]

808029.88694191	
 512
  36
  64
[torch.LongStorage of size 3]

807977.84942627	
 512
  36
  64
[torch.LongStorage of size 3]

807944.13119316	
 512
  36
  64
[torch.LongStorage of size 3]

807889.7564888	
 512
  36
  64
[torch.LongStorage of size 3]

807850.50614357	
 512
  36
  64
[torch.LongStorage of size 3]

807785.4792881	
 512
  36
  64
[torch.LongStorage of size 3]

807743.07497978	
 512
  36
  64
[torch.LongStorage of size 3]

807685.38835526	
 512
  36
  64
[torch.LongStorage of size 3]

807638.97206306	
 512
  36
  64
[torch.LongStorage of size 3]

807586.81680679	
 512
  36
  64
[torch.LongStorage of size 3]

807535.82381248	
 512
  36
  64
[torch.LongStorage of size 3]

807502.03792572	
 512
  36
  64
[torch.LongStorage of size 3]

807446.37342453	
 512
  36
  64
[torch.LongStorage of size 3]

807412.48720169	
 512
  36
  64
[torch.LongStorage of size 3]

807351.04017258	
 512
  36
  64
[torch.LongStorage of size 3]

807313.10721397	
 512
  36
  64
[torch.LongStorage of size 3]

807271.56570435	
 512
  36
  64
[torch.LongStorage of size 3]

807218.94031525	
 512
  36
  64
[torch.LongStorage of size 3]

807176.93710327	
 512
  36
  64
[torch.LongStorage of size 3]

807128.48590851	
 512
  36
  64
[torch.LongStorage of size 3]

807078.16308022	
 512
  36
  64
[torch.LongStorage of size 3]

807031.70544624	
 512
  36
  64
[torch.LongStorage of size 3]

806983.20842743	
 512
  36
  64
[torch.LongStorage of size 3]

806938.48027229	
 512
  36
  64
[torch.LongStorage of size 3]

806893.78832817	
 512
  36
  64
[torch.LongStorage of size 3]

806849.56752777	
 512
  36
  64
[torch.LongStorage of size 3]

806809.3560791	
 512
  36
  64
[torch.LongStorage of size 3]

806765.33846855	
 512
  36
  64
[torch.LongStorage of size 3]

806728.30294609	
 512
  36
  64
[torch.LongStorage of size 3]

806678.05238724	
 512
  36
  64
[torch.LongStorage of size 3]

806637.12143898	
 512
  36
  64
[torch.LongStorage of size 3]

806593.36724281	
 512
  36
  64
[torch.LongStorage of size 3]

806575.49711227	
 512
  36
  64
[torch.LongStorage of size 3]

806528.64376068	
 512
  36
  64
[torch.LongStorage of size 3]

806496.68430328	
 512
  36
  64
[torch.LongStorage of size 3]

806452.79909134	
 512
  36
  64
[torch.LongStorage of size 3]

806416.51006699	
 512
  36
  64
[torch.LongStorage of size 3]

806368.01394463	
 512
  36
  64
[torch.LongStorage of size 3]

806339.81477737	
 512
  36
  64
[torch.LongStorage of size 3]

806288.4645462	
 512
  36
  64
[torch.LongStorage of size 3]

806252.51758575	
 512
  36
  64
[torch.LongStorage of size 3]

806213.07003021	
 512
  36
  64
[torch.LongStorage of size 3]

806178.31039429	
 512
  36
  64
[torch.LongStorage of size 3]

806143.45472336	
 512
  36
  64
[torch.LongStorage of size 3]

806096.77717209	
 512
  36
  64
[torch.LongStorage of size 3]

806063.09926987	
 512
  36
  64
[torch.LongStorage of size 3]

806013.22309494	
 512
  36
  64
[torch.LongStorage of size 3]

805985.72841644	
 512
  36
  64
[torch.LongStorage of size 3]

805941.39624596	
 512
  36
  64
[torch.LongStorage of size 3]

805906.43984795	
 512
  36
  64
[torch.LongStorage of size 3]

805870.27767181	
 512
  36
  64
[torch.LongStorage of size 3]

805833.04083824	
 512
  36
  64
[torch.LongStorage of size 3]

805792.61976242	
 512
  36
  64
[torch.LongStorage of size 3]

805750.61002731	
 512
  36
  64
[torch.LongStorage of size 3]

805711.70657158	
 512
  36
  64
[torch.LongStorage of size 3]

805678.73380661	
 512
  36
  64
[torch.LongStorage of size 3]

805636.18050575	
 512
  36
  64
[torch.LongStorage of size 3]

805616.07953072	
 512
  36
  64
[torch.LongStorage of size 3]

805568.83049011	
 512
  36
  64
[torch.LongStorage of size 3]

805545.30157089	
 512
  36
  64
[torch.LongStorage of size 3]

805505.10606766	
 512
  36
  64
[torch.LongStorage of size 3]

805467.85898209	
 512
  36
  64
[torch.LongStorage of size 3]

805426.3876915	
 512
  36
  64
[torch.LongStorage of size 3]

805400.34317017	
 512
  36
  64
[torch.LongStorage of size 3]

805358.37458611	
 512
  36
  64
[torch.LongStorage of size 3]

805326.40577316	
 512
  36
  64
[torch.LongStorage of size 3]

805291.00732803	
 512
  36
  64
[torch.LongStorage of size 3]

805256.83122635	
 512
  36
  64
[torch.LongStorage of size 3]

805223.5499382	
 512
  36
  64
[torch.LongStorage of size 3]

805190.67503929	
 512
  36
  64
[torch.LongStorage of size 3]

805161.14408493	
 512
  36
  64
[torch.LongStorage of size 3]

805126.64803505	
 512
  36
  64
[torch.LongStorage of size 3]

805089.96627808	
 512
  36
  64
[torch.LongStorage of size 3]

805059.12488937	
 512
  36
  64
[torch.LongStorage of size 3]

805018.22824478	
 512
  36
  64
[torch.LongStorage of size 3]

804999.50945854	
 512
  36
  64
[torch.LongStorage of size 3]

804951.54132843	
 512
  36
  64
[torch.LongStorage of size 3]

804926.4144516	
 512
  36
  64
[torch.LongStorage of size 3]

804891.93869591	
 512
  36
  64
[torch.LongStorage of size 3]

804860.36258698	
 512
  36
  64
[torch.LongStorage of size 3]

804823.82933617	
 512
  36
  64
[torch.LongStorage of size 3]

804792.30164528	
 512
  36
  64
[torch.LongStorage of size 3]

804759.54665184	
 512
  36
  64
[torch.LongStorage of size 3]

804730.1021862	
 512
  36
  64
[torch.LongStorage of size 3]

804693.34228516	
 512
  36
  64
[torch.LongStorage of size 3]

804664.65396881	
 512
  36
  64
[torch.LongStorage of size 3]

804625.16663551	
 512
  36
  64
[torch.LongStorage of size 3]

804598.95986557	
 512
  36
  64
[torch.LongStorage of size 3]

804551.28791809	
 512
  36
  64
[torch.LongStorage of size 3]

804529.38002586	
 512
  36
  64
[torch.LongStorage of size 3]

804489.07190323	
 512
  36
  64
[torch.LongStorage of size 3]

804460.51300049	
 512
  36
  64
[torch.LongStorage of size 3]

804434.32126999	
 512
  36
  64
[torch.LongStorage of size 3]

804397.49893188	
 512
  36
  64
[torch.LongStorage of size 3]

804379.84975815	
 512
  36
  64
[torch.LongStorage of size 3]

804336.64787292	
 512
  36
  64
[torch.LongStorage of size 3]

804310.6071949	
 512
  36
  64
[torch.LongStorage of size 3]

804286.97605133	
 512
  36
  64
[torch.LongStorage of size 3]

804258.02591324	
 512
  36
  64
[torch.LongStorage of size 3]

804233.3094883	
 512
  36
  64
[torch.LongStorage of size 3]

804203.68061066	
 512
  36
  64
[torch.LongStorage of size 3]

804171.59312248	
 512
  36
  64
[torch.LongStorage of size 3]

804137.6403904	
 512
  36
  64
[torch.LongStorage of size 3]

804102.58746147	
 512
  36
  64
[torch.LongStorage of size 3]

804080.34223557	
 512
  36
  64
[torch.LongStorage of size 3]

804051.93242073	
 512
  36
  64
[torch.LongStorage of size 3]

804028.12109947	
 512
  36
  64
[torch.LongStorage of size 3]

804001.83793068	
 512
  36
  64
[torch.LongStorage of size 3]

803968.54215622	
 512
  36
  64
[torch.LongStorage of size 3]

803947.43937492	
 512
  36
  64
[torch.LongStorage of size 3]

803907.50564575	
 512
  36
  64
[torch.LongStorage of size 3]

803884.45357323	
 512
  36
  64
[torch.LongStorage of size 3]

803855.15853882	
 512
  36
  64
[torch.LongStorage of size 3]

803833.15156937	
 512
  36
  64
[torch.LongStorage of size 3]

803804.69900131	
 512
  36
  64
[torch.LongStorage of size 3]

803779.29943085	
 512
  36
  64
[torch.LongStorage of size 3]

803751.67865753	
 512
  36
  64
[torch.LongStorage of size 3]

803723.82575035	
 512
  36
  64
[torch.LongStorage of size 3]

803699.375	
 512
  36
  64
[torch.LongStorage of size 3]

803671.47233963	
 512
  36
  64
[torch.LongStorage of size 3]

803645.7715416	
 512
  36
  64
[torch.LongStorage of size 3]

803618.44776154	
 512
  36
  64
[torch.LongStorage of size 3]

803590.35776138	
 512
  36
  64
[torch.LongStorage of size 3]

803561.02737427	
 512
  36
  64
[torch.LongStorage of size 3]

803537.68078804	
 512
  36
  64
[torch.LongStorage of size 3]

803502.19866753	
 512
  36
  64
[torch.LongStorage of size 3]

803483.27882767	
 512
  36
  64
[torch.LongStorage of size 3]

803448.13605309	
 512
  36
  64
[torch.LongStorage of size 3]

803436.76811218	
 512
  36
  64
[torch.LongStorage of size 3]

803403.88120651	
 512
  36
  64
[torch.LongStorage of size 3]

803382.88032532	
 512
  36
  64
[torch.LongStorage of size 3]

803357.98894882	
 512
  36
  64
[torch.LongStorage of size 3]

803331.14112854	
 512
  36
  64
[torch.LongStorage of size 3]

803305.30163765	
 512
  36
  64
[torch.LongStorage of size 3]

803282.46426582	
 512
  36
  64
[torch.LongStorage of size 3]

803258.88073921	
 512
  36
  64
[torch.LongStorage of size 3]

803232.50566483	
 512
  36
  64
[torch.LongStorage of size 3]

803207.44542122	
 512
  36
  64
[torch.LongStorage of size 3]

803180.10547638	
 512
  36
  64
[torch.LongStorage of size 3]

803157.25039482	
 512
  36
  64
[torch.LongStorage of size 3]

803130.2658844	
 512
  36
  64
[torch.LongStorage of size 3]

803111.86075211	
 512
  36
  64
[torch.LongStorage of size 3]

803088.17635536	
 512
  36
  64
[torch.LongStorage of size 3]

803063.19993019	
 512
  36
  64
[torch.LongStorage of size 3]

803039.85165596	
 512
  36
  64
[torch.LongStorage of size 3]

803011.36469841	
 512
  36
  64
[torch.LongStorage of size 3]

802996.22526169	
 512
  36
  64
[torch.LongStorage of size 3]

802960.9120369	
 512
  36
  64
[torch.LongStorage of size 3]

802940.74638367	
 512
  36
  64
[torch.LongStorage of size 3]

802911.50543213	
 512
  36
  64
[torch.LongStorage of size 3]

802890.13382912	
 512
  36
  64
[torch.LongStorage of size 3]

802864.73693848	
 512
  36
  64
[torch.LongStorage of size 3]

802849.10748482	
 512
  36
  64
[torch.LongStorage of size 3]

802817.79263496	
 512
  36
  64
[torch.LongStorage of size 3]

802800.77201843	
 512
  36
  64
[torch.LongStorage of size 3]

802774.28010941	
 512
  36
  64
[torch.LongStorage of size 3]

802752.6366806	
 512
  36
  64
[torch.LongStorage of size 3]

802730.17957687	
 512
  36
  64
[torch.LongStorage of size 3]

802706.83757782	
 512
  36
  64
[torch.LongStorage of size 3]

802684.22558784	
 512
  36
  64
[torch.LongStorage of size 3]

802659.5363903	
 512
  36
  64
[torch.LongStorage of size 3]

802638.74428749	
 512
  36
  64
[torch.LongStorage of size 3]

802613.35792542	
 512
  36
  64
[torch.LongStorage of size 3]

802595.20015717	
 512
  36
  64
[torch.LongStorage of size 3]

802567.79689789	
 512
  36
  64
[torch.LongStorage of size 3]

802548.86079788	
 512
  36
  64
[torch.LongStorage of size 3]

802521.13910675	
 512
  36
  64
[torch.LongStorage of size 3]

802503.90419006	
Iteration 666 / 1000	
  Content 1 loss: 628962.656250	
  Style 1 loss: 486.272240	
  Style 2 loss: 5879.920197	
  Style 3 loss: 5970.560074	
  Style 4 loss: 159006.787109	
  Style 5 loss: 2197.708321	
  Total loss: 802503.904190	
s/KNSGUHk.jpg_out_prepost_666.png	
 512
  36
  64
[torch.LongStorage of size 3]

802480.37657738	
 512
  36
  64
[torch.LongStorage of size 3]

802461.11545563	
 512
  36
  64
[torch.LongStorage of size 3]

802438.40008736	
 512
  36
  64
[torch.LongStorage of size 3]

802415.24804115	
 512
  36
  64
[torch.LongStorage of size 3]

802392.60457993	
 512
  36
  64
[torch.LongStorage of size 3]

802370.63138962	
 512
  36
  64
[torch.LongStorage of size 3]

802347.42977142	
 512
  36
  64
[torch.LongStorage of size 3]

802325.05400658	
 512
  36
  64
[torch.LongStorage of size 3]

802302.50902176	
 512
  36
  64
[torch.LongStorage of size 3]

802282.53307343	
 512
  36
  64
[torch.LongStorage of size 3]

802257.96152115	
 512
  36
  64
[torch.LongStorage of size 3]

802242.08867073	
 512
  36
  64
[torch.LongStorage of size 3]

802214.85067368	
 512
  36
  64
[torch.LongStorage of size 3]

802197.40477562	
 512
  36
  64
[torch.LongStorage of size 3]

802168.55038643	
 512
  36
  64
[torch.LongStorage of size 3]

802150.66626549	
 512
  36
  64
[torch.LongStorage of size 3]

802128.88917923	
 512
  36
  64
[torch.LongStorage of size 3]

802109.72908974	
 512
  36
  64
[torch.LongStorage of size 3]

802089.73185539	
 512
  36
  64
[torch.LongStorage of size 3]

802069.08605576	
 512
  36
  64
[torch.LongStorage of size 3]

802044.85619545	
 512
  36
  64
[torch.LongStorage of size 3]

802025.76403618	
 512
  36
  64
[torch.LongStorage of size 3]

802002.15650558	
 512
  36
  64
[torch.LongStorage of size 3]

801988.20371628	
 512
  36
  64
[torch.LongStorage of size 3]

801963.28557014	
 512
  36
  64
[torch.LongStorage of size 3]

801951.16581917	
 512
  36
  64
[torch.LongStorage of size 3]

801926.1004734	
 512
  36
  64
[torch.LongStorage of size 3]

801908.62855911	
 512
  36
  64
[torch.LongStorage of size 3]

801883.31640244	
 512
  36
  64
[torch.LongStorage of size 3]

801868.53286743	
 512
  36
  64
[torch.LongStorage of size 3]

801847.01592445	
 512
  36
  64
[torch.LongStorage of size 3]

801830.92912674	
 512
  36
  64
[torch.LongStorage of size 3]

801811.87437057	
 512
  36
  64
[torch.LongStorage of size 3]

801794.86349106	
 512
  36
  64
[torch.LongStorage of size 3]

801771.86911583	
 512
  36
  64
[torch.LongStorage of size 3]

801754.62125778	
 512
  36
  64
[torch.LongStorage of size 3]

801735.41074753	
 512
  36
  64
[torch.LongStorage of size 3]

801715.64301491	
 512
  36
  64
[torch.LongStorage of size 3]

801699.14764404	
 512
  36
  64
[torch.LongStorage of size 3]

801679.5164299	
 512
  36
  64
[torch.LongStorage of size 3]

801662.36274719	
 512
  36
  64
[torch.LongStorage of size 3]

801641.83753014	
 512
  36
  64
[torch.LongStorage of size 3]

801621.45853996	
 512
  36
  64
[torch.LongStorage of size 3]

801605.24175644	
 512
  36
  64
[torch.LongStorage of size 3]

801581.95680618	
 512
  36
  64
[torch.LongStorage of size 3]

801568.88221741	
 512
  36
  64
[torch.LongStorage of size 3]

801547.7017498	
 512
  36
  64
[torch.LongStorage of size 3]

801531.57613754	
 512
  36
  64
[torch.LongStorage of size 3]

801509.8238945	
 512
  36
  64
[torch.LongStorage of size 3]

801498.05407524	
 512
  36
  64
[torch.LongStorage of size 3]

801472.48659134	
 512
  36
  64
[torch.LongStorage of size 3]

801462.81352997	
 512
  36
  64
[torch.LongStorage of size 3]

801444.38076973	
 512
  36
  64
[torch.LongStorage of size 3]

801426.88649178	
 512
  36
  64
[torch.LongStorage of size 3]

801409.48917389	
 512
  36
  64
[torch.LongStorage of size 3]

801393.20681572	
 512
  36
  64
[torch.LongStorage of size 3]

801377.83817291	
 512
  36
  64
[torch.LongStorage of size 3]

801357.39562988	
 512
  36
  64
[torch.LongStorage of size 3]

801342.8470993	
 512
  36
  64
[torch.LongStorage of size 3]

801321.66837692	
 512
  36
  64
[torch.LongStorage of size 3]

801310.18123627	
 512
  36
  64
[torch.LongStorage of size 3]

801289.88070488	
 512
  36
  64
[torch.LongStorage of size 3]

801277.87467957	
 512
  36
  64
[torch.LongStorage of size 3]

801256.34908676	
 512
  36
  64
[torch.LongStorage of size 3]

801239.93770599	
 512
  36
  64
[torch.LongStorage of size 3]

801223.63790512	
 512
  36
  64
[torch.LongStorage of size 3]

801207.43082047	
 512
  36
  64
[torch.LongStorage of size 3]

801189.72376823	
 512
  36
  64
[torch.LongStorage of size 3]

801174.59275246	
 512
  36
  64
[torch.LongStorage of size 3]

801159.4360733	
 512
  36
  64
[torch.LongStorage of size 3]

801143.75167847	
 512
  36
  64
[torch.LongStorage of size 3]

801123.97830009	
 512
  36
  64
[torch.LongStorage of size 3]

801109.53217506	
 512
  36
  64
[torch.LongStorage of size 3]

801090.3001976	
 512
  36
  64
[torch.LongStorage of size 3]

801077.08379745	
 512
  36
  64
[torch.LongStorage of size 3]

801058.6686039	
 512
  36
  64
[torch.LongStorage of size 3]

801045.17331123	
 512
  36
  64
[torch.LongStorage of size 3]

801027.46632576	
 512
  36
  64
[torch.LongStorage of size 3]

801013.9087677	
 512
  36
  64
[torch.LongStorage of size 3]

800996.69677734	
 512
  36
  64
[torch.LongStorage of size 3]

800983.41396332	
 512
  36
  64
[torch.LongStorage of size 3]

800962.44282722	
 512
  36
  64
[torch.LongStorage of size 3]

800953.64008904	
 512
  36
  64
[torch.LongStorage of size 3]

800930.97930908	
 512
  36
  64
[torch.LongStorage of size 3]

800920.77030182	
 512
  36
  64
[torch.LongStorage of size 3]

800903.7928772	
 512
  36
  64
[torch.LongStorage of size 3]

800891.00623131	
 512
  36
  64
[torch.LongStorage of size 3]

800874.31560516	
 512
  36
  64
[torch.LongStorage of size 3]

800860.19748688	
 512
  36
  64
[torch.LongStorage of size 3]

800845.51395416	
 512
  36
  64
[torch.LongStorage of size 3]

800830.63944817	
 512
  36
  64
[torch.LongStorage of size 3]

800815.05249977	
 512
  36
  64
[torch.LongStorage of size 3]

800801.711092	
 512
  36
  64
[torch.LongStorage of size 3]

800786.78261757	
 512
  36
  64
[torch.LongStorage of size 3]

800771.21826172	
 512
  36
  64
[torch.LongStorage of size 3]

800755.77368736	
 512
  36
  64
[torch.LongStorage of size 3]

800742.3620224	
 512
  36
  64
[torch.LongStorage of size 3]

800726.8918705	
 512
  36
  64
[torch.LongStorage of size 3]

800712.71355629	
 512
  36
  64
[torch.LongStorage of size 3]

800698.55053902	
 512
  36
  64
[torch.LongStorage of size 3]

800682.04791069	
 512
  36
  64
[torch.LongStorage of size 3]

800669.36512947	
 512
  36
  64
[torch.LongStorage of size 3]

800651.18288994	
 512
  36
  64
[torch.LongStorage of size 3]

800641.09026909	
 512
  36
  64
[torch.LongStorage of size 3]

800623.49813461	
 512
  36
  64
[torch.LongStorage of size 3]

800613.58198166	
 512
  36
  64
[torch.LongStorage of size 3]

800595.00154495	
 512
  36
  64
[torch.LongStorage of size 3]

800585.40523529	
 512
  36
  64
[torch.LongStorage of size 3]

800568.89431953	
 512
  36
  64
[torch.LongStorage of size 3]

800556.22925758	
 512
  36
  64
[torch.LongStorage of size 3]

800539.79420662	
 512
  36
  64
[torch.LongStorage of size 3]

800528.93505096	
 512
  36
  64
[torch.LongStorage of size 3]

800514.2884922	
 512
  36
  64
[torch.LongStorage of size 3]

800503.69591713	
 512
  36
  64
[torch.LongStorage of size 3]

800486.10131264	
 512
  36
  64
[torch.LongStorage of size 3]

800475.47827721	
 512
  36
  64
[torch.LongStorage of size 3]

800459.83436584	
 512
  36
  64
[torch.LongStorage of size 3]

800450.08912086	
 512
  36
  64
[torch.LongStorage of size 3]

800435.42158127	
 512
  36
  64
[torch.LongStorage of size 3]

800424.03549194	
 512
  36
  64
[torch.LongStorage of size 3]

800410.17582893	
 512
  36
  64
[torch.LongStorage of size 3]

800395.82151413	
 512
  36
  64
[torch.LongStorage of size 3]

800380.59586525	
 512
  36
  64
[torch.LongStorage of size 3]

800368.00826073	
 512
  36
  64
[torch.LongStorage of size 3]

800356.06574059	
 512
  36
  64
[torch.LongStorage of size 3]

800341.58509254	
 512
  36
  64
[torch.LongStorage of size 3]

800331.30281448	
 512
  36
  64
[torch.LongStorage of size 3]

800315.81114769	
 512
  36
  64
[torch.LongStorage of size 3]

800306.47447586	
 512
  36
  64
[torch.LongStorage of size 3]

800289.73214149	
 512
  36
  64
[torch.LongStorage of size 3]

800278.55820656	
 512
  36
  64
[torch.LongStorage of size 3]

800264.35045242	
 512
  36
  64
[torch.LongStorage of size 3]

800251.60607338	
 512
  36
  64
[torch.LongStorage of size 3]

800240.1675415	
 512
  36
  64
[torch.LongStorage of size 3]

800226.96544647	
 512
  36
  64
[torch.LongStorage of size 3]

800216.89072609	
 512
  36
  64
[torch.LongStorage of size 3]

800199.79110718	
 512
  36
  64
[torch.LongStorage of size 3]

800191.89917564	
 512
  36
  64
[torch.LongStorage of size 3]

800174.35538292	
 512
  36
  64
[torch.LongStorage of size 3]

800165.53783417	
 512
  36
  64
[torch.LongStorage of size 3]

800149.87858772	
 512
  36
  64
[torch.LongStorage of size 3]

800138.06001663	
 512
  36
  64
[torch.LongStorage of size 3]

800126.24030113	
 512
  36
  64
[torch.LongStorage of size 3]

800113.35048676	
 512
  36
  64
[torch.LongStorage of size 3]

800098.52730751	
 512
  36
  64
[torch.LongStorage of size 3]

800085.52088737	
 512
  36
  64
[torch.LongStorage of size 3]

800073.15833092	
 512
  36
  64
[torch.LongStorage of size 3]

800062.29878426	
 512
  36
  64
[torch.LongStorage of size 3]

800049.44359779	
 512
  36
  64
[torch.LongStorage of size 3]

800039.70122337	
 512
  36
  64
[torch.LongStorage of size 3]

800024.75661278	
 512
  36
  64
[torch.LongStorage of size 3]

800014.47690964	
 512
  36
  64
[torch.LongStorage of size 3]

800000.75153351	
 512
  36
  64
[torch.LongStorage of size 3]

799992.14513779	
 512
  36
  64
[torch.LongStorage of size 3]

799977.52744675	
 512
  36
  64
[torch.LongStorage of size 3]

799966.23459816	
 512
  36
  64
[torch.LongStorage of size 3]

799954.08554077	
 512
  36
  64
[torch.LongStorage of size 3]

799944.59362984	
 512
  36
  64
[torch.LongStorage of size 3]

799931.71361923	
 512
  36
  64
[torch.LongStorage of size 3]

799921.48456573	
 512
  36
  64
[torch.LongStorage of size 3]

799909.07495499	
 512
  36
  64
[torch.LongStorage of size 3]

799899.28145409	
 512
  36
  64
[torch.LongStorage of size 3]

799886.39912605	
 512
  36
  64
[torch.LongStorage of size 3]

799876.40222549	
 512
  36
  64
[torch.LongStorage of size 3]

799866.24872208	
 512
  36
  64
[torch.LongStorage of size 3]

799853.01012993	
 512
  36
  64
[torch.LongStorage of size 3]

799843.8553524	
 512
  36
  64
[torch.LongStorage of size 3]

799830.47870636	
 512
  36
  64
[torch.LongStorage of size 3]

799823.00580025	
 512
  36
  64
[torch.LongStorage of size 3]

799808.71965408	
 512
  36
  64
[torch.LongStorage of size 3]

799800.78462601	
 512
  36
  64
[torch.LongStorage of size 3]

799788.50581169	
 512
  36
  64
[torch.LongStorage of size 3]

799780.07979393	
 512
  36
  64
[torch.LongStorage of size 3]

799769.47694778	
 512
  36
  64
[torch.LongStorage of size 3]

799760.98056793	
 512
  36
  64
[torch.LongStorage of size 3]

799749.54024315	
 512
  36
  64
[torch.LongStorage of size 3]

799741.43525124	
 512
  36
  64
[torch.LongStorage of size 3]

799726.92657471	
 512
  36
  64
[torch.LongStorage of size 3]

799722.5442028	
 512
  36
  64
[torch.LongStorage of size 3]

799707.90006638	
 512
  36
  64
[torch.LongStorage of size 3]

799699.90580559	
 512
  36
  64
[torch.LongStorage of size 3]

799691.60235405	
 512
  36
  64
[torch.LongStorage of size 3]

799681.95451736	
 512
  36
  64
[torch.LongStorage of size 3]

799671.40917778	
 512
  36
  64
[torch.LongStorage of size 3]

799663.06062698	
 512
  36
  64
[torch.LongStorage of size 3]

799651.54231071	
 512
  36
  64
[torch.LongStorage of size 3]

799641.39115334	
 512
  36
  64
[torch.LongStorage of size 3]

799630.017519	
 512
  36
  64
[torch.LongStorage of size 3]

799622.5195694	
 512
  36
  64
[torch.LongStorage of size 3]

799611.71197891	
 512
  36
  64
[torch.LongStorage of size 3]

799604.4709301	
 512
  36
  64
[torch.LongStorage of size 3]

799591.71251297	
 512
  36
  64
[torch.LongStorage of size 3]

799583.38380814	
 512
  36
  64
[torch.LongStorage of size 3]

799572.32505798	
 512
  36
  64
[torch.LongStorage of size 3]

799563.62911224	
 512
  36
  64
[torch.LongStorage of size 3]

799553.15337181	
 512
  36
  64
[torch.LongStorage of size 3]

799545.45572281	
 512
  36
  64
[torch.LongStorage of size 3]

799533.44646454	
 512
  36
  64
[torch.LongStorage of size 3]

799527.498703	
 512
  36
  64
[torch.LongStorage of size 3]

799515.47523499	
 512
  36
  64
[torch.LongStorage of size 3]

799505.33133507	
 512
  36
  64
[torch.LongStorage of size 3]

799494.37238693	
 512
  36
  64
[torch.LongStorage of size 3]

799485.28381348	
 512
  36
  64
[torch.LongStorage of size 3]

799474.9648571	
 512
  36
  64
[torch.LongStorage of size 3]

799467.95082092	
 512
  36
  64
[torch.LongStorage of size 3]

799455.39309502	
 512
  36
  64
[torch.LongStorage of size 3]

799446.04543686	
 512
  36
  64
[torch.LongStorage of size 3]

799434.43166733	
 512
  36
  64
[torch.LongStorage of size 3]

799426.92137718	
 512
  36
  64
[torch.LongStorage of size 3]

799415.7179451	
 512
  36
  64
[torch.LongStorage of size 3]

799408.91798973	
 512
  36
  64
[torch.LongStorage of size 3]

799397.53820419	
 512
  36
  64
[torch.LongStorage of size 3]

799389.82048035	
 512
  36
  64
[torch.LongStorage of size 3]

799379.6120739	
 512
  36
  64
[torch.LongStorage of size 3]

799372.47675896	
 512
  36
  64
[torch.LongStorage of size 3]

799360.85492134	
 512
  36
  64
[torch.LongStorage of size 3]

799354.68535423	
 512
  36
  64
[torch.LongStorage of size 3]

799345.11316299	
 512
  36
  64
[torch.LongStorage of size 3]

799337.4475956	
 512
  36
  64
[torch.LongStorage of size 3]

799326.46617889	
 512
  36
  64
[torch.LongStorage of size 3]

799318.01372528	
 512
  36
  64
[torch.LongStorage of size 3]

799310.0065136	
 512
  36
  64
[torch.LongStorage of size 3]

799301.73511505	
 512
  36
  64
[torch.LongStorage of size 3]

799294.4465065	
 512
  36
  64
[torch.LongStorage of size 3]

799284.19665337	
 512
  36
  64
[torch.LongStorage of size 3]

799276.06976509	
 512
  36
  64
[torch.LongStorage of size 3]

799266.99789047	
 512
  36
  64
[torch.LongStorage of size 3]

799258.65884781	
 512
  36
  64
[torch.LongStorage of size 3]

799249.40672874	
 512
  36
  64
[torch.LongStorage of size 3]

799241.36240005	
 512
  36
  64
[torch.LongStorage of size 3]

799232.14365005	
 512
  36
  64
[torch.LongStorage of size 3]

799227.05104828	
 512
  36
  64
[torch.LongStorage of size 3]

799215.81019402	
 512
  36
  64
[torch.LongStorage of size 3]

799210.87154388	
 512
  36
  64
[torch.LongStorage of size 3]

799200.22373199	
 512
  36
  64
[torch.LongStorage of size 3]

799193.21825981	
 512
  36
  64
[torch.LongStorage of size 3]

799186.06393814	
 512
  36
  64
[torch.LongStorage of size 3]

799177.51132965	
 512
  36
  64
[torch.LongStorage of size 3]

799169.31610107	
 512
  36
  64
[torch.LongStorage of size 3]

799162.03414917	
 512
  36
  64
[torch.LongStorage of size 3]

799153.79638672	
 512
  36
  64
[torch.LongStorage of size 3]

799147.15651512	
 512
  36
  64
[torch.LongStorage of size 3]

799139.09944534	
 512
  36
  64
[torch.LongStorage of size 3]

799131.56925201	
 512
  36
  64
[torch.LongStorage of size 3]

799125.36307335	
 512
  36
  64
[torch.LongStorage of size 3]

799116.3630867	
 512
  36
  64
[torch.LongStorage of size 3]

799110.07750511	
 512
  36
  64
[torch.LongStorage of size 3]

799100.63657761	
 512
  36
  64
[torch.LongStorage of size 3]

799092.53253937	
 512
  36
  64
[torch.LongStorage of size 3]

799084.85444069	
 512
  36
  64
[torch.LongStorage of size 3]

799078.62287521	
 512
  36
  64
[torch.LongStorage of size 3]

799069.742136	
 512
  36
  64
[torch.LongStorage of size 3]

799063.26869965	
 512
  36
  64
[torch.LongStorage of size 3]

799055.99798203	
 512
  36
  64
[torch.LongStorage of size 3]

799047.5551796	
 512
  36
  64
[torch.LongStorage of size 3]

799042.20770836	
 512
  36
  64
[torch.LongStorage of size 3]

799032.94656754	
 512
  36
  64
[torch.LongStorage of size 3]

799027.07428932	
 512
  36
  64
[torch.LongStorage of size 3]

799018.09425354	
 512
  36
  64
[torch.LongStorage of size 3]

799012.18826294	
 512
  36
  64
[torch.LongStorage of size 3]

799002.64014244	
 512
  36
  64
[torch.LongStorage of size 3]

798996.34435654	
 512
  36
  64
[torch.LongStorage of size 3]

798988.06123734	
 512
  36
  64
[torch.LongStorage of size 3]

798982.43196487	
 512
  36
  64
[torch.LongStorage of size 3]

798973.39231491	
 512
  36
  64
[torch.LongStorage of size 3]

798967.82352448	
 512
  36
  64
[torch.LongStorage of size 3]

798959.17620659	
 512
  36
  64
[torch.LongStorage of size 3]

798953.51181984	
 512
  36
  64
[torch.LongStorage of size 3]

798944.94708061	
 512
  36
  64
[torch.LongStorage of size 3]

798938.3005619	
 512
  36
  64
[torch.LongStorage of size 3]

798929.99012947	
 512
  36
  64
[torch.LongStorage of size 3]

798924.29055214	
 512
  36
  64
[torch.LongStorage of size 3]

798915.75023651	
 512
  36
  64
[torch.LongStorage of size 3]

798910.18261909	
 512
  36
  64
[torch.LongStorage of size 3]

798903.40409279	
 512
  36
  64
[torch.LongStorage of size 3]

798895.64259529	
 512
  36
  64
[torch.LongStorage of size 3]

798889.68974113	
 512
  36
  64
[torch.LongStorage of size 3]

798882.95672417	
 512
  36
  64
[torch.LongStorage of size 3]

798877.03831673	
 512
  36
  64
[torch.LongStorage of size 3]

798867.93372154	
 512
  36
  64
[torch.LongStorage of size 3]

798862.26433754	
 512
  36
  64
[torch.LongStorage of size 3]

798852.86804199	
 512
  36
  64
[torch.LongStorage of size 3]

798847.8429985	
 512
  36
  64
[torch.LongStorage of size 3]

798838.82276535	
 512
  36
  64
[torch.LongStorage of size 3]

798831.7332077	
 512
  36
  64
[torch.LongStorage of size 3]

798824.85993385	
 512
  36
  64
[torch.LongStorage of size 3]

798817.99344063	
 512
  36
  64
[torch.LongStorage of size 3]

798810.24122238	
 512
  36
  64
[torch.LongStorage of size 3]

798803.78126144	
 512
  36
  64
[torch.LongStorage of size 3]

798795.6738472	
 512
  36
  64
[torch.LongStorage of size 3]

798789.0780735	
 512
  36
  64
[torch.LongStorage of size 3]

798782.44309425	
 512
  36
  64
[torch.LongStorage of size 3]

798775.78331947	
 512
  36
  64
[torch.LongStorage of size 3]

798768.27259064	
 512
  36
  64
[torch.LongStorage of size 3]

798761.48525238	
 512
  36
  64
[torch.LongStorage of size 3]

798753.7115097	
 512
  36
  64
[torch.LongStorage of size 3]

798746.74608231	
 512
  36
  64
[torch.LongStorage of size 3]

798739.48361397	
 512
  36
  64
[torch.LongStorage of size 3]

798732.7020359	
 512
  36
  64
[torch.LongStorage of size 3]

798725.92591286	
 512
  36
  64
[torch.LongStorage of size 3]

798718.41989517	
 512
  36
  64
[torch.LongStorage of size 3]

798711.99851036	
 512
  36
  64
[torch.LongStorage of size 3]

798704.73470688	
 512
  36
  64
[torch.LongStorage of size 3]

798697.98027039	
 512
  36
  64
[torch.LongStorage of size 3]

798690.51784515	
 512
  36
  64
[torch.LongStorage of size 3]

798684.12045479	
 512
  36
  64
[torch.LongStorage of size 3]

798676.14356995	
 512
  36
  64
[torch.LongStorage of size 3]

798671.43621445	
 512
  36
  64
[torch.LongStorage of size 3]

798662.14987755	
 512
  36
  64
[torch.LongStorage of size 3]

798656.79402351	
 512
  36
  64
[torch.LongStorage of size 3]

798648.12403679	
 512
  36
  64
[torch.LongStorage of size 3]

798642.38181114	
 512
  36
  64
[torch.LongStorage of size 3]

798633.79360199	
 512
  36
  64
[torch.LongStorage of size 3]

798627.12921143	
 512
  36
  64
[torch.LongStorage of size 3]

798618.05879593	
 512
  36
  64
[torch.LongStorage of size 3]

798612.04248428	
 512
  36
  64
[torch.LongStorage of size 3]

798602.57724762	
 512
  36
  64
[torch.LongStorage of size 3]

798597.62018204	
 512
  36
  64
[torch.LongStorage of size 3]

798589.38738823	
 512
  36
  64
[torch.LongStorage of size 3]

798583.01680565	
 512
  36
  64
[torch.LongStorage of size 3]

798575.18960953	
 512
  36
  64
[torch.LongStorage of size 3]

798569.15594101	
 512
  36
  64
[torch.LongStorage of size 3]

798561.16447449	
 512
  36
  64
[torch.LongStorage of size 3]

798555.0361824	
 512
  36
  64
[torch.LongStorage of size 3]

798548.85044098	
 512
  36
  64
[torch.LongStorage of size 3]

798541.58040047	
 512
  36
  64
[torch.LongStorage of size 3]

798535.31970024	
 512
  36
  64
[torch.LongStorage of size 3]

798527.92201042	
 512
  36
  64
[torch.LongStorage of size 3]

798523.97629738	
 512
  36
  64
[torch.LongStorage of size 3]

798515.04942894	
 512
  36
  64
[torch.LongStorage of size 3]

798510.67154884	
 512
  36
  64
[torch.LongStorage of size 3]

798501.720438	
 512
  36
  64
[torch.LongStorage of size 3]

798497.1594429	
Iteration 999 / 1000	
  Content 1 loss: 626638.320312	
  Style 1 loss: 420.606518	
  Style 2 loss: 5444.383621	
  Style 3 loss: 5788.859940	
  Style 4 loss: 158006.457520	
  Style 5 loss: 2198.531532	
  Total loss: 798497.159443	
s/KNSGUHk.jpg_out_prepost_999.png	
 512
  36
  64
[torch.LongStorage of size 3]

798488.87425423	
s/KNSGUHk.jpg_out_prepost_1000.png	
<optim.lbfgs> 	reached max number of iterations	
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0804 20:09:02.314291 14648 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0804 20:09:02.314370 14648 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0804 20:09:02.314384 14648 _caffe.cpp:142] Net('./zhang/colorization/models/colorization_deploy_v2.prototxt', 1, weights='./zhang/colorization/models/colorization_release_v2.caffemodel')
I0804 20:09:02.316375 14648 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_deploy_v2.prototxt
I0804 20:09:02.316403 14648 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 20:09:02.316718 14648 net.cpp:51] Initializing net from parameters: 
name: "LtoAB"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data_l"
  type: "Input"
  top: "data_l"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "bw_conv1_1"
  type: "Convolution"
  bottom: "data_l"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_2norm"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_2norm"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_2norm"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_2norm"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_3norm"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_3norm"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_3norm"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_3norm"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_3norm"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_3norm"
  top: "conv6_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv6_3"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "conv6_3"
  top: "conv6_3"
}
layer {
  name: "conv6_3norm"
  type: "BatchNorm"
  bottom: "conv6_3"
  top: "conv6_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_3norm"
  top: "conv7_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv7_3"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "conv7_3"
  top: "conv7_3"
}
layer {
  name: "conv7_3norm"
  type: "BatchNorm"
  bottom: "conv7_3"
  top: "conv7_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv8_1"
  type: "Deconvolution"
  bottom: "conv7_3norm"
  top: "conv8_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    stride: 2
    dilation: 1
  }
}
layer {
  name: "relu8_1"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_2"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv8_3"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_3"
  type: "ReLU"
  bottom: "conv8_3"
  top: "conv8_3"
}
layer {
  name: "conv8_313"
  type: "Convolution"
  bottom: "conv8_3"
  top: "conv8_313"
  convolution_param {
    num_output: 313
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv8_313_rh"
  type: "Scale"
  bottom: "conv8_313"
  top: "conv8_313_rh"
  scale_param {
    filler {
      type: "constant"
      value: 2.606
    }
    bias_term: false
  }
}
layer {
  name: "class8_313_rh"
  type: "Softmax"
  bottom: "conv8_313_rh"
  top: "class8_313_rh"
}
layer {
  name: "class8_ab"
  type: "Convolution"
  bottom: "class8_313_rh"
  top: "class8_ab"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "Silence"
  type: "Silence"
  bottom: "class8_ab"
}
I0804 20:09:02.316925 14648 layer_factory.hpp:77] Creating layer data_l
I0804 20:09:02.316949 14648 net.cpp:84] Creating Layer data_l
I0804 20:09:02.316965 14648 net.cpp:380] data_l -> data_l
I0804 20:09:02.329211 14648 net.cpp:122] Setting up data_l
I0804 20:09:02.329263 14648 net.cpp:129] Top shape: 1 1 224 224 (50176)
I0804 20:09:02.329277 14648 net.cpp:137] Memory required for data: 200704
I0804 20:09:02.329293 14648 layer_factory.hpp:77] Creating layer bw_conv1_1
I0804 20:09:02.329320 14648 net.cpp:84] Creating Layer bw_conv1_1
I0804 20:09:02.329335 14648 net.cpp:406] bw_conv1_1 <- data_l
I0804 20:09:02.329352 14648 net.cpp:380] bw_conv1_1 -> conv1_1
I0804 20:09:02.331605 14648 net.cpp:122] Setting up bw_conv1_1
I0804 20:09:02.331636 14648 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 20:09:02.331650 14648 net.cpp:137] Memory required for data: 13045760
I0804 20:09:02.331676 14648 layer_factory.hpp:77] Creating layer relu1_1
I0804 20:09:02.331696 14648 net.cpp:84] Creating Layer relu1_1
I0804 20:09:02.331709 14648 net.cpp:406] relu1_1 <- conv1_1
I0804 20:09:02.331727 14648 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0804 20:09:02.331744 14648 net.cpp:122] Setting up relu1_1
I0804 20:09:02.331758 14648 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 20:09:02.331771 14648 net.cpp:137] Memory required for data: 25890816
I0804 20:09:02.331784 14648 layer_factory.hpp:77] Creating layer conv1_2
I0804 20:09:02.331800 14648 net.cpp:84] Creating Layer conv1_2
I0804 20:09:02.331814 14648 net.cpp:406] conv1_2 <- conv1_1
I0804 20:09:02.331830 14648 net.cpp:380] conv1_2 -> conv1_2
I0804 20:09:02.333112 14648 net.cpp:122] Setting up conv1_2
I0804 20:09:02.333163 14648 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 20:09:02.333176 14648 net.cpp:137] Memory required for data: 29102080
I0804 20:09:02.333199 14648 layer_factory.hpp:77] Creating layer relu1_2
I0804 20:09:02.333217 14648 net.cpp:84] Creating Layer relu1_2
I0804 20:09:02.333231 14648 net.cpp:406] relu1_2 <- conv1_2
I0804 20:09:02.333248 14648 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0804 20:09:02.333266 14648 net.cpp:122] Setting up relu1_2
I0804 20:09:02.333279 14648 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 20:09:02.333292 14648 net.cpp:137] Memory required for data: 32313344
I0804 20:09:02.333304 14648 layer_factory.hpp:77] Creating layer conv1_2norm
I0804 20:09:02.333322 14648 net.cpp:84] Creating Layer conv1_2norm
I0804 20:09:02.333334 14648 net.cpp:406] conv1_2norm <- conv1_2
I0804 20:09:02.333353 14648 net.cpp:380] conv1_2norm -> conv1_2norm
I0804 20:09:02.333590 14648 net.cpp:122] Setting up conv1_2norm
I0804 20:09:02.333608 14648 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 20:09:02.333621 14648 net.cpp:137] Memory required for data: 35524608
I0804 20:09:02.333642 14648 layer_factory.hpp:77] Creating layer conv2_1
I0804 20:09:02.333662 14648 net.cpp:84] Creating Layer conv2_1
I0804 20:09:02.333675 14648 net.cpp:406] conv2_1 <- conv1_2norm
I0804 20:09:02.333690 14648 net.cpp:380] conv2_1 -> conv2_1
I0804 20:09:02.334985 14648 net.cpp:122] Setting up conv2_1
I0804 20:09:02.335014 14648 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 20:09:02.335027 14648 net.cpp:137] Memory required for data: 41947136
I0804 20:09:02.335047 14648 layer_factory.hpp:77] Creating layer relu2_1
I0804 20:09:02.335064 14648 net.cpp:84] Creating Layer relu2_1
I0804 20:09:02.335078 14648 net.cpp:406] relu2_1 <- conv2_1
I0804 20:09:02.335093 14648 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0804 20:09:02.335109 14648 net.cpp:122] Setting up relu2_1
I0804 20:09:02.335124 14648 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 20:09:02.335136 14648 net.cpp:137] Memory required for data: 48369664
I0804 20:09:02.335149 14648 layer_factory.hpp:77] Creating layer conv2_2
I0804 20:09:02.335170 14648 net.cpp:84] Creating Layer conv2_2
I0804 20:09:02.335183 14648 net.cpp:406] conv2_2 <- conv2_1
I0804 20:09:02.335199 14648 net.cpp:380] conv2_2 -> conv2_2
I0804 20:09:02.336550 14648 net.cpp:122] Setting up conv2_2
I0804 20:09:02.336577 14648 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 20:09:02.336591 14648 net.cpp:137] Memory required for data: 49975296
I0804 20:09:02.336607 14648 layer_factory.hpp:77] Creating layer relu2_2
I0804 20:09:02.336627 14648 net.cpp:84] Creating Layer relu2_2
I0804 20:09:02.336639 14648 net.cpp:406] relu2_2 <- conv2_2
I0804 20:09:02.336654 14648 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0804 20:09:02.336671 14648 net.cpp:122] Setting up relu2_2
I0804 20:09:02.336686 14648 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 20:09:02.336699 14648 net.cpp:137] Memory required for data: 51580928
I0804 20:09:02.336710 14648 layer_factory.hpp:77] Creating layer conv2_2norm
I0804 20:09:02.336731 14648 net.cpp:84] Creating Layer conv2_2norm
I0804 20:09:02.336745 14648 net.cpp:406] conv2_2norm <- conv2_2
I0804 20:09:02.336760 14648 net.cpp:380] conv2_2norm -> conv2_2norm
I0804 20:09:02.336997 14648 net.cpp:122] Setting up conv2_2norm
I0804 20:09:02.337050 14648 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 20:09:02.337064 14648 net.cpp:137] Memory required for data: 53186560
I0804 20:09:02.337082 14648 layer_factory.hpp:77] Creating layer conv3_1
I0804 20:09:02.337101 14648 net.cpp:84] Creating Layer conv3_1
I0804 20:09:02.337115 14648 net.cpp:406] conv3_1 <- conv2_2norm
I0804 20:09:02.337129 14648 net.cpp:380] conv3_1 -> conv3_1
I0804 20:09:02.337636 14648 net.cpp:122] Setting up conv3_1
I0804 20:09:02.337654 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.337667 14648 net.cpp:137] Memory required for data: 56397824
I0804 20:09:02.337683 14648 layer_factory.hpp:77] Creating layer relu3_1
I0804 20:09:02.337700 14648 net.cpp:84] Creating Layer relu3_1
I0804 20:09:02.337733 14648 net.cpp:406] relu3_1 <- conv3_1
I0804 20:09:02.337749 14648 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0804 20:09:02.337764 14648 net.cpp:122] Setting up relu3_1
I0804 20:09:02.337779 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.337791 14648 net.cpp:137] Memory required for data: 59609088
I0804 20:09:02.337803 14648 layer_factory.hpp:77] Creating layer conv3_2
I0804 20:09:02.337821 14648 net.cpp:84] Creating Layer conv3_2
I0804 20:09:02.337834 14648 net.cpp:406] conv3_2 <- conv3_1
I0804 20:09:02.337851 14648 net.cpp:380] conv3_2 -> conv3_2
I0804 20:09:02.339689 14648 net.cpp:122] Setting up conv3_2
I0804 20:09:02.339721 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.339735 14648 net.cpp:137] Memory required for data: 62820352
I0804 20:09:02.339758 14648 layer_factory.hpp:77] Creating layer relu3_2
I0804 20:09:02.339776 14648 net.cpp:84] Creating Layer relu3_2
I0804 20:09:02.339789 14648 net.cpp:406] relu3_2 <- conv3_2
I0804 20:09:02.339807 14648 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0804 20:09:02.339823 14648 net.cpp:122] Setting up relu3_2
I0804 20:09:02.339838 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.339849 14648 net.cpp:137] Memory required for data: 66031616
I0804 20:09:02.339862 14648 layer_factory.hpp:77] Creating layer conv3_3
I0804 20:09:02.339879 14648 net.cpp:84] Creating Layer conv3_3
I0804 20:09:02.339892 14648 net.cpp:406] conv3_3 <- conv3_2
I0804 20:09:02.339910 14648 net.cpp:380] conv3_3 -> conv3_3
I0804 20:09:02.341799 14648 net.cpp:122] Setting up conv3_3
I0804 20:09:02.341836 14648 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 20:09:02.341850 14648 net.cpp:137] Memory required for data: 66834432
I0804 20:09:02.341868 14648 layer_factory.hpp:77] Creating layer relu3_3
I0804 20:09:02.341892 14648 net.cpp:84] Creating Layer relu3_3
I0804 20:09:02.341905 14648 net.cpp:406] relu3_3 <- conv3_3
I0804 20:09:02.341920 14648 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0804 20:09:02.341938 14648 net.cpp:122] Setting up relu3_3
I0804 20:09:02.341953 14648 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 20:09:02.341964 14648 net.cpp:137] Memory required for data: 67637248
I0804 20:09:02.341976 14648 layer_factory.hpp:77] Creating layer conv3_3norm
I0804 20:09:02.341994 14648 net.cpp:84] Creating Layer conv3_3norm
I0804 20:09:02.342006 14648 net.cpp:406] conv3_3norm <- conv3_3
I0804 20:09:02.342023 14648 net.cpp:380] conv3_3norm -> conv3_3norm
I0804 20:09:02.342257 14648 net.cpp:122] Setting up conv3_3norm
I0804 20:09:02.342275 14648 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 20:09:02.342288 14648 net.cpp:137] Memory required for data: 68440064
I0804 20:09:02.342305 14648 layer_factory.hpp:77] Creating layer conv4_1
I0804 20:09:02.342327 14648 net.cpp:84] Creating Layer conv4_1
I0804 20:09:02.342341 14648 net.cpp:406] conv4_1 <- conv3_3norm
I0804 20:09:02.342356 14648 net.cpp:380] conv4_1 -> conv4_1
I0804 20:09:02.345568 14648 net.cpp:122] Setting up conv4_1
I0804 20:09:02.345615 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.345628 14648 net.cpp:137] Memory required for data: 70045696
I0804 20:09:02.345646 14648 layer_factory.hpp:77] Creating layer relu4_1
I0804 20:09:02.345666 14648 net.cpp:84] Creating Layer relu4_1
I0804 20:09:02.345680 14648 net.cpp:406] relu4_1 <- conv4_1
I0804 20:09:02.345696 14648 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0804 20:09:02.345713 14648 net.cpp:122] Setting up relu4_1
I0804 20:09:02.345728 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.345741 14648 net.cpp:137] Memory required for data: 71651328
I0804 20:09:02.345753 14648 layer_factory.hpp:77] Creating layer conv4_2
I0804 20:09:02.345777 14648 net.cpp:84] Creating Layer conv4_2
I0804 20:09:02.345790 14648 net.cpp:406] conv4_2 <- conv4_1
I0804 20:09:02.345806 14648 net.cpp:380] conv4_2 -> conv4_2
I0804 20:09:02.351809 14648 net.cpp:122] Setting up conv4_2
I0804 20:09:02.351863 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.351877 14648 net.cpp:137] Memory required for data: 73256960
I0804 20:09:02.351917 14648 layer_factory.hpp:77] Creating layer relu4_2
I0804 20:09:02.351936 14648 net.cpp:84] Creating Layer relu4_2
I0804 20:09:02.351951 14648 net.cpp:406] relu4_2 <- conv4_2
I0804 20:09:02.351969 14648 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0804 20:09:02.351987 14648 net.cpp:122] Setting up relu4_2
I0804 20:09:02.352002 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.352015 14648 net.cpp:137] Memory required for data: 74862592
I0804 20:09:02.352027 14648 layer_factory.hpp:77] Creating layer conv4_3
I0804 20:09:02.352046 14648 net.cpp:84] Creating Layer conv4_3
I0804 20:09:02.352058 14648 net.cpp:406] conv4_3 <- conv4_2
I0804 20:09:02.352078 14648 net.cpp:380] conv4_3 -> conv4_3
I0804 20:09:02.358077 14648 net.cpp:122] Setting up conv4_3
I0804 20:09:02.358129 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.358144 14648 net.cpp:137] Memory required for data: 76468224
I0804 20:09:02.358162 14648 layer_factory.hpp:77] Creating layer relu4_3
I0804 20:09:02.358181 14648 net.cpp:84] Creating Layer relu4_3
I0804 20:09:02.358196 14648 net.cpp:406] relu4_3 <- conv4_3
I0804 20:09:02.358212 14648 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0804 20:09:02.358232 14648 net.cpp:122] Setting up relu4_3
I0804 20:09:02.358247 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.358258 14648 net.cpp:137] Memory required for data: 78073856
I0804 20:09:02.358271 14648 layer_factory.hpp:77] Creating layer conv4_3norm
I0804 20:09:02.358288 14648 net.cpp:84] Creating Layer conv4_3norm
I0804 20:09:02.358300 14648 net.cpp:406] conv4_3norm <- conv4_3
I0804 20:09:02.358321 14648 net.cpp:380] conv4_3norm -> conv4_3norm
I0804 20:09:02.358564 14648 net.cpp:122] Setting up conv4_3norm
I0804 20:09:02.358582 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.358595 14648 net.cpp:137] Memory required for data: 79679488
I0804 20:09:02.358613 14648 layer_factory.hpp:77] Creating layer conv5_1
I0804 20:09:02.358633 14648 net.cpp:84] Creating Layer conv5_1
I0804 20:09:02.358647 14648 net.cpp:406] conv5_1 <- conv4_3norm
I0804 20:09:02.358662 14648 net.cpp:380] conv5_1 -> conv5_1
I0804 20:09:02.364626 14648 net.cpp:122] Setting up conv5_1
I0804 20:09:02.364678 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.364691 14648 net.cpp:137] Memory required for data: 81285120
I0804 20:09:02.364717 14648 layer_factory.hpp:77] Creating layer relu5_1
I0804 20:09:02.364739 14648 net.cpp:84] Creating Layer relu5_1
I0804 20:09:02.364754 14648 net.cpp:406] relu5_1 <- conv5_1
I0804 20:09:02.364769 14648 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0804 20:09:02.364789 14648 net.cpp:122] Setting up relu5_1
I0804 20:09:02.364802 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.364815 14648 net.cpp:137] Memory required for data: 82890752
I0804 20:09:02.364827 14648 layer_factory.hpp:77] Creating layer conv5_2
I0804 20:09:02.364847 14648 net.cpp:84] Creating Layer conv5_2
I0804 20:09:02.364861 14648 net.cpp:406] conv5_2 <- conv5_1
I0804 20:09:02.364876 14648 net.cpp:380] conv5_2 -> conv5_2
I0804 20:09:02.370862 14648 net.cpp:122] Setting up conv5_2
I0804 20:09:02.370915 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.370929 14648 net.cpp:137] Memory required for data: 84496384
I0804 20:09:02.370947 14648 layer_factory.hpp:77] Creating layer relu5_2
I0804 20:09:02.370970 14648 net.cpp:84] Creating Layer relu5_2
I0804 20:09:02.370985 14648 net.cpp:406] relu5_2 <- conv5_2
I0804 20:09:02.371001 14648 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0804 20:09:02.371017 14648 net.cpp:122] Setting up relu5_2
I0804 20:09:02.371031 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.371044 14648 net.cpp:137] Memory required for data: 86102016
I0804 20:09:02.371057 14648 layer_factory.hpp:77] Creating layer conv5_3
I0804 20:09:02.371076 14648 net.cpp:84] Creating Layer conv5_3
I0804 20:09:02.371089 14648 net.cpp:406] conv5_3 <- conv5_2
I0804 20:09:02.371104 14648 net.cpp:380] conv5_3 -> conv5_3
I0804 20:09:02.377071 14648 net.cpp:122] Setting up conv5_3
I0804 20:09:02.377123 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.377137 14648 net.cpp:137] Memory required for data: 87707648
I0804 20:09:02.377156 14648 layer_factory.hpp:77] Creating layer relu5_3
I0804 20:09:02.377176 14648 net.cpp:84] Creating Layer relu5_3
I0804 20:09:02.377189 14648 net.cpp:406] relu5_3 <- conv5_3
I0804 20:09:02.377207 14648 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0804 20:09:02.377224 14648 net.cpp:122] Setting up relu5_3
I0804 20:09:02.377239 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.377251 14648 net.cpp:137] Memory required for data: 89313280
I0804 20:09:02.377264 14648 layer_factory.hpp:77] Creating layer conv5_3norm
I0804 20:09:02.377282 14648 net.cpp:84] Creating Layer conv5_3norm
I0804 20:09:02.377295 14648 net.cpp:406] conv5_3norm <- conv5_3
I0804 20:09:02.377311 14648 net.cpp:380] conv5_3norm -> conv5_3norm
I0804 20:09:02.377555 14648 net.cpp:122] Setting up conv5_3norm
I0804 20:09:02.377573 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.377586 14648 net.cpp:137] Memory required for data: 90918912
I0804 20:09:02.377604 14648 layer_factory.hpp:77] Creating layer conv6_1
I0804 20:09:02.377629 14648 net.cpp:84] Creating Layer conv6_1
I0804 20:09:02.377642 14648 net.cpp:406] conv6_1 <- conv5_3norm
I0804 20:09:02.377657 14648 net.cpp:380] conv6_1 -> conv6_1
I0804 20:09:02.383473 14648 net.cpp:122] Setting up conv6_1
I0804 20:09:02.383527 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.383540 14648 net.cpp:137] Memory required for data: 92524544
I0804 20:09:02.383559 14648 layer_factory.hpp:77] Creating layer relu6_1
I0804 20:09:02.383580 14648 net.cpp:84] Creating Layer relu6_1
I0804 20:09:02.383595 14648 net.cpp:406] relu6_1 <- conv6_1
I0804 20:09:02.383610 14648 net.cpp:367] relu6_1 -> conv6_1 (in-place)
I0804 20:09:02.383628 14648 net.cpp:122] Setting up relu6_1
I0804 20:09:02.383643 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.383656 14648 net.cpp:137] Memory required for data: 94130176
I0804 20:09:02.383668 14648 layer_factory.hpp:77] Creating layer conv6_2
I0804 20:09:02.383688 14648 net.cpp:84] Creating Layer conv6_2
I0804 20:09:02.383702 14648 net.cpp:406] conv6_2 <- conv6_1
I0804 20:09:02.383718 14648 net.cpp:380] conv6_2 -> conv6_2
I0804 20:09:02.389562 14648 net.cpp:122] Setting up conv6_2
I0804 20:09:02.389616 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.389628 14648 net.cpp:137] Memory required for data: 95735808
I0804 20:09:02.389647 14648 layer_factory.hpp:77] Creating layer relu6_2
I0804 20:09:02.389667 14648 net.cpp:84] Creating Layer relu6_2
I0804 20:09:02.389680 14648 net.cpp:406] relu6_2 <- conv6_2
I0804 20:09:02.389698 14648 net.cpp:367] relu6_2 -> conv6_2 (in-place)
I0804 20:09:02.389716 14648 net.cpp:122] Setting up relu6_2
I0804 20:09:02.389730 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.389744 14648 net.cpp:137] Memory required for data: 97341440
I0804 20:09:02.389755 14648 layer_factory.hpp:77] Creating layer conv6_3
I0804 20:09:02.389772 14648 net.cpp:84] Creating Layer conv6_3
I0804 20:09:02.389786 14648 net.cpp:406] conv6_3 <- conv6_2
I0804 20:09:02.389803 14648 net.cpp:380] conv6_3 -> conv6_3
I0804 20:09:02.395716 14648 net.cpp:122] Setting up conv6_3
I0804 20:09:02.395768 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.395782 14648 net.cpp:137] Memory required for data: 98947072
I0804 20:09:02.395800 14648 layer_factory.hpp:77] Creating layer relu6_3
I0804 20:09:02.395820 14648 net.cpp:84] Creating Layer relu6_3
I0804 20:09:02.395834 14648 net.cpp:406] relu6_3 <- conv6_3
I0804 20:09:02.395853 14648 net.cpp:367] relu6_3 -> conv6_3 (in-place)
I0804 20:09:02.395870 14648 net.cpp:122] Setting up relu6_3
I0804 20:09:02.395884 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.395897 14648 net.cpp:137] Memory required for data: 100552704
I0804 20:09:02.395910 14648 layer_factory.hpp:77] Creating layer conv6_3norm
I0804 20:09:02.395926 14648 net.cpp:84] Creating Layer conv6_3norm
I0804 20:09:02.395962 14648 net.cpp:406] conv6_3norm <- conv6_3
I0804 20:09:02.395982 14648 net.cpp:380] conv6_3norm -> conv6_3norm
I0804 20:09:02.396224 14648 net.cpp:122] Setting up conv6_3norm
I0804 20:09:02.396242 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.396255 14648 net.cpp:137] Memory required for data: 102158336
I0804 20:09:02.396272 14648 layer_factory.hpp:77] Creating layer conv7_1
I0804 20:09:02.396292 14648 net.cpp:84] Creating Layer conv7_1
I0804 20:09:02.396306 14648 net.cpp:406] conv7_1 <- conv6_3norm
I0804 20:09:02.396322 14648 net.cpp:380] conv7_1 -> conv7_1
I0804 20:09:02.402175 14648 net.cpp:122] Setting up conv7_1
I0804 20:09:02.402227 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.402240 14648 net.cpp:137] Memory required for data: 103763968
I0804 20:09:02.402259 14648 layer_factory.hpp:77] Creating layer relu7_1
I0804 20:09:02.402278 14648 net.cpp:84] Creating Layer relu7_1
I0804 20:09:02.402292 14648 net.cpp:406] relu7_1 <- conv7_1
I0804 20:09:02.402310 14648 net.cpp:367] relu7_1 -> conv7_1 (in-place)
I0804 20:09:02.402328 14648 net.cpp:122] Setting up relu7_1
I0804 20:09:02.402343 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.402356 14648 net.cpp:137] Memory required for data: 105369600
I0804 20:09:02.402369 14648 layer_factory.hpp:77] Creating layer conv7_2
I0804 20:09:02.402386 14648 net.cpp:84] Creating Layer conv7_2
I0804 20:09:02.402400 14648 net.cpp:406] conv7_2 <- conv7_1
I0804 20:09:02.402417 14648 net.cpp:380] conv7_2 -> conv7_2
I0804 20:09:02.408277 14648 net.cpp:122] Setting up conv7_2
I0804 20:09:02.408330 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.408344 14648 net.cpp:137] Memory required for data: 106975232
I0804 20:09:02.408362 14648 layer_factory.hpp:77] Creating layer relu7_2
I0804 20:09:02.408381 14648 net.cpp:84] Creating Layer relu7_2
I0804 20:09:02.408396 14648 net.cpp:406] relu7_2 <- conv7_2
I0804 20:09:02.408413 14648 net.cpp:367] relu7_2 -> conv7_2 (in-place)
I0804 20:09:02.408432 14648 net.cpp:122] Setting up relu7_2
I0804 20:09:02.408447 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.408458 14648 net.cpp:137] Memory required for data: 108580864
I0804 20:09:02.408470 14648 layer_factory.hpp:77] Creating layer conv7_3
I0804 20:09:02.408488 14648 net.cpp:84] Creating Layer conv7_3
I0804 20:09:02.408501 14648 net.cpp:406] conv7_3 <- conv7_2
I0804 20:09:02.408521 14648 net.cpp:380] conv7_3 -> conv7_3
I0804 20:09:02.414381 14648 net.cpp:122] Setting up conv7_3
I0804 20:09:02.414434 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.414448 14648 net.cpp:137] Memory required for data: 110186496
I0804 20:09:02.414468 14648 layer_factory.hpp:77] Creating layer relu7_3
I0804 20:09:02.414489 14648 net.cpp:84] Creating Layer relu7_3
I0804 20:09:02.414504 14648 net.cpp:406] relu7_3 <- conv7_3
I0804 20:09:02.414520 14648 net.cpp:367] relu7_3 -> conv7_3 (in-place)
I0804 20:09:02.414537 14648 net.cpp:122] Setting up relu7_3
I0804 20:09:02.414551 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.414564 14648 net.cpp:137] Memory required for data: 111792128
I0804 20:09:02.414577 14648 layer_factory.hpp:77] Creating layer conv7_3norm
I0804 20:09:02.414594 14648 net.cpp:84] Creating Layer conv7_3norm
I0804 20:09:02.414608 14648 net.cpp:406] conv7_3norm <- conv7_3
I0804 20:09:02.414623 14648 net.cpp:380] conv7_3norm -> conv7_3norm
I0804 20:09:02.414876 14648 net.cpp:122] Setting up conv7_3norm
I0804 20:09:02.414896 14648 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:09:02.414907 14648 net.cpp:137] Memory required for data: 113397760
I0804 20:09:02.414925 14648 layer_factory.hpp:77] Creating layer conv8_1
I0804 20:09:02.414942 14648 net.cpp:84] Creating Layer conv8_1
I0804 20:09:02.414955 14648 net.cpp:406] conv8_1 <- conv7_3norm
I0804 20:09:02.414973 14648 net.cpp:380] conv8_1 -> conv8_1
I0804 20:09:02.420255 14648 net.cpp:122] Setting up conv8_1
I0804 20:09:02.420317 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.420351 14648 net.cpp:137] Memory required for data: 116609024
I0804 20:09:02.420372 14648 layer_factory.hpp:77] Creating layer relu8_1
I0804 20:09:02.420390 14648 net.cpp:84] Creating Layer relu8_1
I0804 20:09:02.420404 14648 net.cpp:406] relu8_1 <- conv8_1
I0804 20:09:02.420423 14648 net.cpp:367] relu8_1 -> conv8_1 (in-place)
I0804 20:09:02.420440 14648 net.cpp:122] Setting up relu8_1
I0804 20:09:02.420455 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.420469 14648 net.cpp:137] Memory required for data: 119820288
I0804 20:09:02.420480 14648 layer_factory.hpp:77] Creating layer conv8_2
I0804 20:09:02.420498 14648 net.cpp:84] Creating Layer conv8_2
I0804 20:09:02.420511 14648 net.cpp:406] conv8_2 <- conv8_1
I0804 20:09:02.420529 14648 net.cpp:380] conv8_2 -> conv8_2
I0804 20:09:02.422472 14648 net.cpp:122] Setting up conv8_2
I0804 20:09:02.422504 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.422518 14648 net.cpp:137] Memory required for data: 123031552
I0804 20:09:02.422535 14648 layer_factory.hpp:77] Creating layer relu8_2
I0804 20:09:02.422551 14648 net.cpp:84] Creating Layer relu8_2
I0804 20:09:02.422565 14648 net.cpp:406] relu8_2 <- conv8_2
I0804 20:09:02.422582 14648 net.cpp:367] relu8_2 -> conv8_2 (in-place)
I0804 20:09:02.422600 14648 net.cpp:122] Setting up relu8_2
I0804 20:09:02.422613 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.422626 14648 net.cpp:137] Memory required for data: 126242816
I0804 20:09:02.422638 14648 layer_factory.hpp:77] Creating layer conv8_3
I0804 20:09:02.422657 14648 net.cpp:84] Creating Layer conv8_3
I0804 20:09:02.422669 14648 net.cpp:406] conv8_3 <- conv8_2
I0804 20:09:02.422685 14648 net.cpp:380] conv8_3 -> conv8_3
I0804 20:09:02.424564 14648 net.cpp:122] Setting up conv8_3
I0804 20:09:02.424599 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.424613 14648 net.cpp:137] Memory required for data: 129454080
I0804 20:09:02.424643 14648 layer_factory.hpp:77] Creating layer relu8_3
I0804 20:09:02.424661 14648 net.cpp:84] Creating Layer relu8_3
I0804 20:09:02.424675 14648 net.cpp:406] relu8_3 <- conv8_3
I0804 20:09:02.424692 14648 net.cpp:367] relu8_3 -> conv8_3 (in-place)
I0804 20:09:02.424710 14648 net.cpp:122] Setting up relu8_3
I0804 20:09:02.424724 14648 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:09:02.424736 14648 net.cpp:137] Memory required for data: 132665344
I0804 20:09:02.424749 14648 layer_factory.hpp:77] Creating layer conv8_313
I0804 20:09:02.424767 14648 net.cpp:84] Creating Layer conv8_313
I0804 20:09:02.424779 14648 net.cpp:406] conv8_313 <- conv8_3
I0804 20:09:02.424795 14648 net.cpp:380] conv8_313 -> conv8_313
I0804 20:09:02.426234 14648 net.cpp:122] Setting up conv8_313
I0804 20:09:02.426268 14648 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 20:09:02.426281 14648 net.cpp:137] Memory required for data: 136591616
I0804 20:09:02.426300 14648 layer_factory.hpp:77] Creating layer conv8_313_rh
I0804 20:09:02.426319 14648 net.cpp:84] Creating Layer conv8_313_rh
I0804 20:09:02.426333 14648 net.cpp:406] conv8_313_rh <- conv8_313
I0804 20:09:02.426352 14648 net.cpp:380] conv8_313_rh -> conv8_313_rh
I0804 20:09:02.426482 14648 net.cpp:122] Setting up conv8_313_rh
I0804 20:09:02.426501 14648 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 20:09:02.426513 14648 net.cpp:137] Memory required for data: 140517888
I0804 20:09:02.426527 14648 layer_factory.hpp:77] Creating layer class8_313_rh
I0804 20:09:02.426543 14648 net.cpp:84] Creating Layer class8_313_rh
I0804 20:09:02.426556 14648 net.cpp:406] class8_313_rh <- conv8_313_rh
I0804 20:09:02.426573 14648 net.cpp:380] class8_313_rh -> class8_313_rh
I0804 20:09:02.426661 14648 net.cpp:122] Setting up class8_313_rh
I0804 20:09:02.426677 14648 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 20:09:02.426690 14648 net.cpp:137] Memory required for data: 144444160
I0804 20:09:02.426703 14648 layer_factory.hpp:77] Creating layer class8_ab
I0804 20:09:02.426722 14648 net.cpp:84] Creating Layer class8_ab
I0804 20:09:02.426734 14648 net.cpp:406] class8_ab <- class8_313_rh
I0804 20:09:02.426769 14648 net.cpp:380] class8_ab -> class8_ab
I0804 20:09:02.427052 14648 net.cpp:122] Setting up class8_ab
I0804 20:09:02.427069 14648 net.cpp:129] Top shape: 1 2 56 56 (6272)
I0804 20:09:02.427083 14648 net.cpp:137] Memory required for data: 144469248
I0804 20:09:02.427098 14648 layer_factory.hpp:77] Creating layer Silence
I0804 20:09:02.427114 14648 net.cpp:84] Creating Layer Silence
I0804 20:09:02.427127 14648 net.cpp:406] Silence <- class8_ab
I0804 20:09:02.427145 14648 net.cpp:122] Setting up Silence
I0804 20:09:02.427157 14648 net.cpp:137] Memory required for data: 144469248
I0804 20:09:02.427170 14648 net.cpp:200] Silence does not need backward computation.
I0804 20:09:02.427182 14648 net.cpp:200] class8_ab does not need backward computation.
I0804 20:09:02.427196 14648 net.cpp:200] class8_313_rh does not need backward computation.
I0804 20:09:02.427208 14648 net.cpp:200] conv8_313_rh does not need backward computation.
I0804 20:09:02.427222 14648 net.cpp:200] conv8_313 does not need backward computation.
I0804 20:09:02.427234 14648 net.cpp:200] relu8_3 does not need backward computation.
I0804 20:09:02.427248 14648 net.cpp:200] conv8_3 does not need backward computation.
I0804 20:09:02.427260 14648 net.cpp:200] relu8_2 does not need backward computation.
I0804 20:09:02.427273 14648 net.cpp:200] conv8_2 does not need backward computation.
I0804 20:09:02.427285 14648 net.cpp:200] relu8_1 does not need backward computation.
I0804 20:09:02.427299 14648 net.cpp:200] conv8_1 does not need backward computation.
I0804 20:09:02.427311 14648 net.cpp:200] conv7_3norm does not need backward computation.
I0804 20:09:02.427325 14648 net.cpp:200] relu7_3 does not need backward computation.
I0804 20:09:02.427337 14648 net.cpp:200] conv7_3 does not need backward computation.
I0804 20:09:02.427350 14648 net.cpp:200] relu7_2 does not need backward computation.
I0804 20:09:02.427363 14648 net.cpp:200] conv7_2 does not need backward computation.
I0804 20:09:02.427376 14648 net.cpp:200] relu7_1 does not need backward computation.
I0804 20:09:02.427388 14648 net.cpp:200] conv7_1 does not need backward computation.
I0804 20:09:02.427402 14648 net.cpp:200] conv6_3norm does not need backward computation.
I0804 20:09:02.427414 14648 net.cpp:200] relu6_3 does not need backward computation.
I0804 20:09:02.427428 14648 net.cpp:200] conv6_3 does not need backward computation.
I0804 20:09:02.427440 14648 net.cpp:200] relu6_2 does not need backward computation.
I0804 20:09:02.427453 14648 net.cpp:200] conv6_2 does not need backward computation.
I0804 20:09:02.427465 14648 net.cpp:200] relu6_1 does not need backward computation.
I0804 20:09:02.427479 14648 net.cpp:200] conv6_1 does not need backward computation.
I0804 20:09:02.427491 14648 net.cpp:200] conv5_3norm does not need backward computation.
I0804 20:09:02.427505 14648 net.cpp:200] relu5_3 does not need backward computation.
I0804 20:09:02.427517 14648 net.cpp:200] conv5_3 does not need backward computation.
I0804 20:09:02.427530 14648 net.cpp:200] relu5_2 does not need backward computation.
I0804 20:09:02.427542 14648 net.cpp:200] conv5_2 does not need backward computation.
I0804 20:09:02.427556 14648 net.cpp:200] relu5_1 does not need backward computation.
I0804 20:09:02.427567 14648 net.cpp:200] conv5_1 does not need backward computation.
I0804 20:09:02.427580 14648 net.cpp:200] conv4_3norm does not need backward computation.
I0804 20:09:02.427592 14648 net.cpp:200] relu4_3 does not need backward computation.
I0804 20:09:02.427605 14648 net.cpp:200] conv4_3 does not need backward computation.
I0804 20:09:02.427618 14648 net.cpp:200] relu4_2 does not need backward computation.
I0804 20:09:02.427630 14648 net.cpp:200] conv4_2 does not need backward computation.
I0804 20:09:02.427644 14648 net.cpp:200] relu4_1 does not need backward computation.
I0804 20:09:02.427657 14648 net.cpp:200] conv4_1 does not need backward computation.
I0804 20:09:02.427670 14648 net.cpp:200] conv3_3norm does not need backward computation.
I0804 20:09:02.427697 14648 net.cpp:200] relu3_3 does not need backward computation.
I0804 20:09:02.427711 14648 net.cpp:200] conv3_3 does not need backward computation.
I0804 20:09:02.427723 14648 net.cpp:200] relu3_2 does not need backward computation.
I0804 20:09:02.427736 14648 net.cpp:200] conv3_2 does not need backward computation.
I0804 20:09:02.427749 14648 net.cpp:200] relu3_1 does not need backward computation.
I0804 20:09:02.427762 14648 net.cpp:200] conv3_1 does not need backward computation.
I0804 20:09:02.427775 14648 net.cpp:200] conv2_2norm does not need backward computation.
I0804 20:09:02.427788 14648 net.cpp:200] relu2_2 does not need backward computation.
I0804 20:09:02.427800 14648 net.cpp:200] conv2_2 does not need backward computation.
I0804 20:09:02.427814 14648 net.cpp:200] relu2_1 does not need backward computation.
I0804 20:09:02.427826 14648 net.cpp:200] conv2_1 does not need backward computation.
I0804 20:09:02.427839 14648 net.cpp:200] conv1_2norm does not need backward computation.
I0804 20:09:02.427852 14648 net.cpp:200] relu1_2 does not need backward computation.
I0804 20:09:02.427865 14648 net.cpp:200] conv1_2 does not need backward computation.
I0804 20:09:02.427878 14648 net.cpp:200] relu1_1 does not need backward computation.
I0804 20:09:02.427891 14648 net.cpp:200] bw_conv1_1 does not need backward computation.
I0804 20:09:02.427903 14648 net.cpp:200] data_l does not need backward computation.
I0804 20:09:02.427943 14648 net.cpp:255] Network initialization done.
I0804 20:09:02.529563 14648 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_release_v2.caffemodel
I0804 20:09:02.529621 14648 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 20:09:02.529637 14648 net.cpp:744] Ignoring source layer img
I0804 20:09:02.529651 14648 net.cpp:744] Ignoring source layer img_lab
I0804 20:09:02.529664 14648 net.cpp:744] Ignoring source layer img_slice
I0804 20:09:02.529676 14648 net.cpp:744] Ignoring source layer data_l_meansub
I0804 20:09:02.529688 14648 net.cpp:744] Ignoring source layer data_ab_ss
I0804 20:09:02.529700 14648 net.cpp:744] Ignoring source layer data_ab_ss_data_ab_ss_0_split
I0804 20:09:02.529713 14648 net.cpp:744] Ignoring source layer ab_enc
I0804 20:09:02.529726 14648 net.cpp:744] Ignoring source layer gt_ab_313_ab_enc_0_split
I0804 20:09:02.529737 14648 net.cpp:744] Ignoring source layer ab_pb
I0804 20:09:02.529749 14648 net.cpp:744] Ignoring source layer ab_pb
I0804 20:09:02.529762 14648 net.cpp:744] Ignoring source layer pb_nongray
I0804 20:09:02.554672 14648 net.cpp:744] Ignoring source layer PriorBoost8
I0804 20:09:02.554698 14648 net.cpp:744] Ignoring source layer SoftmaxLoss8
/home/thijser/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.
  warn("The default mode, 'constant', will be changed to 'reflect' in "
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
killing all other torch instances
/home/thijser/torch/install/bin/luajit: no process found
https://www.google.co.in/search?q=planetarium&safe=off&source=lnms&tbm=isch&num=25
there are total 100 images
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
could not load : http://tellusmuseum.org/wp-content/uploads/2012/06/Planetarium-with-graphic-cropped.jpg
HTTP Error 403: Forbidden
43
44
45
46
47
48
49
50
51
52
could not load : http://tellusmuseum.org/wp-content/uploads/2012/06/Planetarium.jpg
HTTP Error 403: Forbidden
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
could not load : http://www.most.org/wp-content/uploads/2016/04/PlanetariumWEB.jpg
HTTP Error 403: Forbidden
77
78
79
80
81
82
83
84
85
86
could not load : http://statemuseumpa.org/wp-content/uploads/2013/09/Website-Main-Header-2-960x350.jpg
HTTP Error 403: Forbidden
87
could not load : http://460fnt1vjfoo3jkqfk3fkfkz.wpengine.netdna-cdn.com/wp-content/uploads/2016/06/Planetarium.jpg
HTTP Error 403: Forbidden
88
89
90
91
92
93
94
95
th imageSelector.lua -avaible_images t/Pictures/planetarium/ActiOn_45.jpg,t/Pictures/planetarium/ActiOn_23.jpg,t/Pictures/planetarium/ActiOn_35.jpg,t/Pictures/planetarium/ActiOn_61.jpg,t/Pictures/planetarium/ActiOn_91.jpg,t/Pictures/planetarium/ActiOn_7.jpg,t/Pictures/planetarium/ActiOn_40.jpg,t/Pictures/planetarium/ActiOn_11.jpg,t/Pictures/planetarium/ActiOn_90.jpg,t/Pictures/planetarium/ActiOn_74.jpg,t/Pictures/planetarium/ActiOn_44.jpg,t/Pictures/planetarium/ActiOn_6.jpg,t/Pictures/planetarium/ActiOn_2.jpg,t/Pictures/planetarium/ActiOn_9.jpg,t/Pictures/planetarium/ActiOn_88.jpg,t/Pictures/planetarium/ActiOn_94.jpg,t/Pictures/planetarium/ActiOn_57.jpg,t/Pictures/planetarium/ActiOn_62.jpg,t/Pictures/planetarium/ActiOn_20.jpg,t/Pictures/planetarium/ActiOn_30.jpg,t/Pictures/planetarium/ActiOn_95.jpg,t/Pictures/planetarium/ActiOn_58.jpg,t/Pictures/planetarium/ActiOn_41.jpg,t/Pictures/planetarium/ActiOn_4.jpg,t/Pictures/planetarium/ActiOn_28.jpg,t/Pictures/planetarium/ActiOn_83.jpg,t/Pictures/planetarium/ActiOn_49.jpg,t/Pictures/planetarium/ActiOn_52.jpg,t/Pictures/planetarium/ActiOn_78.jpg,t/Pictures/planetarium/ActiOn_37.jpg,t/Pictures/planetarium/ActiOn_55.jpg,t/Pictures/planetarium/ActiOn_73.jpg,t/Pictures/planetarium/ActiOn_66.jpg,t/Pictures/planetarium/ActiOn_17.jpg,t/Pictures/planetarium/ActiOn_32.jpg,t/Pictures/planetarium/ActiOn_5.jpg,t/Pictures/planetarium/ActiOn_31.jpg,t/Pictures/planetarium/ActiOn_13.jpg,t/Pictures/planetarium/ActiOn_60.png,t/Pictures/planetarium/ActiOn_85.jpg,t/Pictures/planetarium/ActiOn_81.jpg,t/Pictures/planetarium/ActiOn_36.png,t/Pictures/planetarium/ActiOn_82.jpg,t/Pictures/planetarium/ActiOn_72.jpg,t/Pictures/planetarium/ActiOn_18.jpg,t/Pictures/planetarium/ActiOn_14.jpg,t/Pictures/planetarium/ActiOn_76.jpg,t/Pictures/planetarium/ActiOn_3.jpg,t/Pictures/planetarium/ActiOn_22.jpg,t/Pictures/planetarium/ActiOn_8.jpg,t/Pictures/planetarium/ActiOn_33.jpg,t/Pictures/planetarium/ActiOn_67.png,t/Pictures/planetarium/ActiOn_46.jpg,t/Pictures/planetarium/ActiOn_59.png,t/Pictures/planetarium/ActiOn_77.jpg,t/Pictures/planetarium/ActiOn_75.jpg,t/Pictures/planetarium/ActiOn_29.jpg,t/Pictures/planetarium/ActiOn_65.jpg,t/Pictures/planetarium/ActiOn_63.jpg,t/Pictures/planetarium/ActiOn_24.jpg,t/Pictures/planetarium/ActiOn_69.jpg,t/Pictures/planetarium/ActiOn_68.jpg,t/Pictures/planetarium/ActiOn_15.jpg,t/Pictures/planetarium/ActiOn_51.jpg,t/Pictures/planetarium/ActiOn_80.jpg,t/Pictures/planetarium/ActiOn_21.jpg,t/Pictures/planetarium/ActiOn_86.jpg,t/Pictures/planetarium/ActiOn_56.jpg,t/Pictures/planetarium/ActiOn_1.jpg,t/Pictures/planetarium/ActiOn_34.jpg,t/Pictures/planetarium/ActiOn_43.jpg,t/Pictures/planetarium/ActiOn_79.jpg,t/Pictures/planetarium/ActiOn_92.jpg,t/Pictures/planetarium/ActiOn_12.jpg,t/Pictures/planetarium/ActiOn_16.jpg,t/Pictures/planetarium/ActiOn_38.jpg,t/Pictures/planetarium/ActiOn_53.jpg,t/Pictures/planetarium/ActiOn_64.jpg,t/Pictures/planetarium/ActiOn_93.jpg,t/Pictures/planetarium/ActiOn_26.jpg,t/Pictures/planetarium/ActiOn_25.jpg,t/Pictures/planetarium/ActiOn_48.jpg,t/Pictures/planetarium/ActiOn_87.jpg,t/Pictures/planetarium/ActiOn_71.jpg,t/Pictures/planetarium/ActiOn_42.jpg,t/Pictures/planetarium/ActiOn_39.jpg,t/Pictures/planetarium/ActiOn_50.jpg,t/Pictures/planetarium/ActiOn_19.jpg,t/Pictures/planetarium/ActiOn_70.jpg,t/Pictures/planetarium/ActiOn_89.jpg,t/Pictures/planetarium/ActiOn_27.jpg,t/Pictures/planetarium/ActiOn_47.jpg,t/Pictures/planetarium/ActiOn_54.jpg,t/Pictures/planetarium/ActiOn_10.jpg
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
coleval=914487465.26331	
neuroval=497542308	
coleval=2102139322.9167	
neuroval=559887200	
coleval=492452772.34136	
neuroval=561893992	
coleval=635223750	
neuroval=682699538	
coleval=390892500	
neuroval=519636352	
coleval=503653125	
neuroval=747383328	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1118276250	
neuroval=646291412	
coleval=421507500	
neuroval=589109476	
coleval=797078278.00402	
neuroval=609355596	
coleval=2243173409.5459	
neuroval=448955284	
coleval=686665428.59136	
neuroval=541333728	
coleval=449838642.17953	
neuroval=571808796	
coleval=1972141875	
neuroval=827351992	
coleval=975144375	
neuroval=576357612	
coleval=981783750	
neuroval=670066592	
coleval=896044708.60178	
neuroval=464055524	
coleval=70225144.400968	
neuroval=553340154	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
[1;35mimage.load[0m

loads an image into a torch.Tensor

[0;34m> [0musage:
[0;36mimage.load(
    string                              -- path to file
    [number]                            -- force destination depth: 1 | 3
    [string]                            -- type: byte | float | double
)
[0m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++	
coleval=1011420000	
neuroval=582996948	
coleval=280985625	
neuroval=693668636	
coleval=449051250	
neuroval=808544864	
coleval=1351063125	
neuroval=762588376	
coleval=841665000	
neuroval=668481860	
coleval=633238125	
neuroval=619046328	
coleval=327718125	
neuroval=488906492	
coleval=1021804310.8037	
neuroval=601878832	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
[1;35mimage.load[0m

loads an image into a torch.Tensor

[0;34m> [0musage:
[0;36mimage.load(
    string                              -- path to file
    [number]                            -- force destination depth: 1 | 3
    [string]                            -- type: byte | float | double
)
[0m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2862845625	
neuroval=654124668	
coleval=995250000	
neuroval=803785232	
coleval=3765821250	
neuroval=467777480	
coleval=830332500	
neuroval=651306904	
coleval=3312435000	
neuroval=586728240	
coleval=3302687658.2972	
neuroval=571143740	
coleval=1008684375	
neuroval=630837716	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_42.jpg"
      3 : "t/Pictures/planetarium/ActiOn_50.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_37.jpg"
    }
  2 : 623565298.40097
}
coleval=555932030.15386	
neuroval=730037992	
coleval=3252266250	
neuroval=387569604	
coleval=2578794375	
neuroval=492829852	
coleval=691299375	
neuroval=607431672	
coleval=70225144.400968	
neuroval=553340154	
coleval=198107700.43705	
neuroval=681846940	
coleval=662842604.64092	
neuroval=571100292	
coleval=690992871.16018	
neuroval=641681304	
coleval=651263070.30918	
neuroval=548029808	
coleval=335302600.74538	
neuroval=604537216	
coleval=327718125	
neuroval=488906492	
coleval=504283125	
neuroval=478191300	
coleval=561603750	
neuroval=421105354	
coleval=483815625	
neuroval=482742550	
coleval=575025000	
neuroval=480338982	
coleval=390892500	
neuroval=519636352	
coleval=355518750	
neuroval=433361352	
coleval=429153750	
neuroval=483635088	
coleval=435684375	
neuroval=475216034	
coleval=3514623750	
neuroval=493530852	
coleval=3331515000	
neuroval=458111276	
coleval=280985625	
neuroval=693668636	
coleval=2614710000	
neuroval=608773500	
coleval=2686794375	
neuroval=563972468	
coleval=2860327500	
neuroval=666260972	
coleval=2878768125	
neuroval=488855072	
coleval=2949144375	
neuroval=565318252	
coleval=421507500	
neuroval=589109476	
coleval=469580625	
neuroval=497435188	
coleval=471658125	
neuroval=551750628	
coleval=479835000	
neuroval=588582720	
coleval=490044360.65051	
neuroval=607838920	
coleval=468798750	
neuroval=628872768	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_42.jpg"
      3 : "t/Pictures/planetarium/ActiOn_50.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_37.jpg"
    }
  2 : 623565298.40097
}
coleval=559348268.35465	
neuroval=359125372	
coleval=794933934.45073	
neuroval=503624264	
coleval=473525625	
neuroval=701016624	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2084597159.3749	
neuroval=569016156	
coleval=2947571250	
neuroval=579868132	
coleval=70225144.400968	
neuroval=553340154	
coleval=82913337.567319	
neuroval=451258578	
coleval=94881661.414045	
neuroval=580584404	
coleval=17353854.757181	
neuroval=525876042	
coleval=91944160.979279	
neuroval=431248202	
coleval=611825595.36358	
neuroval=463610716	
coleval=355518750	
neuroval=433361352	
coleval=248881875	
neuroval=338115142	
coleval=213373125	
neuroval=387696240	
coleval=611137500	
neuroval=370168992	
coleval=786521685.5668	
neuroval=428498012	
coleval=703849623.62484	
neuroval=396807156	
coleval=327718125	
neuroval=488906492	
coleval=1962158125	
neuroval=443653896	
coleval=1862362109.375	
neuroval=545509824	
coleval=1578816679.6875	
neuroval=646518188	
coleval=360220230.48868	
neuroval=699245176	
coleval=254726250	
neuroval=681053120	
coleval=198107700.43705	
neuroval=681846940	
coleval=114854447.78638	
neuroval=552165430	
coleval=68426149.446541	
neuroval=640372972	
coleval=1721442639.6344	
neuroval=754455712	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1828270220.8984	
neuroval=662085336	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2875547456.4127	
neuroval=630709940	
coleval=390892500	
neuroval=519636352	
coleval=471016875	
neuroval=532175084	
coleval=435343125	
neuroval=583744820	
coleval=454321875	
neuroval=641244728	
coleval=611731875	
neuroval=637236728	
coleval=446154375	
neuroval=643910080	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_74.jpg"
      3 : "t/Pictures/planetarium/ActiOn_52.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_37.jpg"
    }
  2 : 523192362.97928
}
coleval=2765563125	
neuroval=478569152	
coleval=318195030.93371	
neuroval=411420336	
coleval=1016113125	
neuroval=368942622	
coleval=482581273.31792	
neuroval=542955272	
coleval=302490000	
neuroval=422940076	
coleval=91944160.979279	
neuroval=431248202	
coleval=97376486.128088	
neuroval=354966202	
coleval=1280167808.6727	
neuroval=427318764	
coleval=1622596123.1724	
neuroval=337819640	
coleval=1397572500	
neuroval=410238168	
coleval=3360360000	
neuroval=407904048	
coleval=82913337.567319	
neuroval=451258578	
coleval=137331028.60154	
neuroval=260076436	
coleval=602040643.95919	
neuroval=237730588	
coleval=534729844.17074	
neuroval=286171832	
coleval=917002666.97147	
neuroval=308439408	
coleval=673171329.99435	
neuroval=380015824	
coleval=17353854.757181	
neuroval=525876042	
coleval=551299980.36172	
neuroval=408131850	
coleval=592417500	
neuroval=402924714	
coleval=722998125	
neuroval=460424622	
coleval=777875625	
neuroval=450698590	
coleval=783626250	
neuroval=463837878	
coleval=248881875	
neuroval=338115142	
coleval=266835000	
neuroval=366326380	
coleval=319974375	
neuroval=450412848	
coleval=593068721.69962	
neuroval=436907392	
coleval=456094472.9552	
neuroval=468380108	
coleval=453972944.63489	
neuroval=576928664	
coleval=213373125	
neuroval=387696240	
coleval=174903750	
neuroval=363979952	
coleval=163260000	
neuroval=507256708	
coleval=314602500	
neuroval=482384956	
coleval=363435000	
neuroval=581313704	
coleval=309924375	
neuroval=514951932	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_42.jpg"
      3 : "t/Pictures/planetarium/ActiOn_82.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_95.jpg"
    }
  2 : 397407464.60154
}
coleval=303340021.09013	
neuroval=781015728	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=4058173125	
neuroval=495092540	
coleval=758283750	
neuroval=487694280	
coleval=298787309.50159	
neuroval=572265048	
coleval=775642500	
neuroval=567550524	
coleval=137331028.60154	
neuroval=260076436	
coleval=423619601.98324	
neuroval=359774330	
coleval=434027303.24812	
neuroval=441852418	
coleval=75189871.700503	
neuroval=450531570	
coleval=391191562.08369	
neuroval=542146430	
coleval=365788360.81881	
neuroval=724186432	
coleval=97376486.128088	
neuroval=354966202	
coleval=664915720.45659	
neuroval=354782666	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=663961869.31261	
neuroval=419202228	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=17234682.277642	
neuroval=412899016	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2176078054.441	
neuroval=439676064	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=4478878125	
neuroval=424662068	
coleval=91944160.979279	
neuroval=431248202	
coleval=530767573.13516	
neuroval=452008040	
coleval=649539919.09405	
neuroval=360523792	
coleval=921060093.13144	
neuroval=435524624	
coleval=1053605625	
neuroval=547812000	
coleval=1879050000	
neuroval=560614976	
coleval=82913337.567319	
neuroval=451258578	
coleval=253360563.24508	
neuroval=497893226	
coleval=284728379.16305	
neuroval=373642650	
coleval=220188706.47425	
neuroval=414804694	
coleval=299693875.41956	
neuroval=448014472	
coleval=531808209.40394	
neuroval=468191752	
coleval=174903750	
neuroval=363979952	
coleval=337783125	
neuroval=403052772	
coleval=394170000	
neuroval=344231192	
coleval=1964700000	
neuroval=392438728	
coleval=1775908125	
neuroval=481538332	
coleval=1923973125	
neuroval=623475396	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_42.jpg"
      3 : "t/Pictures/planetarium/ActiOn_82.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_95.jpg"
    }
  2 : 397407464.60154
}
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=754810531.71171	
neuroval=536218020	
coleval=430682801.20081	
neuroval=473609150	
coleval=616490625	
neuroval=476573654	
coleval=1848266390.4877	
neuroval=508071520	
coleval=137331028.60154	
neuroval=260076436	
coleval=121952819.15214	
neuroval=309657534	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=17234682.277642	
neuroval=412899016	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=49792333.296057	
neuroval=441773724	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1989823642.9361	
neuroval=416976884	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=3317376107.0126	
neuroval=393374956	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=3024868961.4225	
neuroval=463955968	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2350826767.9933	
neuroval=381935700	
coleval=97376486.128088	
neuroval=354966202	
coleval=599844886.07693	
neuroval=369458922	
coleval=399063722.2237	
neuroval=441793358	
coleval=786178493.13749	
neuroval=486095438	
coleval=690034173.94106	
neuroval=449386318	
coleval=474762630.33382	
neuroval=455165766	
coleval=91944160.979279	
neuroval=431248202	
coleval=42170698.367672	
neuroval=587341370	
coleval=483496886.40246	
neuroval=761034318	
coleval=3497836089.6902	
neuroval=597237134	
coleval=3576415548.1631	
neuroval=423806014	
coleval=3595942500	
neuroval=452656686	
coleval=75189871.700503	
neuroval=450531570	
coleval=564651102.16925	
neuroval=294254866	
coleval=512719192.66404	
neuroval=450390116	
coleval=1115307664.2972	
neuroval=516475560	
coleval=2181223464.498	
neuroval=508234188	
coleval=2353486895.1156	
neuroval=474600732	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_42.jpg"
      3 : "t/Pictures/planetarium/ActiOn_82.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_95.jpg"
    }
  2 : 397407464.60154
}
coleval=2813832685.8037	
neuroval=482329910	
coleval=870763125	
neuroval=454544554	
coleval=3128847792.1642	
neuroval=468843264	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2506715625	
neuroval=506535880	
coleval=137331028.60154	
neuroval=260076436	
coleval=1473589358.0286	
neuroval=380781718	
coleval=1431626049.736	
neuroval=399450750	
coleval=1298600583.4274	
neuroval=491065610	
coleval=1533982551.2008	
neuroval=605965752	
coleval=1571973799.8987	
neuroval=505931838	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=17234682.277642	
neuroval=412899016	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=378502645.6798	
neuroval=505114068	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=413071875	
neuroval=499906932	
coleval=2768434010.4167	
neuroval=466362868	
coleval=2776149791.6667	
neuroval=520217392	
coleval=713840625	
neuroval=487525978	
coleval=121952819.15214	
neuroval=309657534	
coleval=505529076.87163	
neuroval=492105660	
coleval=97376486.128088	
neuroval=354966202	
coleval=572753249.28843	
neuroval=440259132	
coleval=616798622.47481	
neuroval=556265436	
coleval=793636555.18501	
neuroval=645365040	
coleval=723033492.84777	
neuroval=650555168	
coleval=3020709448.1352	
neuroval=518165696	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=49792333.296057	
neuroval=441773724	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1327038750	
neuroval=477861308	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1430757254.0657	
neuroval=441625212	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=690153474.76881	
neuroval=486720508	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2486807045.6991	
neuroval=462661996	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=3202192604.1667	
neuroval=418858032	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_42.jpg"
      3 : "t/Pictures/planetarium/ActiOn_82.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_95.jpg"
    }
  2 : 397407464.60154
}
coleval=1900128127.3344	
neuroval=746654378	
coleval=1419747868.2537	
neuroval=549028528	
coleval=3444792992.5696	
neuroval=389109404	
coleval=1464063750	
neuroval=349235550	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=886344375	
neuroval=583550640	
coleval=137331028.60154	
neuroval=260076436	
coleval=469069491.86419	
neuroval=274569156	
coleval=331771362.39991	
neuroval=371257176	
coleval=266086973.07699	
neuroval=384642430	
coleval=1722743680.6663	
neuroval=355481958	
coleval=1855711859.8887	
neuroval=533614866	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=17234682.277642	
neuroval=412899016	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=971782963.17887	
neuroval=398901632	
coleval=997857643.81968	
neuroval=422178568	
coleval=895634816.90376	
neuroval=443079240	
coleval=2125897578.483	
neuroval=386232464	
coleval=1887275439.1708	
neuroval=456813476	
coleval=121952819.15214	
neuroval=309657534	
coleval=2070658486.6492	
neuroval=279070314	
coleval=1995271679.6875	
neuroval=319711650	
coleval=3828351328.125	
neuroval=288445370	
coleval=4014054492.1875	
neuroval=244085106	
coleval=3230301930.4657	
neuroval=296939902	
coleval=97376486.128088	
neuroval=354966202	
coleval=537376825.01853	
neuroval=368464442	
coleval=538547048.34907	
neuroval=273899326	
coleval=3599285625	
neuroval=258885330	
coleval=780686250	
neuroval=322927278	
coleval=804502500	
neuroval=348505022	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=49792333.296057	
neuroval=441773724	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=42538941.717746	
neuroval=401492692	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=252345709.7609	
neuroval=411589124	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=244796943.48486	
neuroval=490202888	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=524720625	
neuroval=633897976	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=585759375	
neuroval=644079616	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_42.jpg"
      3 : "t/Pictures/planetarium/ActiOn_82.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_95.jpg"
    }
  2 : 397407464.60154
}
coleval=2022545625	
neuroval=473721266	
coleval=1376064375	
neuroval=702223064	
coleval=1158620696.5076	
neuroval=534559336	
coleval=968415000	
neuroval=564604944	
coleval=1779866250	
neuroval=446855182	
coleval=137331028.60154	
neuroval=260076436	
coleval=1764017473.735	
neuroval=257118468	
coleval=3239229986.9792	
neuroval=251728988	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1844145000	
neuroval=285273052	
coleval=1810111875	
neuroval=329536996	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=17234682.277642	
neuroval=412899016	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=1316115632.3334	
neuroval=529208068	
coleval=1559240553.3946	
neuroval=567999660	
coleval=1526766491.2434	
neuroval=594278592	
coleval=1264386281.8638	
neuroval=661082432	
coleval=1141856933.9517	
neuroval=707155960	
coleval=121952819.15214	
neuroval=309657534	
coleval=249873485.40729	
neuroval=331855486	
coleval=225036056.55685	
neuroval=401963474	
coleval=314229662.63013	
neuroval=471982170	
coleval=1046709892.5874	
neuroval=426886874	
coleval=1121583682.8124	
neuroval=513583672	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=42538941.717746	
neuroval=401492692	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=56709002.752902	
neuroval=426283416	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=56199669.140551	
neuroval=436107800	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=608878918.11749	
neuroval=441295432	
coleval=848153947.99565	
neuroval=508097536	
coleval=1099117500	
neuroval=513858472	
coleval=97376486.128088	
neuroval=354966202	
coleval=298195832.52876	
neuroval=406231102	
coleval=428546250	
neuroval=446872438	
coleval=924708750	
neuroval=467959998	
coleval=1843644375	
neuroval=406626166	
coleval=1701309375	
neuroval=404381694	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_42.jpg"
      3 : "t/Pictures/planetarium/ActiOn_82.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_95.jpg"
    }
  2 : 397407464.60154
}
coleval=415555497.48987	
neuroval=613374694	
coleval=838878750	
neuroval=372759500	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=2709639124.9557	
neuroval=415276752	
coleval=3279547500	
neuroval=383526156	
coleval=900075000	
neuroval=492688580	
coleval=137331028.60154	
neuroval=260076436	
coleval=196058735.93388	
neuroval=293185196	
coleval=328202331.79977	
neuroval=413275466	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=17234682.277642	
neuroval=412899016	
coleval=800095889.84368	
neuroval=390505368	
coleval=1042875000	
neuroval=375000228	
coleval=886528125	
neuroval=338291108	
coleval=789076875	
neuroval=375123200	
coleval=759652500	
neuroval=336050380	
coleval=121952819.15214	
neuroval=309657534	
coleval=604499708.19359	
neuroval=380366354	
coleval=614428916.61554	
neuroval=437116280	
coleval=427154765.85973	
neuroval=445433272	
coleval=446438367.88726	
neuroval=482884992	
coleval=2644671062.8277	
neuroval=436150120	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=42538941.717746	
neuroval=401492692	
coleval=1581121455.4361	
neuroval=471923164	
coleval=325409487.77894	
neuroval=432439852	
coleval=3392149179.4642	
neuroval=398756824	
coleval=3276948750	
neuroval=471089016	
coleval=3348830625	
neuroval=445096032	
coleval=97376486.128088	
neuroval=354966202	
coleval=158842500	
neuroval=472684538	
coleval=138626250	
neuroval=346330206	
coleval=1001308125	
neuroval=417788066	
coleval=1130638125	
neuroval=389996770	
coleval=1081338750	
neuroval=416056072	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_42.jpg"
      3 : "t/Pictures/planetarium/ActiOn_82.jpg"
      4 : "t/Pictures/planetarium/ActiOn_51.jpg"
      5 : "t/Pictures/planetarium/ActiOn_95.jpg"
    }
  2 : 397407464.60154
}
coleval=2647130462.9847	
neuroval=456426046	
coleval=436479375	
neuroval=444496882	
coleval=541357256.60446	
neuroval=708155624	
coleval=2650726580.6604	
neuroval=506374080	
coleval=3757500312.5	
neuroval=327153922	
coleval=137331028.60154	
neuroval=260076436	
coleval=149092260.34795	
neuroval=377794772	
coleval=329546596.12269	
neuroval=425990998	
coleval=829179170.34144	
neuroval=451392016	
coleval=2233785349.5407	
neuroval=436679808	
coleval=2612984680.5953	
neuroval=464845100	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=17234682.277642	
neuroval=412899016	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=13366875	
neuroval=376634038	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=901074375	
neuroval=382980902	
coleval=862717500	
neuroval=315234680	
coleval=179270625	
neuroval=207036908	
coleval=319719375	
neuroval=264536816	
coleval=121952819.15214	
neuroval=309657534	
coleval=153051431.40914	
neuroval=356020134	
coleval=140892265.55628	
neuroval=363524982	
coleval=378041856.21383	
neuroval=542872266	
coleval=381771144.95081	
neuroval=557311994	
coleval=388692780.85576	
neuroval=570361228	
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
coleval=42538941.717746	
neuroval=401492692	
coleval=374026183.04494	
neuroval=604821004	
coleval=366577500	
neuroval=596807740	
coleval=557831250	
neuroval=361422380	
coleval=531571318.12789	
neuroval=387879028	
coleval=566656933.36227	
neuroval=570978136	
coleval=97376486.128088	
neuroval=354966202	
coleval=2247040523.5165	
neuroval=353752234	
coleval=652404948.15841	
neuroval=431103658	
coleval=2978737974.1071	
neuroval=326218570	
coleval=3038606042.2572	
neuroval=378607526	
coleval=2979183750	
neuroval=411716286	
{
  1 : 
    {
      1 : "t/Pictures/planetarium/ActiOn_45.jpg"
      2 : "t/Pictures/planetarium/ActiOn_90.jpg"
      3 : "t/Pictures/planetarium/ActiOn_62.jpg"
      4 : "t/Pictures/planetarium/ActiOn_52.jpg"
      5 : "t/Pictures/planetarium/ActiOn_61.jpg"
    }
  2 : 386307533
}
selected:	
t/Pictures/planetarium/ActiOn_45.jpg	
t/Pictures/planetarium/ActiOn_90.jpg	
t/Pictures/planetarium/ActiOn_62.jpg	
t/Pictures/planetarium/ActiOn_52.jpg	
t/Pictures/planetarium/ActiOn_61.jpg	
t/Pictures/planetarium/ActiOn_45.jpg,t/Pictures/planetarium/ActiOn_90.jpg,t/Pictures/planetarium/ActiOn_62.jpg,t/Pictures/planetarium/ActiOn_52.jpg,t/Pictures/planetarium/ActiOn_61.jpg	
writing selected	
t/Pictures/planetarium/ActiOn_45.jpg	
t/Pictures/planetarium/ActiOn_90.jpg	
t/Pictures/planetarium/ActiOn_62.jpg	
t/Pictures/planetarium/ActiOn_52.jpg	
t/Pictures/planetarium/ActiOn_61.jpg	
done writing selector	
2425735	
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
Setting up style layer  	2	:	relu1_1	
Setting up style layer  	7	:	relu2_1	
Setting up style layer  	12	:	relu3_1	
Setting up style layer  	21	:	relu4_1	
Setting up content layer	23	:	relu4_2	
Setting up style layer  	30	:	relu5_1	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
WARNING: Skipping content loss	
Running optimization with L-BFGS	
 512
  64
  38
[torch.LongStorage of size 3]

133312329.01917	
<optim.lbfgs> 	creating recyclable direction/step/history buffers	
 512
  64
  38
[torch.LongStorage of size 3]

133312091.0267	
 512
  64
  38
[torch.LongStorage of size 3]

130550794.49997	
 512
  64
  38
[torch.LongStorage of size 3]

88953235.662689	
 512
  64
  38
[torch.LongStorage of size 3]

51877531.289444	
 512
  64
  38
[torch.LongStorage of size 3]

29324246.756592	
 512
  64
  38
[torch.LongStorage of size 3]

14980018.644333	
 512
  64
  38
[torch.LongStorage of size 3]

15349659.497566	
 512
  64
  38
[torch.LongStorage of size 3]

9947718.2265091	
 512
  64
  38
[torch.LongStorage of size 3]

8828448.5808182	
 512
  64
  38
[torch.LongStorage of size 3]

7867046.2257767	
 512
  64
  38
[torch.LongStorage of size 3]

6160866.8914795	
 512
  64
  38
[torch.LongStorage of size 3]

5336372.7539062	
 512
  64
  38
[torch.LongStorage of size 3]

4841461.8873596	
 512
  64
  38
[torch.LongStorage of size 3]

4636140.9659958	
 512
  64
  38
[torch.LongStorage of size 3]

4214852.7527618	
 512
  64
  38
[torch.LongStorage of size 3]

3966617.3303223	
 512
  64
  38
[torch.LongStorage of size 3]

3769074.8727417	
 512
  64
  38
[torch.LongStorage of size 3]

3655243.2249069	
 512
  64
  38
[torch.LongStorage of size 3]

3443731.2324524	
 512
  64
  38
[torch.LongStorage of size 3]

3296828.5185242	
 512
  64
  38
[torch.LongStorage of size 3]

3148956.7259598	
 512
  64
  38
[torch.LongStorage of size 3]

3077711.9865036	
 512
  64
  38
[torch.LongStorage of size 3]

2977181.6522217	
 512
  64
  38
[torch.LongStorage of size 3]

2917351.5572739	
 512
  64
  38
[torch.LongStorage of size 3]

2820131.6077042	
 512
  64
  38
[torch.LongStorage of size 3]

2763566.7834854	
 512
  64
  38
[torch.LongStorage of size 3]

2707420.2949905	
 512
  64
  38
[torch.LongStorage of size 3]

2625219.2020607	
 512
  64
  38
[torch.LongStorage of size 3]

2528889.5588493	
 512
  64
  38
[torch.LongStorage of size 3]

2475708.9673424	
 512
  64
  38
[torch.LongStorage of size 3]

2446617.461586	
 512
  64
  38
[torch.LongStorage of size 3]

2413892.6370811	
 512
  64
  38
[torch.LongStorage of size 3]

2366312.1448326	
 512
  64
  38
[torch.LongStorage of size 3]

2316468.7917137	
 512
  64
  38
[torch.LongStorage of size 3]

2269075.7168961	
 512
  64
  38
[torch.LongStorage of size 3]

2216105.6954765	
 512
  64
  38
[torch.LongStorage of size 3]

2192093.0338478	
 512
  64
  38
[torch.LongStorage of size 3]

2134658.4158707	
 512
  64
  38
[torch.LongStorage of size 3]

2097601.3959312	
 512
  64
  38
[torch.LongStorage of size 3]

2060958.8785744	
 512
  64
  38
[torch.LongStorage of size 3]

2047520.0342751	
 512
  64
  38
[torch.LongStorage of size 3]

2034188.9943695	
 512
  64
  38
[torch.LongStorage of size 3]

2011108.9208984	
 512
  64
  38
[torch.LongStorage of size 3]

1995465.1127625	
 512
  64
  38
[torch.LongStorage of size 3]

1963330.9320068	
 512
  64
  38
[torch.LongStorage of size 3]

1946135.2971268	
 512
  64
  38
[torch.LongStorage of size 3]

1907341.8598175	
 512
  64
  38
[torch.LongStorage of size 3]

1895927.6784897	
 512
  64
  38
[torch.LongStorage of size 3]

1870115.5241966	
 512
  64
  38
[torch.LongStorage of size 3]

1848389.048233	
 512
  64
  38
[torch.LongStorage of size 3]

1829117.1566391	
 512
  64
  38
[torch.LongStorage of size 3]

1818154.8936272	
 512
  64
  38
[torch.LongStorage of size 3]

1804119.9126816	
 512
  64
  38
[torch.LongStorage of size 3]

1785391.5022087	
 512
  64
  38
[torch.LongStorage of size 3]

1769140.0687408	
 512
  64
  38
[torch.LongStorage of size 3]

1753035.7839394	
 512
  64
  38
[torch.LongStorage of size 3]

1735677.6917839	
 512
  64
  38
[torch.LongStorage of size 3]

1719876.6557121	
 512
  64
  38
[torch.LongStorage of size 3]

1709029.9454498	
 512
  64
  38
[torch.LongStorage of size 3]

1695745.561142	
 512
  64
  38
[torch.LongStorage of size 3]

1685940.920105	
 512
  64
  38
[torch.LongStorage of size 3]

1674986.1910248	
 512
  64
  38
[torch.LongStorage of size 3]

1662628.6673737	
 512
  64
  38
[torch.LongStorage of size 3]

1647460.1492882	
 512
  64
  38
[torch.LongStorage of size 3]

1633073.5223198	
 512
  64
  38
[torch.LongStorage of size 3]

1620635.7777596	
 512
  64
  38
[torch.LongStorage of size 3]

1609127.7973175	
 512
  64
  38
[torch.LongStorage of size 3]

1598390.2646255	
 512
  64
  38
[torch.LongStorage of size 3]

1588897.3183441	
 512
  64
  38
[torch.LongStorage of size 3]

1576506.5151978	
 512
  64
  38
[torch.LongStorage of size 3]

1569576.1465454	
 512
  64
  38
[torch.LongStorage of size 3]

1561103.6841583	
 512
  64
  38
[torch.LongStorage of size 3]

1553104.1287422	
 512
  64
  38
[torch.LongStorage of size 3]

1541775.0380516	
 512
  64
  38
[torch.LongStorage of size 3]

1532332.9782486	
 512
  64
  38
[torch.LongStorage of size 3]

1523861.3188362	
 512
  64
  38
[torch.LongStorage of size 3]

1517107.379055	
 512
  64
  38
[torch.LongStorage of size 3]

1508646.4326859	
 512
  64
  38
[torch.LongStorage of size 3]

1502123.4101677	
 512
  64
  38
[torch.LongStorage of size 3]

1492670.2660179	
 512
  64
  38
[torch.LongStorage of size 3]

1487436.6242981	
 512
  64
  38
[torch.LongStorage of size 3]

1480748.1626892	
 512
  64
  38
[torch.LongStorage of size 3]

1471623.9885712	
 512
  64
  38
[torch.LongStorage of size 3]

1461624.962101	
 512
  64
  38
[torch.LongStorage of size 3]

1455135.4516983	
 512
  64
  38
[torch.LongStorage of size 3]

1450514.3610001	
 512
  64
  38
[torch.LongStorage of size 3]

1445709.5115852	
 512
  64
  38
[torch.LongStorage of size 3]

1439436.3907242	
 512
  64
  38
[torch.LongStorage of size 3]

1431966.0549736	
 512
  64
  38
[torch.LongStorage of size 3]

1425019.1903305	
 512
  64
  38
[torch.LongStorage of size 3]

1416169.9795914	
 512
  64
  38
[torch.LongStorage of size 3]

1409342.1712112	
 512
  64
  38
[torch.LongStorage of size 3]

1403698.2944107	
 512
  64
  38
[torch.LongStorage of size 3]

1397659.5821953	
 512
  64
  38
[torch.LongStorage of size 3]

1393336.767807	
 512
  64
  38
[torch.LongStorage of size 3]

1387960.5303955	
 512
  64
  38
[torch.LongStorage of size 3]

1381707.2455788	
 512
  64
  38
[torch.LongStorage of size 3]

1374770.9508133	
 512
  64
  38
[torch.LongStorage of size 3]

1369406.0654449	
 512
  64
  38
[torch.LongStorage of size 3]

1364471.2770271	
 512
  64
  38
[torch.LongStorage of size 3]

1358838.8098335	
 512
  64
  38
[torch.LongStorage of size 3]

1353457.7639008	
 512
  64
  38
[torch.LongStorage of size 3]

1349251.2283325	
 512
  64
  38
[torch.LongStorage of size 3]

1344268.6412811	
 512
  64
  38
[torch.LongStorage of size 3]

1338511.1421013	
 512
  64
  38
[torch.LongStorage of size 3]

1334236.852417	
 512
  64
  38
[torch.LongStorage of size 3]

1330509.0459442	
 512
  64
  38
[torch.LongStorage of size 3]

1325992.3602295	
 512
  64
  38
[torch.LongStorage of size 3]

1319371.1154175	
 512
  64
  38
[torch.LongStorage of size 3]

1317395.8620834	
 512
  64
  38
[torch.LongStorage of size 3]

1311287.252903	
 512
  64
  38
[torch.LongStorage of size 3]

1307820.3127289	
 512
  64
  38
[torch.LongStorage of size 3]

1303842.4556923	
 512
  64
  38
[torch.LongStorage of size 3]

1297729.0219688	
 512
  64
  38
[torch.LongStorage of size 3]

1295171.1958504	
 512
  64
  38
[torch.LongStorage of size 3]

1292794.8465729	
 512
  64
  38
[torch.LongStorage of size 3]

1289363.8030434	
 512
  64
  38
[torch.LongStorage of size 3]

1285080.7923889	
 512
  64
  38
[torch.LongStorage of size 3]

1280696.4321327	
 512
  64
  38
[torch.LongStorage of size 3]

1273714.3258286	
 512
  64
  38
[torch.LongStorage of size 3]

1269967.3097038	
 512
  64
  38
[torch.LongStorage of size 3]

1267461.0030556	
 512
  64
  38
[torch.LongStorage of size 3]

1264682.5577545	
 512
  64
  38
[torch.LongStorage of size 3]

1260955.0981903	
 512
  64
  38
[torch.LongStorage of size 3]

1257167.173233	
 512
  64
  38
[torch.LongStorage of size 3]

1254521.311264	
 512
  64
  38
[torch.LongStorage of size 3]

1251952.6876831	
 512
  64
  38
[torch.LongStorage of size 3]

1247899.8509789	
 512
  64
  38
[torch.LongStorage of size 3]

1244935.2666473	
 512
  64
  38
[torch.LongStorage of size 3]

1241666.6146469	
 512
  64
  38
[torch.LongStorage of size 3]

1239573.8508797	
 512
  64
  38
[torch.LongStorage of size 3]

1237443.995266	
 512
  64
  38
[torch.LongStorage of size 3]

1233622.0121384	
 512
  64
  38
[torch.LongStorage of size 3]

1229113.0729294	
 512
  64
  38
[torch.LongStorage of size 3]

1226453.4004021	
 512
  64
  38
[torch.LongStorage of size 3]

1224008.754673	
 512
  64
  38
[torch.LongStorage of size 3]

1220644.9821472	
 512
  64
  38
[torch.LongStorage of size 3]

1217327.8873253	
 512
  64
  38
[torch.LongStorage of size 3]

1214442.7952003	
 512
  64
  38
[torch.LongStorage of size 3]

1212176.2582588	
 512
  64
  38
[torch.LongStorage of size 3]

1210050.7422447	
 512
  64
  38
[torch.LongStorage of size 3]

1205983.7625313	
 512
  64
  38
[torch.LongStorage of size 3]

1203144.7886086	
 512
  64
  38
[torch.LongStorage of size 3]

1200019.2877007	
 512
  64
  38
[torch.LongStorage of size 3]

1197670.9101677	
 512
  64
  38
[torch.LongStorage of size 3]

1195057.9428291	
 512
  64
  38
[torch.LongStorage of size 3]

1192742.9452324	
 512
  64
  38
[torch.LongStorage of size 3]

1189809.6092224	
 512
  64
  38
[torch.LongStorage of size 3]

1187899.1477585	
 512
  64
  38
[torch.LongStorage of size 3]

1186481.5076256	
 512
  64
  38
[torch.LongStorage of size 3]

1183776.3306808	
 512
  64
  38
[torch.LongStorage of size 3]

1181017.1276093	
 512
  64
  38
[torch.LongStorage of size 3]

1177965.7537651	
 512
  64
  38
[torch.LongStorage of size 3]

1175238.0110741	
 512
  64
  38
[torch.LongStorage of size 3]

1171966.4912224	
 512
  64
  38
[torch.LongStorage of size 3]

1169697.2930908	
 512
  64
  38
[torch.LongStorage of size 3]

1167726.2543678	
 512
  64
  38
[torch.LongStorage of size 3]

1165789.0788078	
 512
  64
  38
[torch.LongStorage of size 3]

1163801.8121529	
 512
  64
  38
[torch.LongStorage of size 3]

1161981.283474	
 512
  64
  38
[torch.LongStorage of size 3]

1159072.0742035	
 512
  64
  38
[torch.LongStorage of size 3]

1158627.2697067	
 512
  64
  38
[torch.LongStorage of size 3]

1154738.4389877	
 512
  64
  38
[torch.LongStorage of size 3]

1153053.2443619	
 512
  64
  38
[torch.LongStorage of size 3]

1151376.2385559	
 512
  64
  38
[torch.LongStorage of size 3]

1150077.3576164	
 512
  64
  38
[torch.LongStorage of size 3]

1148624.9036789	
 512
  64
  38
[torch.LongStorage of size 3]

1146676.1555862	
 512
  64
  38
[torch.LongStorage of size 3]

1144292.3645401	
 512
  64
  38
[torch.LongStorage of size 3]

1142349.9452209	
 512
  64
  38
[torch.LongStorage of size 3]

1140159.5606422	
 512
  64
  38
[torch.LongStorage of size 3]

1137922.2668266	
 512
  64
  38
[torch.LongStorage of size 3]

1136160.7436752	
 512
  64
  38
[torch.LongStorage of size 3]

1134642.9795647	
 512
  64
  38
[torch.LongStorage of size 3]

1133793.9200974	
 512
  64
  38
[torch.LongStorage of size 3]

1132451.3412666	
 512
  64
  38
[torch.LongStorage of size 3]

1129897.2520638	
 512
  64
  38
[torch.LongStorage of size 3]

1127867.9155159	
 512
  64
  38
[torch.LongStorage of size 3]

1125825.794754	
 512
  64
  38
[torch.LongStorage of size 3]

1124012.791214	
 512
  64
  38
[torch.LongStorage of size 3]

1122440.6643295	
 512
  64
  38
[torch.LongStorage of size 3]

1120484.5955086	
 512
  64
  38
[torch.LongStorage of size 3]

1118759.8901176	
 512
  64
  38
[torch.LongStorage of size 3]

1117092.6436806	
 512
  64
  38
[torch.LongStorage of size 3]

1116684.4688034	
 512
  64
  38
[torch.LongStorage of size 3]

1114799.3920326	
 512
  64
  38
[torch.LongStorage of size 3]

1113929.6273232	
 512
  64
  38
[torch.LongStorage of size 3]

1112634.7314835	
 512
  64
  38
[torch.LongStorage of size 3]

1111231.9978142	
 512
  64
  38
[torch.LongStorage of size 3]

1109783.8246155	
 512
  64
  38
[torch.LongStorage of size 3]

1108272.302494	
 512
  64
  38
[torch.LongStorage of size 3]

1106933.969059	
 512
  64
  38
[torch.LongStorage of size 3]

1105108.9629364	
 512
  64
  38
[torch.LongStorage of size 3]

1103026.6275215	
 512
  64
  38
[torch.LongStorage of size 3]

1101511.8470001	
 512
  64
  38
[torch.LongStorage of size 3]

1099945.8295822	
 512
  64
  38
[torch.LongStorage of size 3]

1098715.3198242	
 512
  64
  38
[torch.LongStorage of size 3]

1097625.3876305	
 512
  64
  38
[torch.LongStorage of size 3]

1096471.0849762	
 512
  64
  38
[torch.LongStorage of size 3]

1095410.0587845	
 512
  64
  38
[torch.LongStorage of size 3]

1094256.1343956	
 512
  64
  38
[torch.LongStorage of size 3]

1092517.4539375	
 512
  64
  38
[torch.LongStorage of size 3]

1091004.5078468	
 512
  64
  38
[torch.LongStorage of size 3]

1089440.9109688	
 512
  64
  38
[torch.LongStorage of size 3]

1087995.3199577	
 512
  64
  38
[torch.LongStorage of size 3]

1086563.9331055	
 512
  64
  38
[torch.LongStorage of size 3]

1085205.3387642	
 512
  64
  38
[torch.LongStorage of size 3]

1083961.6280746	
 512
  64
  38
[torch.LongStorage of size 3]

1082958.4794617	
 512
  64
  38
[torch.LongStorage of size 3]

1081592.8908348	
 512
  64
  38
[torch.LongStorage of size 3]

1080383.9869308	
 512
  64
  38
[torch.LongStorage of size 3]

1079279.0500259	
 512
  64
  38
[torch.LongStorage of size 3]

1078163.4905243	
 512
  64
  38
[torch.LongStorage of size 3]

1077326.5218544	
 512
  64
  38
[torch.LongStorage of size 3]

1075861.6474533	
 512
  64
  38
[torch.LongStorage of size 3]

1074447.2963715	
 512
  64
  38
[torch.LongStorage of size 3]

1073210.9573936	
 512
  64
  38
[torch.LongStorage of size 3]

1072009.9432373	
 512
  64
  38
[torch.LongStorage of size 3]

1070863.2261086	
 512
  64
  38
[torch.LongStorage of size 3]

1070000.7413292	
 512
  64
  38
[torch.LongStorage of size 3]

1068839.0877724	
 512
  64
  38
[torch.LongStorage of size 3]

1067823.0571747	
 512
  64
  38
[torch.LongStorage of size 3]

1066665.4316521	
 512
  64
  38
[torch.LongStorage of size 3]

1065744.2637825	
 512
  64
  38
[torch.LongStorage of size 3]

1064450.9944344	
 512
  64
  38
[torch.LongStorage of size 3]

1062955.6258583	
 512
  64
  38
[torch.LongStorage of size 3]

1061876.6223145	
 512
  64
  38
[torch.LongStorage of size 3]

1060978.8044548	
 512
  64
  38
[torch.LongStorage of size 3]

1060136.3934708	
 512
  64
  38
[torch.LongStorage of size 3]

1059176.871376	
 512
  64
  38
[torch.LongStorage of size 3]

1058223.62463	
 512
  64
  38
[torch.LongStorage of size 3]

1057306.7003822	
 512
  64
  38
[torch.LongStorage of size 3]

1056320.1110077	
 512
  64
  38
[torch.LongStorage of size 3]

1055373.9406967	
 512
  64
  38
[torch.LongStorage of size 3]

1054250.9882545	
 512
  64
  38
[torch.LongStorage of size 3]

1053135.5615807	
 512
  64
  38
[torch.LongStorage of size 3]

1052046.8352699	
 512
  64
  38
[torch.LongStorage of size 3]

1050948.9171219	
 512
  64
  38
[torch.LongStorage of size 3]

1049997.0762444	
 512
  64
  38
[torch.LongStorage of size 3]

1049011.8643379	
 512
  64
  38
[torch.LongStorage of size 3]

1048033.3275604	
 512
  64
  38
[torch.LongStorage of size 3]

1046775.8445168	
 512
  64
  38
[torch.LongStorage of size 3]

1045640.4260635	
 512
  64
  38
[torch.LongStorage of size 3]

1044885.3382111	
 512
  64
  38
[torch.LongStorage of size 3]

1043819.8697472	
 512
  64
  38
[torch.LongStorage of size 3]

1042594.4332504	
 512
  64
  38
[torch.LongStorage of size 3]

1041142.8355789	
 512
  64
  38
[torch.LongStorage of size 3]

1040157.3058891	
 512
  64
  38
[torch.LongStorage of size 3]

1039692.1624374	
 512
  64
  38
[torch.LongStorage of size 3]

1038745.9479332	
 512
  64
  38
[torch.LongStorage of size 3]

1038027.6548004	
 512
  64
  38
[torch.LongStorage of size 3]

1036336.0439491	
 512
  64
  38
[torch.LongStorage of size 3]

1035567.52985	
 512
  64
  38
[torch.LongStorage of size 3]

1034772.1643448	
 512
  64
  38
[torch.LongStorage of size 3]

1034023.2110214	
 512
  64
  38
[torch.LongStorage of size 3]

1033522.5559998	
 512
  64
  38
[torch.LongStorage of size 3]

1032393.4225082	
 512
  64
  38
[torch.LongStorage of size 3]

1031204.3703842	
 512
  64
  38
[torch.LongStorage of size 3]

1030260.3103065	
 512
  64
  38
[torch.LongStorage of size 3]

1029640.6985092	
 512
  64
  38
[torch.LongStorage of size 3]

1028658.2198334	
 512
  64
  38
[torch.LongStorage of size 3]

1027776.35355	
 512
  64
  38
[torch.LongStorage of size 3]

1026974.3315887	
 512
  64
  38
[torch.LongStorage of size 3]

1026079.2245483	
 512
  64
  38
[torch.LongStorage of size 3]

1025403.2195854	
 512
  64
  38
[torch.LongStorage of size 3]

1024529.3147659	
 512
  64
  38
[torch.LongStorage of size 3]

1023672.7920151	
 512
  64
  38
[torch.LongStorage of size 3]

1022824.3001556	
 512
  64
  38
[torch.LongStorage of size 3]

1022290.0483322	
 512
  64
  38
[torch.LongStorage of size 3]

1021376.2250519	
 512
  64
  38
[torch.LongStorage of size 3]

1020677.4643135	
 512
  64
  38
[torch.LongStorage of size 3]

1019794.3406677	
 512
  64
  38
[torch.LongStorage of size 3]

1018978.5131645	
 512
  64
  38
[torch.LongStorage of size 3]

1018408.4090042	
 512
  64
  38
[torch.LongStorage of size 3]

1017655.2088165	
 512
  64
  38
[torch.LongStorage of size 3]

1016836.800518	
 512
  64
  38
[torch.LongStorage of size 3]

1016187.1104622	
 512
  64
  38
[torch.LongStorage of size 3]

1015227.1821213	
 512
  64
  38
[torch.LongStorage of size 3]

1014551.5221214	
 512
  64
  38
[torch.LongStorage of size 3]

1013865.3303719	
 512
  64
  38
[torch.LongStorage of size 3]

1013329.0660667	
 512
  64
  38
[torch.LongStorage of size 3]

1012951.0111809	
 512
  64
  38
[torch.LongStorage of size 3]

1012191.8977356	
 512
  64
  38
[torch.LongStorage of size 3]

1011386.3079643	
 512
  64
  38
[torch.LongStorage of size 3]

1010320.0438499	
 512
  64
  38
[torch.LongStorage of size 3]

1009567.4435043	
 512
  64
  38
[torch.LongStorage of size 3]

1009163.4369659	
 512
  64
  38
[torch.LongStorage of size 3]

1008644.0448952	
 512
  64
  38
[torch.LongStorage of size 3]

1007940.4861069	
 512
  64
  38
[torch.LongStorage of size 3]

1007122.4522781	
 512
  64
  38
[torch.LongStorage of size 3]

1006654.8867226	
 512
  64
  38
[torch.LongStorage of size 3]

1005889.6777725	
 512
  64
  38
[torch.LongStorage of size 3]

1005551.6348648	
 512
  64
  38
[torch.LongStorage of size 3]

1004959.172554	
 512
  64
  38
[torch.LongStorage of size 3]

1004103.1162453	
 512
  64
  38
[torch.LongStorage of size 3]

1003140.9407997	
 512
  64
  38
[torch.LongStorage of size 3]

1002440.6395531	
 512
  64
  38
[torch.LongStorage of size 3]

1001862.9467201	
 512
  64
  38
[torch.LongStorage of size 3]

1001120.6807518	
 512
  64
  38
[torch.LongStorage of size 3]

1000402.6561737	
 512
  64
  38
[torch.LongStorage of size 3]

999719.65053558	
 512
  64
  38
[torch.LongStorage of size 3]

999145.36781311	
 512
  64
  38
[torch.LongStorage of size 3]

998155.05235672	
 512
  64
  38
[torch.LongStorage of size 3]

997536.86441422	
 512
  64
  38
[torch.LongStorage of size 3]

996979.93814468	
 512
  64
  38
[torch.LongStorage of size 3]

996564.63661194	
 512
  64
  38
[torch.LongStorage of size 3]

996090.85327148	
 512
  64
  38
[torch.LongStorage of size 3]

995282.91395187	
 512
  64
  38
[torch.LongStorage of size 3]

994438.31224442	
 512
  64
  38
[torch.LongStorage of size 3]

993829.40290451	
 512
  64
  38
[torch.LongStorage of size 3]

993428.00735474	
 512
  64
  38
[torch.LongStorage of size 3]

992954.43302155	
 512
  64
  38
[torch.LongStorage of size 3]

992297.05226898	
 512
  64
  38
[torch.LongStorage of size 3]

991451.48704529	
 512
  64
  38
[torch.LongStorage of size 3]

990952.35286713	
 512
  64
  38
[torch.LongStorage of size 3]

990489.88073349	
 512
  64
  38
[torch.LongStorage of size 3]

990019.63941574	
 512
  64
  38
[torch.LongStorage of size 3]

989490.36331177	
 512
  64
  38
[torch.LongStorage of size 3]

988648.11594009	
 512
  64
  38
[torch.LongStorage of size 3]

987930.52778244	
 512
  64
  38
[torch.LongStorage of size 3]

987533.61776352	
 512
  64
  38
[torch.LongStorage of size 3]

987111.57588959	
 512
  64
  38
[torch.LongStorage of size 3]

986392.5945282	
 512
  64
  38
[torch.LongStorage of size 3]

985738.94556046	
 512
  64
  38
[torch.LongStorage of size 3]

985237.99606323	
 512
  64
  38
[torch.LongStorage of size 3]

984875.37265778	
 512
  64
  38
[torch.LongStorage of size 3]

984466.37937546	
 512
  64
  38
[torch.LongStorage of size 3]

983947.38559723	
 512
  64
  38
[torch.LongStorage of size 3]

983366.4825058	
 512
  64
  38
[torch.LongStorage of size 3]

982871.0691452	
 512
  64
  38
[torch.LongStorage of size 3]

982368.47560883	
 512
  64
  38
[torch.LongStorage of size 3]

981971.81110382	
Iteration 333 / 1000	
  Content 1 loss: 800216.015625	
  Style 1 loss: 7752.930450	
  Style 2 loss: 20547.906494	
  Style 3 loss: 8638.028717	
  Style 4 loss: 143844.018555	
  Style 5 loss: 972.911263	
  Total loss: 981971.811104	
s/1f8C5Gj.jpg_out_prepost_333.png	
 512
  64
  38
[torch.LongStorage of size 3]

981313.98326874	
 512
  64
  38
[torch.LongStorage of size 3]

980913.12944412	
 512
  64
  38
[torch.LongStorage of size 3]

980510.51401138	
 512
  64
  38
[torch.LongStorage of size 3]

979845.39890289	
 512
  64
  38
[torch.LongStorage of size 3]

979208.3147049	
 512
  64
  38
[torch.LongStorage of size 3]

978755.48513412	
 512
  64
  38
[torch.LongStorage of size 3]

978323.50641251	
 512
  64
  38
[torch.LongStorage of size 3]

977852.51285553	
 512
  64
  38
[torch.LongStorage of size 3]

977305.16111374	
 512
  64
  38
[torch.LongStorage of size 3]

976695.99132538	
 512
  64
  38
[torch.LongStorage of size 3]

976286.28501892	
 512
  64
  38
[torch.LongStorage of size 3]

975869.22300339	
 512
  64
  38
[torch.LongStorage of size 3]

975078.70857239	
 512
  64
  38
[torch.LongStorage of size 3]

974540.19508362	
 512
  64
  38
[torch.LongStorage of size 3]

974228.34035873	
 512
  64
  38
[torch.LongStorage of size 3]

973842.26964951	
 512
  64
  38
[torch.LongStorage of size 3]

973354.79478836	
 512
  64
  38
[torch.LongStorage of size 3]

972862.39952087	
 512
  64
  38
[torch.LongStorage of size 3]

972449.72787857	
 512
  64
  38
[torch.LongStorage of size 3]

971925.04716873	
 512
  64
  38
[torch.LongStorage of size 3]

971468.25586319	
 512
  64
  38
[torch.LongStorage of size 3]

971106.87465668	
 512
  64
  38
[torch.LongStorage of size 3]

970696.39665604	
 512
  64
  38
[torch.LongStorage of size 3]

970213.33381653	
 512
  64
  38
[torch.LongStorage of size 3]

969754.08779144	
 512
  64
  38
[torch.LongStorage of size 3]

969093.93051147	
 512
  64
  38
[torch.LongStorage of size 3]

968571.5574646	
 512
  64
  38
[torch.LongStorage of size 3]

968264.27818298	
 512
  64
  38
[torch.LongStorage of size 3]

968031.79876328	
 512
  64
  38
[torch.LongStorage of size 3]

967546.79050446	
 512
  64
  38
[torch.LongStorage of size 3]

967116.34548187	
 512
  64
  38
[torch.LongStorage of size 3]

966781.01400375	
 512
  64
  38
[torch.LongStorage of size 3]

966420.57878494	
 512
  64
  38
[torch.LongStorage of size 3]

966208.89621735	
 512
  64
  38
[torch.LongStorage of size 3]

965845.27345657	
 512
  64
  38
[torch.LongStorage of size 3]

965326.43728256	
 512
  64
  38
[torch.LongStorage of size 3]

964881.40001297	
 512
  64
  38
[torch.LongStorage of size 3]

964522.304039	
 512
  64
  38
[torch.LongStorage of size 3]

964170.73869705	
 512
  64
  38
[torch.LongStorage of size 3]

963617.03008652	
 512
  64
  38
[torch.LongStorage of size 3]

963167.8985405	
 512
  64
  38
[torch.LongStorage of size 3]

962859.04182434	
 512
  64
  38
[torch.LongStorage of size 3]

962526.91093445	
 512
  64
  38
[torch.LongStorage of size 3]

962161.52076721	
 512
  64
  38
[torch.LongStorage of size 3]

961816.66934967	
 512
  64
  38
[torch.LongStorage of size 3]

961467.69453049	
 512
  64
  38
[torch.LongStorage of size 3]

961067.45185852	
 512
  64
  38
[torch.LongStorage of size 3]

960692.87269592	
 512
  64
  38
[torch.LongStorage of size 3]

960387.00775146	
 512
  64
  38
[torch.LongStorage of size 3]

959987.31964111	
 512
  64
  38
[torch.LongStorage of size 3]

959521.52927399	
 512
  64
  38
[torch.LongStorage of size 3]

959148.41833115	
 512
  64
  38
[torch.LongStorage of size 3]

958980.2230835	
 512
  64
  38
[torch.LongStorage of size 3]

958699.19424057	
 512
  64
  38
[torch.LongStorage of size 3]

958285.55557251	
 512
  64
  38
[torch.LongStorage of size 3]

957894.29271698	
 512
  64
  38
[torch.LongStorage of size 3]

957596.84865952	
 512
  64
  38
[torch.LongStorage of size 3]

957167.06485748	
 512
  64
  38
[torch.LongStorage of size 3]

956717.46135712	
 512
  64
  38
[torch.LongStorage of size 3]

956423.48697662	
 512
  64
  38
[torch.LongStorage of size 3]

956181.24977112	
 512
  64
  38
[torch.LongStorage of size 3]

955936.42532349	
 512
  64
  38
[torch.LongStorage of size 3]

955583.92316818	
 512
  64
  38
[torch.LongStorage of size 3]

955225.431633	
 512
  64
  38
[torch.LongStorage of size 3]

954815.95491409	
 512
  64
  38
[torch.LongStorage of size 3]

954516.93460464	
 512
  64
  38
[torch.LongStorage of size 3]

954247.24479675	
 512
  64
  38
[torch.LongStorage of size 3]

953854.22677994	
 512
  64
  38
[torch.LongStorage of size 3]

953603.37110519	
 512
  64
  38
[torch.LongStorage of size 3]

953377.00841904	
 512
  64
  38
[torch.LongStorage of size 3]

953090.2630806	
 512
  64
  38
[torch.LongStorage of size 3]

952830.05277634	
 512
  64
  38
[torch.LongStorage of size 3]

952515.73400497	
 512
  64
  38
[torch.LongStorage of size 3]

952183.5292244	
 512
  64
  38
[torch.LongStorage of size 3]

951900.68769455	
 512
  64
  38
[torch.LongStorage of size 3]

951596.55481339	
 512
  64
  38
[torch.LongStorage of size 3]

951146.00637436	
 512
  64
  38
[torch.LongStorage of size 3]

950751.67739868	
 512
  64
  38
[torch.LongStorage of size 3]

950607.6766777	
 512
  64
  38
[torch.LongStorage of size 3]

950360.37532806	
 512
  64
  38
[torch.LongStorage of size 3]

949992.42370605	
 512
  64
  38
[torch.LongStorage of size 3]

949615.94997406	
 512
  64
  38
[torch.LongStorage of size 3]

949324.07218933	
 512
  64
  38
[torch.LongStorage of size 3]

949034.31936264	
 512
  64
  38
[torch.LongStorage of size 3]

948767.08381653	
 512
  64
  38
[torch.LongStorage of size 3]

948547.97704697	
 512
  64
  38
[torch.LongStorage of size 3]

948319.11224365	
 512
  64
  38
[torch.LongStorage of size 3]

948086.03713989	
 512
  64
  38
[torch.LongStorage of size 3]

947829.8286438	
 512
  64
  38
[torch.LongStorage of size 3]

947462.74404526	
 512
  64
  38
[torch.LongStorage of size 3]

947279.97907639	
 512
  64
  38
[torch.LongStorage of size 3]

947101.79103851	
 512
  64
  38
[torch.LongStorage of size 3]

946615.15241623	
 512
  64
  38
[torch.LongStorage of size 3]

946425.45238495	
 512
  64
  38
[torch.LongStorage of size 3]

946253.74233246	
 512
  64
  38
[torch.LongStorage of size 3]

946053.84336472	
 512
  64
  38
[torch.LongStorage of size 3]

945876.68767929	
 512
  64
  38
[torch.LongStorage of size 3]

945633.91628265	
 512
  64
  38
[torch.LongStorage of size 3]

945294.57906723	
 512
  64
  38
[torch.LongStorage of size 3]

945097.30157852	
 512
  64
  38
[torch.LongStorage of size 3]

944962.96930313	
 512
  64
  38
[torch.LongStorage of size 3]

944596.38809204	
 512
  64
  38
[torch.LongStorage of size 3]

944354.54053879	
 512
  64
  38
[torch.LongStorage of size 3]

944166.9383812	
 512
  64
  38
[torch.LongStorage of size 3]

943972.28837967	
 512
  64
  38
[torch.LongStorage of size 3]

943828.39487076	
 512
  64
  38
[torch.LongStorage of size 3]

943481.15118027	
 512
  64
  38
[torch.LongStorage of size 3]

943384.12799835	
 512
  64
  38
[torch.LongStorage of size 3]

943152.91288376	
 512
  64
  38
[torch.LongStorage of size 3]

943067.15166092	
 512
  64
  38
[torch.LongStorage of size 3]

942915.20614624	
 512
  64
  38
[torch.LongStorage of size 3]

942635.39905548	
 512
  64
  38
[torch.LongStorage of size 3]

942377.21790314	
 512
  64
  38
[torch.LongStorage of size 3]

942188.39298248	
 512
  64
  38
[torch.LongStorage of size 3]

941947.62102127	
 512
  64
  38
[torch.LongStorage of size 3]

941753.3272934	
 512
  64
  38
[torch.LongStorage of size 3]

941527.98316956	
 512
  64
  38
[torch.LongStorage of size 3]

941262.42841721	
 512
  64
  38
[torch.LongStorage of size 3]

941056.8920517	
 512
  64
  38
[torch.LongStorage of size 3]

940856.36154175	
 512
  64
  38
[torch.LongStorage of size 3]

940730.93503952	
 512
  64
  38
[torch.LongStorage of size 3]

940541.73742294	
 512
  64
  38
[torch.LongStorage of size 3]

940293.88168335	
 512
  64
  38
[torch.LongStorage of size 3]

940019.95475769	
 512
  64
  38
[torch.LongStorage of size 3]

939811.40935898	
 512
  64
  38
[torch.LongStorage of size 3]

939543.03016663	
 512
  64
  38
[torch.LongStorage of size 3]

939315.61073303	
 512
  64
  38
[torch.LongStorage of size 3]

939137.21191406	
 512
  64
  38
[torch.LongStorage of size 3]

938916.68697357	
 512
  64
  38
[torch.LongStorage of size 3]

938731.7073822	
 512
  64
  38
[torch.LongStorage of size 3]

938524.12244797	
 512
  64
  38
[torch.LongStorage of size 3]

938379.20743942	
 512
  64
  38
[torch.LongStorage of size 3]

938217.49124527	
 512
  64
  38
[torch.LongStorage of size 3]

937952.38138199	
 512
  64
  38
[torch.LongStorage of size 3]

937669.66777802	
 512
  64
  38
[torch.LongStorage of size 3]

937542.48718262	
 512
  64
  38
[torch.LongStorage of size 3]

937441.48336411	
 512
  64
  38
[torch.LongStorage of size 3]

937205.73265076	
 512
  64
  38
[torch.LongStorage of size 3]

936962.88612366	
 512
  64
  38
[torch.LongStorage of size 3]

936795.20875931	
 512
  64
  38
[torch.LongStorage of size 3]

936691.40743256	
 512
  64
  38
[torch.LongStorage of size 3]

936574.31640625	
 512
  64
  38
[torch.LongStorage of size 3]

936415.6902504	
 512
  64
  38
[torch.LongStorage of size 3]

936256.71253204	
 512
  64
  38
[torch.LongStorage of size 3]

936032.52674103	
 512
  64
  38
[torch.LongStorage of size 3]

935763.15605164	
 512
  64
  38
[torch.LongStorage of size 3]

935599.36029434	
 512
  64
  38
[torch.LongStorage of size 3]

935464.50309753	
 512
  64
  38
[torch.LongStorage of size 3]

935261.50415421	
 512
  64
  38
[torch.LongStorage of size 3]

935045.93719482	
 512
  64
  38
[torch.LongStorage of size 3]

934881.30250931	
 512
  64
  38
[torch.LongStorage of size 3]

934724.02418137	
 512
  64
  38
[torch.LongStorage of size 3]

934529.35930252	
 512
  64
  38
[torch.LongStorage of size 3]

934330.68691254	
 512
  64
  38
[torch.LongStorage of size 3]

934188.00378799	
 512
  64
  38
[torch.LongStorage of size 3]

934047.60002136	
 512
  64
  38
[torch.LongStorage of size 3]

933855.25657654	
 512
  64
  38
[torch.LongStorage of size 3]

933682.52534866	
 512
  64
  38
[torch.LongStorage of size 3]

933531.3275528	
 512
  64
  38
[torch.LongStorage of size 3]

933393.37516785	
 512
  64
  38
[torch.LongStorage of size 3]

933265.59871674	
 512
  64
  38
[torch.LongStorage of size 3]

933094.34373856	
 512
  64
  38
[torch.LongStorage of size 3]

932877.93149948	
 512
  64
  38
[torch.LongStorage of size 3]

932730.9907341	
 512
  64
  38
[torch.LongStorage of size 3]

932622.21506119	
 512
  64
  38
[torch.LongStorage of size 3]

932435.41431427	
 512
  64
  38
[torch.LongStorage of size 3]

932236.08411789	
 512
  64
  38
[torch.LongStorage of size 3]

932119.77294922	
 512
  64
  38
[torch.LongStorage of size 3]

932026.08007431	
 512
  64
  38
[torch.LongStorage of size 3]

931871.59824371	
 512
  64
  38
[torch.LongStorage of size 3]

931690.23538589	
 512
  64
  38
[torch.LongStorage of size 3]

931519.16526794	
 512
  64
  38
[torch.LongStorage of size 3]

931363.57484818	
 512
  64
  38
[torch.LongStorage of size 3]

931207.76903152	
 512
  64
  38
[torch.LongStorage of size 3]

931051.48048401	
 512
  64
  38
[torch.LongStorage of size 3]

930878.28355789	
 512
  64
  38
[torch.LongStorage of size 3]

930695.42636871	
 512
  64
  38
[torch.LongStorage of size 3]

930570.89839935	
 512
  64
  38
[torch.LongStorage of size 3]

930425.34820557	
 512
  64
  38
[torch.LongStorage of size 3]

930295.08571625	
 512
  64
  38
[torch.LongStorage of size 3]

930164.7845459	
 512
  64
  38
[torch.LongStorage of size 3]

930007.46303558	
 512
  64
  38
[torch.LongStorage of size 3]

929880.36165237	
 512
  64
  38
[torch.LongStorage of size 3]

929756.14776611	
 512
  64
  38
[torch.LongStorage of size 3]

929630.72650909	
 512
  64
  38
[torch.LongStorage of size 3]

929499.14318085	
 512
  64
  38
[torch.LongStorage of size 3]

929333.15935135	
 512
  64
  38
[torch.LongStorage of size 3]

929181.78253174	
 512
  64
  38
[torch.LongStorage of size 3]

929049.86803055	
 512
  64
  38
[torch.LongStorage of size 3]

928945.24278641	
 512
  64
  38
[torch.LongStorage of size 3]

928751.76355362	
 512
  64
  38
[torch.LongStorage of size 3]

928607.4495697	
 512
  64
  38
[torch.LongStorage of size 3]

928485.62229156	
 512
  64
  38
[torch.LongStorage of size 3]

928374.1557312	
 512
  64
  38
[torch.LongStorage of size 3]

928242.56959915	
 512
  64
  38
[torch.LongStorage of size 3]

928107.80714035	
 512
  64
  38
[torch.LongStorage of size 3]

927989.67147827	
 512
  64
  38
[torch.LongStorage of size 3]

927903.01956177	
 512
  64
  38
[torch.LongStorage of size 3]

927770.15867233	
 512
  64
  38
[torch.LongStorage of size 3]

927652.87425995	
 512
  64
  38
[torch.LongStorage of size 3]

927552.49685287	
 512
  64
  38
[torch.LongStorage of size 3]

927413.07329178	
 512
  64
  38
[torch.LongStorage of size 3]

927302.69910812	
 512
  64
  38
[torch.LongStorage of size 3]

927171.04221344	
 512
  64
  38
[torch.LongStorage of size 3]

926994.08519745	
 512
  64
  38
[torch.LongStorage of size 3]

926838.02436829	
 512
  64
  38
[torch.LongStorage of size 3]

926719.0290451	
 512
  64
  38
[torch.LongStorage of size 3]

926633.34667206	
 512
  64
  38
[torch.LongStorage of size 3]

926547.15665817	
 512
  64
  38
[torch.LongStorage of size 3]

926445.62746048	
 512
  64
  38
[torch.LongStorage of size 3]

926341.2745285	
 512
  64
  38
[torch.LongStorage of size 3]

926187.07193375	
 512
  64
  38
[torch.LongStorage of size 3]

926078.17728043	
 512
  64
  38
[torch.LongStorage of size 3]

925989.43361282	
 512
  64
  38
[torch.LongStorage of size 3]

925835.36249161	
 512
  64
  38
[torch.LongStorage of size 3]

925679.67788696	
 512
  64
  38
[torch.LongStorage of size 3]

925547.64888763	
 512
  64
  38
[torch.LongStorage of size 3]

925429.8559761	
 512
  64
  38
[torch.LongStorage of size 3]

925325.60689926	
 512
  64
  38
[torch.LongStorage of size 3]

925203.31565857	
 512
  64
  38
[torch.LongStorage of size 3]

925087.34661102	
 512
  64
  38
[torch.LongStorage of size 3]

924980.81165314	
 512
  64
  38
[torch.LongStorage of size 3]

924885.75368881	
 512
  64
  38
[torch.LongStorage of size 3]

924791.40737534	
 512
  64
  38
[torch.LongStorage of size 3]

924666.80734634	
 512
  64
  38
[torch.LongStorage of size 3]

924532.18982697	
 512
  64
  38
[torch.LongStorage of size 3]

924426.27441406	
 512
  64
  38
[torch.LongStorage of size 3]

924325.66747665	
 512
  64
  38
[torch.LongStorage of size 3]

924184.64208603	
 512
  64
  38
[torch.LongStorage of size 3]

924082.97584534	
 512
  64
  38
[torch.LongStorage of size 3]

923996.55031204	
 512
  64
  38
[torch.LongStorage of size 3]

923885.57937622	
 512
  64
  38
[torch.LongStorage of size 3]

923769.40353394	
 512
  64
  38
[torch.LongStorage of size 3]

923649.15985107	
 512
  64
  38
[torch.LongStorage of size 3]

923522.96728134	
 512
  64
  38
[torch.LongStorage of size 3]

923399.32237625	
 512
  64
  38
[torch.LongStorage of size 3]

923276.58285141	
 512
  64
  38
[torch.LongStorage of size 3]

923141.56526566	
 512
  64
  38
[torch.LongStorage of size 3]

923000.96914291	
 512
  64
  38
[torch.LongStorage of size 3]

922916.3593483	
 512
  64
  38
[torch.LongStorage of size 3]

922838.69041443	
 512
  64
  38
[torch.LongStorage of size 3]

922741.70383453	
 512
  64
  38
[torch.LongStorage of size 3]

922629.16259766	
 512
  64
  38
[torch.LongStorage of size 3]

922487.17535019	
 512
  64
  38
[torch.LongStorage of size 3]

922393.06375504	
 512
  64
  38
[torch.LongStorage of size 3]

922325.49320221	
 512
  64
  38
[torch.LongStorage of size 3]

922200.69662094	
 512
  64
  38
[torch.LongStorage of size 3]

922073.7097168	
 512
  64
  38
[torch.LongStorage of size 3]

921968.4608078	
 512
  64
  38
[torch.LongStorage of size 3]

921900.15399933	
 512
  64
  38
[torch.LongStorage of size 3]

921845.7482338	
 512
  64
  38
[torch.LongStorage of size 3]

921761.43651962	
 512
  64
  38
[torch.LongStorage of size 3]

921617.15965271	
 512
  64
  38
[torch.LongStorage of size 3]

921497.88770676	
 512
  64
  38
[torch.LongStorage of size 3]

921397.91604996	
 512
  64
  38
[torch.LongStorage of size 3]

921326.93414688	
 512
  64
  38
[torch.LongStorage of size 3]

921211.65513992	
 512
  64
  38
[torch.LongStorage of size 3]

921084.84558105	
 512
  64
  38
[torch.LongStorage of size 3]

920969.95716095	
 512
  64
  38
[torch.LongStorage of size 3]

920868.9572525	
 512
  64
  38
[torch.LongStorage of size 3]

920782.38269806	
 512
  64
  38
[torch.LongStorage of size 3]

920685.5575943	
 512
  64
  38
[torch.LongStorage of size 3]

920572.74496078	
 512
  64
  38
[torch.LongStorage of size 3]

920487.46194839	
 512
  64
  38
[torch.LongStorage of size 3]

920413.96852493	
 512
  64
  38
[torch.LongStorage of size 3]

920320.44736862	
 512
  64
  38
[torch.LongStorage of size 3]

920208.02108765	
 512
  64
  38
[torch.LongStorage of size 3]

920098.77077103	
 512
  64
  38
[torch.LongStorage of size 3]

920015.92168808	
 512
  64
  38
[torch.LongStorage of size 3]

919917.72565842	
 512
  64
  38
[torch.LongStorage of size 3]

919828.05500031	
 512
  64
  38
[torch.LongStorage of size 3]

919746.18703842	
 512
  64
  38
[torch.LongStorage of size 3]

919661.90954208	
 512
  64
  38
[torch.LongStorage of size 3]

919563.50784302	
 512
  64
  38
[torch.LongStorage of size 3]

919451.0367775	
 512
  64
  38
[torch.LongStorage of size 3]

919338.51642609	
 512
  64
  38
[torch.LongStorage of size 3]

919207.52700806	
 512
  64
  38
[torch.LongStorage of size 3]

919113.98292542	
 512
  64
  38
[torch.LongStorage of size 3]

919032.39830017	
 512
  64
  38
[torch.LongStorage of size 3]

918938.67343903	
 512
  64
  38
[torch.LongStorage of size 3]

918812.95694351	
 512
  64
  38
[torch.LongStorage of size 3]

918709.59623337	
 512
  64
  38
[torch.LongStorage of size 3]

918607.8704071	
 512
  64
  38
[torch.LongStorage of size 3]

918532.29585648	
 512
  64
  38
[torch.LongStorage of size 3]

918462.52147675	
 512
  64
  38
[torch.LongStorage of size 3]

918396.40766144	
 512
  64
  38
[torch.LongStorage of size 3]

918320.65864563	
 512
  64
  38
[torch.LongStorage of size 3]

918227.20674515	
 512
  64
  38
[torch.LongStorage of size 3]

918147.88833618	
 512
  64
  38
[torch.LongStorage of size 3]

918075.34955978	
 512
  64
  38
[torch.LongStorage of size 3]

917962.10390091	
 512
  64
  38
[torch.LongStorage of size 3]

917826.12888336	
 512
  64
  38
[torch.LongStorage of size 3]

917731.68685913	
 512
  64
  38
[torch.LongStorage of size 3]

917674.40036774	
 512
  64
  38
[torch.LongStorage of size 3]

917606.63747787	
 512
  64
  38
[torch.LongStorage of size 3]

917524.75658417	
 512
  64
  38
[torch.LongStorage of size 3]

917439.04163361	
 512
  64
  38
[torch.LongStorage of size 3]

917353.80754471	
 512
  64
  38
[torch.LongStorage of size 3]

917289.50958252	
 512
  64
  38
[torch.LongStorage of size 3]

917233.99383545	
 512
  64
  38
[torch.LongStorage of size 3]

917123.08252335	
 512
  64
  38
[torch.LongStorage of size 3]

917049.59169388	
 512
  64
  38
[torch.LongStorage of size 3]

916969.85408783	
 512
  64
  38
[torch.LongStorage of size 3]

916866.92676544	
 512
  64
  38
[torch.LongStorage of size 3]

916781.15283966	
 512
  64
  38
[torch.LongStorage of size 3]

916705.55971146	
 512
  64
  38
[torch.LongStorage of size 3]

916630.45909882	
 512
  64
  38
[torch.LongStorage of size 3]

916539.51404572	
 512
  64
  38
[torch.LongStorage of size 3]

916465.21060944	
 512
  64
  38
[torch.LongStorage of size 3]

916389.21613693	
 512
  64
  38
[torch.LongStorage of size 3]

916276.6636467	
 512
  64
  38
[torch.LongStorage of size 3]

916217.970047	
 512
  64
  38
[torch.LongStorage of size 3]

916142.74642944	
 512
  64
  38
[torch.LongStorage of size 3]

916079.9413681	
 512
  64
  38
[torch.LongStorage of size 3]

916029.92673874	
 512
  64
  38
[torch.LongStorage of size 3]

915921.03530884	
 512
  64
  38
[torch.LongStorage of size 3]

915841.76965714	
 512
  64
  38
[torch.LongStorage of size 3]

915774.80484009	
 512
  64
  38
[torch.LongStorage of size 3]

915717.4700737	
 512
  64
  38
[torch.LongStorage of size 3]

915634.07440186	
 512
  64
  38
[torch.LongStorage of size 3]

915524.03776169	
 512
  64
  38
[torch.LongStorage of size 3]

915447.58769989	
 512
  64
  38
[torch.LongStorage of size 3]

915397.61957169	
 512
  64
  38
[torch.LongStorage of size 3]

915308.7024498	
 512
  64
  38
[torch.LongStorage of size 3]

915213.50822449	
 512
  64
  38
[torch.LongStorage of size 3]

915132.6820755	
 512
  64
  38
[torch.LongStorage of size 3]

915066.73765182	
 512
  64
  38
[torch.LongStorage of size 3]

915002.95879364	
 512
  64
  38
[torch.LongStorage of size 3]

914918.61049652	
 512
  64
  38
[torch.LongStorage of size 3]

914818.77534866	
 512
  64
  38
[torch.LongStorage of size 3]

914758.11527252	
 512
  64
  38
[torch.LongStorage of size 3]

914715.57134628	
 512
  64
  38
[torch.LongStorage of size 3]

914622.12574005	
Iteration 666 / 1000	
  Content 1 loss: 775728.203125	
  Style 1 loss: 1756.390381	
  Style 2 loss: 8362.596893	
  Style 3 loss: 5841.130447	
  Style 4 loss: 121961.840820	
  Style 5 loss: 971.964073	
  Total loss: 914622.125740	
s/1f8C5Gj.jpg_out_prepost_666.png	
 512
  64
  38
[torch.LongStorage of size 3]

914535.64321518	
 512
  64
  38
[torch.LongStorage of size 3]

914466.88720703	
 512
  64
  38
[torch.LongStorage of size 3]

914423.10926437	
 512
  64
  38
[torch.LongStorage of size 3]

914329.04111862	
 512
  64
  38
[torch.LongStorage of size 3]

914227.47262955	
 512
  64
  38
[torch.LongStorage of size 3]

914155.07720947	
 512
  64
  38
[torch.LongStorage of size 3]

914101.83506012	
 512
  64
  38
[torch.LongStorage of size 3]

914033.18925858	
 512
  64
  38
[torch.LongStorage of size 3]

913953.95500183	
 512
  64
  38
[torch.LongStorage of size 3]

913887.9504776	
 512
  64
  38
[torch.LongStorage of size 3]

913835.84732056	
 512
  64
  38
[torch.LongStorage of size 3]

913759.48184967	
 512
  64
  38
[torch.LongStorage of size 3]

913672.50013351	
 512
  64
  38
[torch.LongStorage of size 3]

913598.36914062	
 512
  64
  38
[torch.LongStorage of size 3]

913543.04700851	
 512
  64
  38
[torch.LongStorage of size 3]

913495.09853363	
 512
  64
  38
[torch.LongStorage of size 3]

913400.86290359	
 512
  64
  38
[torch.LongStorage of size 3]

913327.53946304	
 512
  64
  38
[torch.LongStorage of size 3]

913267.92205811	
 512
  64
  38
[torch.LongStorage of size 3]

913217.05785751	
 512
  64
  38
[torch.LongStorage of size 3]

913161.55012131	
 512
  64
  38
[torch.LongStorage of size 3]

913088.22130203	
 512
  64
  38
[torch.LongStorage of size 3]

913012.22492218	
 512
  64
  38
[torch.LongStorage of size 3]

912927.0605278	
 512
  64
  38
[torch.LongStorage of size 3]

912834.99916077	
 512
  64
  38
[torch.LongStorage of size 3]

912779.71998215	
 512
  64
  38
[torch.LongStorage of size 3]

912720.14099121	
 512
  64
  38
[torch.LongStorage of size 3]

912620.11323929	
 512
  64
  38
[torch.LongStorage of size 3]

912532.35200882	
 512
  64
  38
[torch.LongStorage of size 3]

912474.81472015	
 512
  64
  38
[torch.LongStorage of size 3]

912417.89117813	
 512
  64
  38
[torch.LongStorage of size 3]

912377.86643982	
 512
  64
  38
[torch.LongStorage of size 3]

912325.98415375	
 512
  64
  38
[torch.LongStorage of size 3]

912238.78677368	
 512
  64
  38
[torch.LongStorage of size 3]

912160.89054108	
 512
  64
  38
[torch.LongStorage of size 3]

912046.85424805	
 512
  64
  38
[torch.LongStorage of size 3]

911996.00978851	
 512
  64
  38
[torch.LongStorage of size 3]

911968.12896729	
 512
  64
  38
[torch.LongStorage of size 3]

911912.96108246	
 512
  64
  38
[torch.LongStorage of size 3]

911843.25836182	
 512
  64
  38
[torch.LongStorage of size 3]

911764.23526764	
 512
  64
  38
[torch.LongStorage of size 3]

911708.25183868	
 512
  64
  38
[torch.LongStorage of size 3]

911653.27344894	
 512
  64
  38
[torch.LongStorage of size 3]

911589.73888397	
 512
  64
  38
[torch.LongStorage of size 3]

911518.30936432	
 512
  64
  38
[torch.LongStorage of size 3]

911463.84057999	
 512
  64
  38
[torch.LongStorage of size 3]

911405.41532516	
 512
  64
  38
[torch.LongStorage of size 3]

911358.56628418	
 512
  64
  38
[torch.LongStorage of size 3]

911309.60716248	
 512
  64
  38
[torch.LongStorage of size 3]

911221.6857338	
 512
  64
  38
[torch.LongStorage of size 3]

911148.85297775	
 512
  64
  38
[torch.LongStorage of size 3]

911087.99991608	
 512
  64
  38
[torch.LongStorage of size 3]

911034.14710999	
 512
  64
  38
[torch.LongStorage of size 3]

910953.14022064	
 512
  64
  38
[torch.LongStorage of size 3]

910883.88776779	
 512
  64
  38
[torch.LongStorage of size 3]

910845.25007248	
 512
  64
  38
[torch.LongStorage of size 3]

910806.6109848	
 512
  64
  38
[torch.LongStorage of size 3]

910755.78300476	
 512
  64
  38
[torch.LongStorage of size 3]

910682.1764183	
 512
  64
  38
[torch.LongStorage of size 3]

910622.15114594	
 512
  64
  38
[torch.LongStorage of size 3]

910588.78755569	
 512
  64
  38
[torch.LongStorage of size 3]

910516.5476799	
 512
  64
  38
[torch.LongStorage of size 3]

910445.36306381	
 512
  64
  38
[torch.LongStorage of size 3]

910391.97814941	
 512
  64
  38
[torch.LongStorage of size 3]

910350.87514877	
 512
  64
  38
[torch.LongStorage of size 3]

910287.08608627	
 512
  64
  38
[torch.LongStorage of size 3]

910202.86306381	
 512
  64
  38
[torch.LongStorage of size 3]

910134.15313721	
 512
  64
  38
[torch.LongStorage of size 3]

910083.60370636	
 512
  64
  38
[torch.LongStorage of size 3]

910022.42334366	
 512
  64
  38
[torch.LongStorage of size 3]

909961.61119461	
 512
  64
  38
[torch.LongStorage of size 3]

909901.74734116	
 512
  64
  38
[torch.LongStorage of size 3]

909860.5119133	
 512
  64
  38
[torch.LongStorage of size 3]

909814.79265213	
 512
  64
  38
[torch.LongStorage of size 3]

909741.07450485	
 512
  64
  38
[torch.LongStorage of size 3]

909689.9033165	
 512
  64
  38
[torch.LongStorage of size 3]

909647.28469849	
 512
  64
  38
[torch.LongStorage of size 3]

909591.34592056	
 512
  64
  38
[torch.LongStorage of size 3]

909541.14179611	
 512
  64
  38
[torch.LongStorage of size 3]

909460.10583878	
 512
  64
  38
[torch.LongStorage of size 3]

909408.01078796	
 512
  64
  38
[torch.LongStorage of size 3]

909364.91186142	
 512
  64
  38
[torch.LongStorage of size 3]

909289.48104858	
 512
  64
  38
[torch.LongStorage of size 3]

909250.27788162	
 512
  64
  38
[torch.LongStorage of size 3]

909193.61495972	
 512
  64
  38
[torch.LongStorage of size 3]

909151.14538193	
 512
  64
  38
[torch.LongStorage of size 3]

909116.5070343	
 512
  64
  38
[torch.LongStorage of size 3]

909054.09873962	
 512
  64
  38
[torch.LongStorage of size 3]

908986.92340851	
 512
  64
  38
[torch.LongStorage of size 3]

908931.56879425	
 512
  64
  38
[torch.LongStorage of size 3]

908886.25293732	
 512
  64
  38
[torch.LongStorage of size 3]

908825.83927155	
 512
  64
  38
[torch.LongStorage of size 3]

908770.64472198	
 512
  64
  38
[torch.LongStorage of size 3]

908717.49727249	
 512
  64
  38
[torch.LongStorage of size 3]

908677.56893158	
 512
  64
  38
[torch.LongStorage of size 3]

908638.69283676	
 512
  64
  38
[torch.LongStorage of size 3]

908581.59791946	
 512
  64
  38
[torch.LongStorage of size 3]

908532.57961273	
 512
  64
  38
[torch.LongStorage of size 3]

908462.09545135	
 512
  64
  38
[torch.LongStorage of size 3]

908398.6913681	
 512
  64
  38
[torch.LongStorage of size 3]

908346.75596237	
 512
  64
  38
[torch.LongStorage of size 3]

908307.00593948	
 512
  64
  38
[torch.LongStorage of size 3]

908238.27575684	
 512
  64
  38
[torch.LongStorage of size 3]

908193.48970413	
 512
  64
  38
[torch.LongStorage of size 3]

908139.8270607	
 512
  64
  38
[torch.LongStorage of size 3]

908113.29753876	
 512
  64
  38
[torch.LongStorage of size 3]

908061.89308167	
 512
  64
  38
[torch.LongStorage of size 3]

907977.90712357	
 512
  64
  38
[torch.LongStorage of size 3]

907926.80747986	
 512
  64
  38
[torch.LongStorage of size 3]

907897.35826492	
 512
  64
  38
[torch.LongStorage of size 3]

907848.97384644	
 512
  64
  38
[torch.LongStorage of size 3]

907783.26404572	
 512
  64
  38
[torch.LongStorage of size 3]

907751.54413223	
 512
  64
  38
[torch.LongStorage of size 3]

907694.75984573	
 512
  64
  38
[torch.LongStorage of size 3]

907660.28755188	
 512
  64
  38
[torch.LongStorage of size 3]

907616.29096985	
 512
  64
  38
[torch.LongStorage of size 3]

907554.27095413	
 512
  64
  38
[torch.LongStorage of size 3]

907511.68308258	
 512
  64
  38
[torch.LongStorage of size 3]

907474.66485977	
 512
  64
  38
[torch.LongStorage of size 3]

907450.52061081	
 512
  64
  38
[torch.LongStorage of size 3]

907415.88262558	
 512
  64
  38
[torch.LongStorage of size 3]

907348.78940582	
 512
  64
  38
[torch.LongStorage of size 3]

907285.27772903	
 512
  64
  38
[torch.LongStorage of size 3]

907234.19113159	
 512
  64
  38
[torch.LongStorage of size 3]

907207.73288727	
 512
  64
  38
[torch.LongStorage of size 3]

907169.34732437	
 512
  64
  38
[torch.LongStorage of size 3]

907102.08116531	
 512
  64
  38
[torch.LongStorage of size 3]

907044.56865311	
 512
  64
  38
[torch.LongStorage of size 3]

907017.82911301	
 512
  64
  38
[torch.LongStorage of size 3]

907000.68994522	
 512
  64
  38
[torch.LongStorage of size 3]

906957.35876083	
 512
  64
  38
[torch.LongStorage of size 3]

906898.72314453	
 512
  64
  38
[torch.LongStorage of size 3]

906840.51771164	
 512
  64
  38
[torch.LongStorage of size 3]

906796.91078186	
 512
  64
  38
[torch.LongStorage of size 3]

906777.99015045	
 512
  64
  38
[torch.LongStorage of size 3]

906732.16686249	
 512
  64
  38
[torch.LongStorage of size 3]

906675.54294586	
 512
  64
  38
[torch.LongStorage of size 3]

906594.85214233	
 512
  64
  38
[torch.LongStorage of size 3]

906560.59568405	
 512
  64
  38
[torch.LongStorage of size 3]

906536.49944305	
 512
  64
  38
[torch.LongStorage of size 3]

906498.30436707	
 512
  64
  38
[torch.LongStorage of size 3]

906457.3988533	
 512
  64
  38
[torch.LongStorage of size 3]

906397.21427917	
 512
  64
  38
[torch.LongStorage of size 3]

906356.84879303	
 512
  64
  38
[torch.LongStorage of size 3]

906329.39237595	
 512
  64
  38
[torch.LongStorage of size 3]

906282.22579956	
 512
  64
  38
[torch.LongStorage of size 3]

906236.34813309	
 512
  64
  38
[torch.LongStorage of size 3]

906178.6428833	
 512
  64
  38
[torch.LongStorage of size 3]

906147.54457474	
 512
  64
  38
[torch.LongStorage of size 3]

906117.22585678	
 512
  64
  38
[torch.LongStorage of size 3]

906065.87905884	
 512
  64
  38
[torch.LongStorage of size 3]

906042.32208252	
 512
  64
  38
[torch.LongStorage of size 3]

906004.25247192	
 512
  64
  38
[torch.LongStorage of size 3]

905982.38290787	
 512
  64
  38
[torch.LongStorage of size 3]

905957.86605835	
 512
  64
  38
[torch.LongStorage of size 3]

905894.65835571	
 512
  64
  38
[torch.LongStorage of size 3]

905868.79745483	
 512
  64
  38
[torch.LongStorage of size 3]

905802.86392212	
 512
  64
  38
[torch.LongStorage of size 3]

905764.06181335	
 512
  64
  38
[torch.LongStorage of size 3]

905734.9637413	
 512
  64
  38
[torch.LongStorage of size 3]

905677.77477264	
 512
  64
  38
[torch.LongStorage of size 3]

905642.52063751	
 512
  64
  38
[torch.LongStorage of size 3]

905599.41982269	
 512
  64
  38
[torch.LongStorage of size 3]

905573.40480804	
 512
  64
  38
[torch.LongStorage of size 3]

905544.54666138	
 512
  64
  38
[torch.LongStorage of size 3]

905505.15422821	
 512
  64
  38
[torch.LongStorage of size 3]

905458.91899109	
 512
  64
  38
[torch.LongStorage of size 3]

905428.99980545	
 512
  64
  38
[torch.LongStorage of size 3]

905394.44259644	
 512
  64
  38
[torch.LongStorage of size 3]

905339.45510864	
 512
  64
  38
[torch.LongStorage of size 3]

905303.28519821	
 512
  64
  38
[torch.LongStorage of size 3]

905267.70059586	
 512
  64
  38
[torch.LongStorage of size 3]

905233.23495865	
 512
  64
  38
[torch.LongStorage of size 3]

905190.38007736	
 512
  64
  38
[torch.LongStorage of size 3]

905140.4391098	
 512
  64
  38
[torch.LongStorage of size 3]

905095.35337448	
 512
  64
  38
[torch.LongStorage of size 3]

905070.05268097	
 512
  64
  38
[torch.LongStorage of size 3]

905027.00475693	
 512
  64
  38
[torch.LongStorage of size 3]

904972.97178268	
 512
  64
  38
[torch.LongStorage of size 3]

904935.37176132	
 512
  64
  38
[torch.LongStorage of size 3]

904904.55543518	
 512
  64
  38
[torch.LongStorage of size 3]

904879.39998627	
 512
  64
  38
[torch.LongStorage of size 3]

904842.43450165	
 512
  64
  38
[torch.LongStorage of size 3]

904796.86494827	
 512
  64
  38
[torch.LongStorage of size 3]

904765.48294067	
 512
  64
  38
[torch.LongStorage of size 3]

904730.44786453	
 512
  64
  38
[torch.LongStorage of size 3]

904678.04014206	
 512
  64
  38
[torch.LongStorage of size 3]

904694.76968765	
 512
  64
  38
[torch.LongStorage of size 3]

904618.81853104	
 512
  64
  38
[torch.LongStorage of size 3]

904595.94293594	
 512
  64
  38
[torch.LongStorage of size 3]

904561.85001373	
 512
  64
  38
[torch.LongStorage of size 3]

904515.66066742	
 512
  64
  38
[torch.LongStorage of size 3]

904456.85983658	
 512
  64
  38
[torch.LongStorage of size 3]

904413.56025696	
 512
  64
  38
[torch.LongStorage of size 3]

904380.34164429	
 512
  64
  38
[torch.LongStorage of size 3]

904358.03007126	
 512
  64
  38
[torch.LongStorage of size 3]

904333.73630524	
 512
  64
  38
[torch.LongStorage of size 3]

904282.65743256	
 512
  64
  38
[torch.LongStorage of size 3]

904234.87184525	
 512
  64
  38
[torch.LongStorage of size 3]

904194.12872314	
 512
  64
  38
[torch.LongStorage of size 3]

904160.57291031	
 512
  64
  38
[torch.LongStorage of size 3]

904110.73160172	
 512
  64
  38
[torch.LongStorage of size 3]

904079.11819458	
 512
  64
  38
[torch.LongStorage of size 3]

904046.47857666	
 512
  64
  38
[torch.LongStorage of size 3]

904013.045578	
 512
  64
  38
[torch.LongStorage of size 3]

903978.92700195	
 512
  64
  38
[torch.LongStorage of size 3]

903922.26148605	
 512
  64
  38
[torch.LongStorage of size 3]

903942.97689438	
 512
  64
  38
[torch.LongStorage of size 3]

903879.45983887	
 512
  64
  38
[torch.LongStorage of size 3]

903866.00622177	
 512
  64
  38
[torch.LongStorage of size 3]

903839.6472168	
 512
  64
  38
[torch.LongStorage of size 3]

903806.22013092	
 512
  64
  38
[torch.LongStorage of size 3]

903753.7635994	
 512
  64
  38
[torch.LongStorage of size 3]

903725.70968628	
 512
  64
  38
[torch.LongStorage of size 3]

903682.60347366	
 512
  64
  38
[torch.LongStorage of size 3]

903661.29396439	
 512
  64
  38
[torch.LongStorage of size 3]

903640.18684387	
 512
  64
  38
[torch.LongStorage of size 3]

903599.0309906	
 512
  64
  38
[torch.LongStorage of size 3]

903639.03745651	
 512
  64
  38
[torch.LongStorage of size 3]

903545.28556824	
 512
  64
  38
[torch.LongStorage of size 3]

903523.64963531	
 512
  64
  38
[torch.LongStorage of size 3]

903492.91902542	
 512
  64
  38
[torch.LongStorage of size 3]

903457.14431763	
 512
  64
  38
[torch.LongStorage of size 3]

903437.49980927	
 512
  64
  38
[torch.LongStorage of size 3]

903408.33702087	
 512
  64
  38
[torch.LongStorage of size 3]

903389.53285217	
 512
  64
  38
[torch.LongStorage of size 3]

903365.33588409	
 512
  64
  38
[torch.LongStorage of size 3]

903317.03672409	
 512
  64
  38
[torch.LongStorage of size 3]

903299.53622818	
 512
  64
  38
[torch.LongStorage of size 3]

903237.94725418	
 512
  64
  38
[torch.LongStorage of size 3]

903219.56712723	
 512
  64
  38
[torch.LongStorage of size 3]

903189.03066635	
 512
  64
  38
[torch.LongStorage of size 3]

903160.71243286	
 512
  64
  38
[torch.LongStorage of size 3]

903123.91220093	
 512
  64
  38
[torch.LongStorage of size 3]

903097.22412109	
 512
  64
  38
[torch.LongStorage of size 3]

903064.79604721	
 512
  64
  38
[torch.LongStorage of size 3]

903036.18062973	
 512
  64
  38
[torch.LongStorage of size 3]

903007.37148285	
 512
  64
  38
[torch.LongStorage of size 3]

902967.90023804	
 512
  64
  38
[torch.LongStorage of size 3]

902961.53665543	
 512
  64
  38
[torch.LongStorage of size 3]

902913.62758636	
 512
  64
  38
[torch.LongStorage of size 3]

902892.53276825	
 512
  64
  38
[torch.LongStorage of size 3]

902865.13631821	
 512
  64
  38
[torch.LongStorage of size 3]

902829.8528862	
 512
  64
  38
[torch.LongStorage of size 3]

902800.57447433	
 512
  64
  38
[torch.LongStorage of size 3]

902771.12264633	
 512
  64
  38
[torch.LongStorage of size 3]

902735.79530716	
 512
  64
  38
[torch.LongStorage of size 3]

902687.23543167	
 512
  64
  38
[torch.LongStorage of size 3]

902639.35150146	
 512
  64
  38
[torch.LongStorage of size 3]

902633.31315994	
 512
  64
  38
[torch.LongStorage of size 3]

902594.77302551	
 512
  64
  38
[torch.LongStorage of size 3]

902578.59481812	
 512
  64
  38
[torch.LongStorage of size 3]

902552.03371048	
 512
  64
  38
[torch.LongStorage of size 3]

902515.30784607	
 512
  64
  38
[torch.LongStorage of size 3]

902475.46215057	
 512
  64
  38
[torch.LongStorage of size 3]

902443.24777603	
 512
  64
  38
[torch.LongStorage of size 3]

902424.69917297	
 512
  64
  38
[torch.LongStorage of size 3]

902394.55318451	
 512
  64
  38
[torch.LongStorage of size 3]

902366.10452652	
 512
  64
  38
[torch.LongStorage of size 3]

902326.6431427	
 512
  64
  38
[torch.LongStorage of size 3]

902314.87567902	
 512
  64
  38
[torch.LongStorage of size 3]

902285.35165787	
 512
  64
  38
[torch.LongStorage of size 3]

902260.93847275	
 512
  64
  38
[torch.LongStorage of size 3]

902234.38213348	
 512
  64
  38
[torch.LongStorage of size 3]

902199.41570282	
 512
  64
  38
[torch.LongStorage of size 3]

902150.40039062	
 512
  64
  38
[torch.LongStorage of size 3]

902115.28831482	
 512
  64
  38
[torch.LongStorage of size 3]

902076.81806564	
 512
  64
  38
[torch.LongStorage of size 3]

902061.67430878	
 512
  64
  38
[torch.LongStorage of size 3]

902033.77382278	
 512
  64
  38
[torch.LongStorage of size 3]

902003.27358246	
 512
  64
  38
[torch.LongStorage of size 3]

901966.54800415	
 512
  64
  38
[torch.LongStorage of size 3]

901955.78636169	
 512
  64
  38
[torch.LongStorage of size 3]

901927.45822906	
 512
  64
  38
[torch.LongStorage of size 3]

901907.21553802	
 512
  64
  38
[torch.LongStorage of size 3]

901881.96725845	
 512
  64
  38
[torch.LongStorage of size 3]

901829.97526169	
 512
  64
  38
[torch.LongStorage of size 3]

901819.42239761	
 512
  64
  38
[torch.LongStorage of size 3]

901785.16519547	
 512
  64
  38
[torch.LongStorage of size 3]

901767.92915344	
 512
  64
  38
[torch.LongStorage of size 3]

901753.78767014	
 512
  64
  38
[torch.LongStorage of size 3]

901723.95158768	
 512
  64
  38
[torch.LongStorage of size 3]

901680.83745956	
 512
  64
  38
[torch.LongStorage of size 3]

901704.43447113	
 512
  64
  38
[torch.LongStorage of size 3]

901631.20384216	
 512
  64
  38
[torch.LongStorage of size 3]

901614.87810135	
 512
  64
  38
[torch.LongStorage of size 3]

901593.5385704	
 512
  64
  38
[torch.LongStorage of size 3]

901558.24033737	
 512
  64
  38
[torch.LongStorage of size 3]

901525.5960083	
 512
  64
  38
[torch.LongStorage of size 3]

901499.80382919	
 512
  64
  38
[torch.LongStorage of size 3]

901486.26674652	
 512
  64
  38
[torch.LongStorage of size 3]

901459.09578323	
 512
  64
  38
[torch.LongStorage of size 3]

901435.18238068	
 512
  64
  38
[torch.LongStorage of size 3]

901401.74104691	
 512
  64
  38
[torch.LongStorage of size 3]

901368.87367249	
 512
  64
  38
[torch.LongStorage of size 3]

901357.7803421	
 512
  64
  38
[torch.LongStorage of size 3]

901326.86056137	
 512
  64
  38
[torch.LongStorage of size 3]

901291.73143387	
 512
  64
  38
[torch.LongStorage of size 3]

901279.92053986	
 512
  64
  38
[torch.LongStorage of size 3]

901251.17521286	
 512
  64
  38
[torch.LongStorage of size 3]

901233.77603531	
 512
  64
  38
[torch.LongStorage of size 3]

901210.08497238	
 512
  64
  38
[torch.LongStorage of size 3]

901169.81910706	
 512
  64
  38
[torch.LongStorage of size 3]

901117.49483109	
 512
  64
  38
[torch.LongStorage of size 3]

901135.99201202	
 512
  64
  38
[torch.LongStorage of size 3]

901070.46077728	
 512
  64
  38
[torch.LongStorage of size 3]

901057.81814575	
 512
  64
  38
[torch.LongStorage of size 3]

901039.82265472	
 512
  64
  38
[torch.LongStorage of size 3]

901012.10771561	
 512
  64
  38
[torch.LongStorage of size 3]

900975.36474228	
 512
  64
  38
[torch.LongStorage of size 3]

900946.2607193	
 512
  64
  38
[torch.LongStorage of size 3]

900922.00929642	
 512
  64
  38
[torch.LongStorage of size 3]

900895.30553818	
 512
  64
  38
[torch.LongStorage of size 3]

900886.41407013	
 512
  64
  38
[torch.LongStorage of size 3]

900858.65991592	
 512
  64
  38
[torch.LongStorage of size 3]

900834.55036163	
 512
  64
  38
[torch.LongStorage of size 3]

900809.67222214	
 512
  64
  38
[torch.LongStorage of size 3]

900795.60661316	
 512
  64
  38
[torch.LongStorage of size 3]

900767.86735535	
 512
  64
  38
[torch.LongStorage of size 3]

900747.75775909	
 512
  64
  38
[torch.LongStorage of size 3]

900730.77356339	
 512
  64
  38
[torch.LongStorage of size 3]

900698.49767685	
 512
  64
  38
[torch.LongStorage of size 3]

900674.8806572	
 512
  64
  38
[torch.LongStorage of size 3]

900635.35951614	
 512
  64
  38
[torch.LongStorage of size 3]

900621.40762329	
 512
  64
  38
[torch.LongStorage of size 3]

900598.45287323	
 512
  64
  38
[torch.LongStorage of size 3]

900580.68082809	
 512
  64
  38
[torch.LongStorage of size 3]

900548.71433258	
 512
  64
  38
[torch.LongStorage of size 3]

900521.52700424	
 512
  64
  38
[torch.LongStorage of size 3]

900502.74065018	
 512
  64
  38
[torch.LongStorage of size 3]

900486.82844162	
 512
  64
  38
[torch.LongStorage of size 3]

900459.50176239	
 512
  64
  38
[torch.LongStorage of size 3]

900437.87191391	
Iteration 999 / 1000	
  Content 1 loss: 770917.500000	
  Style 1 loss: 940.450668	
  Style 2 loss: 6210.038376	
  Style 3 loss: 5266.902161	
  Style 4 loss: 116140.356445	
  Style 5 loss: 962.624264	
  Total loss: 900437.871914	
s/1f8C5Gj.jpg_out_prepost_999.png	
 512
  64
  38
[torch.LongStorage of size 3]

900402.01709747	
s/1f8C5Gj.jpg_out_prepost_1000.png	
<optim.lbfgs> 	reached max number of iterations	
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0804 20:20:09.525568  4077 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0804 20:20:09.525655  4077 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0804 20:20:09.525672  4077 _caffe.cpp:142] Net('./zhang/colorization/models/colorization_deploy_v2.prototxt', 1, weights='./zhang/colorization/models/colorization_release_v2.caffemodel')
I0804 20:20:09.527720  4077 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_deploy_v2.prototxt
I0804 20:20:09.527755  4077 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 20:20:09.528070  4077 net.cpp:51] Initializing net from parameters: 
name: "LtoAB"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data_l"
  type: "Input"
  top: "data_l"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "bw_conv1_1"
  type: "Convolution"
  bottom: "data_l"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_2norm"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_2norm"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_2norm"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_2norm"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_3norm"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_3norm"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_3norm"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_3norm"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    stride: 1
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_3norm"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_3norm"
  top: "conv6_1"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv6_3"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_3"
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "conv6_3"
  top: "conv6_3"
}
layer {
  name: "conv6_3norm"
  type: "BatchNorm"
  bottom: "conv6_3"
  top: "conv6_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_3norm"
  top: "conv7_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv7_3"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "conv7_3"
  top: "conv7_3"
}
layer {
  name: "conv7_3norm"
  type: "BatchNorm"
  bottom: "conv7_3"
  top: "conv7_3norm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
  }
}
layer {
  name: "conv8_1"
  type: "Deconvolution"
  bottom: "conv7_3norm"
  top: "conv8_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    stride: 2
    dilation: 1
  }
}
layer {
  name: "relu8_1"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_2"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv8_3"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    dilation: 1
  }
}
layer {
  name: "relu8_3"
  type: "ReLU"
  bottom: "conv8_3"
  top: "conv8_3"
}
layer {
  name: "conv8_313"
  type: "Convolution"
  bottom: "conv8_3"
  top: "conv8_313"
  convolution_param {
    num_output: 313
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv8_313_rh"
  type: "Scale"
  bottom: "conv8_313"
  top: "conv8_313_rh"
  scale_param {
    filler {
      type: "constant"
      value: 2.606
    }
    bias_term: false
  }
}
layer {
  name: "class8_313_rh"
  type: "Softmax"
  bottom: "conv8_313_rh"
  top: "class8_313_rh"
}
layer {
  name: "class8_ab"
  type: "Convolution"
  bottom: "class8_313_rh"
  top: "class8_ab"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "Silence"
  type: "Silence"
  bottom: "class8_ab"
}
I0804 20:20:09.528276  4077 layer_factory.hpp:77] Creating layer data_l
I0804 20:20:09.528301  4077 net.cpp:84] Creating Layer data_l
I0804 20:20:09.528316  4077 net.cpp:380] data_l -> data_l
I0804 20:20:09.541406  4077 net.cpp:122] Setting up data_l
I0804 20:20:09.541460  4077 net.cpp:129] Top shape: 1 1 224 224 (50176)
I0804 20:20:09.541476  4077 net.cpp:137] Memory required for data: 200704
I0804 20:20:09.541491  4077 layer_factory.hpp:77] Creating layer bw_conv1_1
I0804 20:20:09.541517  4077 net.cpp:84] Creating Layer bw_conv1_1
I0804 20:20:09.541530  4077 net.cpp:406] bw_conv1_1 <- data_l
I0804 20:20:09.541549  4077 net.cpp:380] bw_conv1_1 -> conv1_1
I0804 20:20:09.543807  4077 net.cpp:122] Setting up bw_conv1_1
I0804 20:20:09.543851  4077 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 20:20:09.543887  4077 net.cpp:137] Memory required for data: 13045760
I0804 20:20:09.543913  4077 layer_factory.hpp:77] Creating layer relu1_1
I0804 20:20:09.543936  4077 net.cpp:84] Creating Layer relu1_1
I0804 20:20:09.543949  4077 net.cpp:406] relu1_1 <- conv1_1
I0804 20:20:09.543967  4077 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0804 20:20:09.543987  4077 net.cpp:122] Setting up relu1_1
I0804 20:20:09.544001  4077 net.cpp:129] Top shape: 1 64 224 224 (3211264)
I0804 20:20:09.544013  4077 net.cpp:137] Memory required for data: 25890816
I0804 20:20:09.544026  4077 layer_factory.hpp:77] Creating layer conv1_2
I0804 20:20:09.544047  4077 net.cpp:84] Creating Layer conv1_2
I0804 20:20:09.544060  4077 net.cpp:406] conv1_2 <- conv1_1
I0804 20:20:09.544075  4077 net.cpp:380] conv1_2 -> conv1_2
I0804 20:20:09.545444  4077 net.cpp:122] Setting up conv1_2
I0804 20:20:09.545480  4077 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 20:20:09.545492  4077 net.cpp:137] Memory required for data: 29102080
I0804 20:20:09.545513  4077 layer_factory.hpp:77] Creating layer relu1_2
I0804 20:20:09.545532  4077 net.cpp:84] Creating Layer relu1_2
I0804 20:20:09.545547  4077 net.cpp:406] relu1_2 <- conv1_2
I0804 20:20:09.545563  4077 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0804 20:20:09.545580  4077 net.cpp:122] Setting up relu1_2
I0804 20:20:09.545595  4077 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 20:20:09.545608  4077 net.cpp:137] Memory required for data: 32313344
I0804 20:20:09.545620  4077 layer_factory.hpp:77] Creating layer conv1_2norm
I0804 20:20:09.545639  4077 net.cpp:84] Creating Layer conv1_2norm
I0804 20:20:09.545652  4077 net.cpp:406] conv1_2norm <- conv1_2
I0804 20:20:09.545667  4077 net.cpp:380] conv1_2norm -> conv1_2norm
I0804 20:20:09.545913  4077 net.cpp:122] Setting up conv1_2norm
I0804 20:20:09.545931  4077 net.cpp:129] Top shape: 1 64 112 112 (802816)
I0804 20:20:09.545944  4077 net.cpp:137] Memory required for data: 35524608
I0804 20:20:09.545964  4077 layer_factory.hpp:77] Creating layer conv2_1
I0804 20:20:09.545984  4077 net.cpp:84] Creating Layer conv2_1
I0804 20:20:09.545996  4077 net.cpp:406] conv2_1 <- conv1_2norm
I0804 20:20:09.546013  4077 net.cpp:380] conv2_1 -> conv2_1
I0804 20:20:09.547298  4077 net.cpp:122] Setting up conv2_1
I0804 20:20:09.547329  4077 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 20:20:09.547343  4077 net.cpp:137] Memory required for data: 41947136
I0804 20:20:09.547364  4077 layer_factory.hpp:77] Creating layer relu2_1
I0804 20:20:09.547382  4077 net.cpp:84] Creating Layer relu2_1
I0804 20:20:09.547396  4077 net.cpp:406] relu2_1 <- conv2_1
I0804 20:20:09.547413  4077 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0804 20:20:09.547430  4077 net.cpp:122] Setting up relu2_1
I0804 20:20:09.547446  4077 net.cpp:129] Top shape: 1 128 112 112 (1605632)
I0804 20:20:09.547458  4077 net.cpp:137] Memory required for data: 48369664
I0804 20:20:09.547471  4077 layer_factory.hpp:77] Creating layer conv2_2
I0804 20:20:09.547492  4077 net.cpp:84] Creating Layer conv2_2
I0804 20:20:09.547505  4077 net.cpp:406] conv2_2 <- conv2_1
I0804 20:20:09.547521  4077 net.cpp:380] conv2_2 -> conv2_2
I0804 20:20:09.548866  4077 net.cpp:122] Setting up conv2_2
I0804 20:20:09.548895  4077 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 20:20:09.548908  4077 net.cpp:137] Memory required for data: 49975296
I0804 20:20:09.548926  4077 layer_factory.hpp:77] Creating layer relu2_2
I0804 20:20:09.548944  4077 net.cpp:84] Creating Layer relu2_2
I0804 20:20:09.548959  4077 net.cpp:406] relu2_2 <- conv2_2
I0804 20:20:09.548974  4077 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0804 20:20:09.548990  4077 net.cpp:122] Setting up relu2_2
I0804 20:20:09.549019  4077 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 20:20:09.549042  4077 net.cpp:137] Memory required for data: 51580928
I0804 20:20:09.549057  4077 layer_factory.hpp:77] Creating layer conv2_2norm
I0804 20:20:09.549075  4077 net.cpp:84] Creating Layer conv2_2norm
I0804 20:20:09.549089  4077 net.cpp:406] conv2_2norm <- conv2_2
I0804 20:20:09.549124  4077 net.cpp:380] conv2_2norm -> conv2_2norm
I0804 20:20:09.549368  4077 net.cpp:122] Setting up conv2_2norm
I0804 20:20:09.549386  4077 net.cpp:129] Top shape: 1 128 56 56 (401408)
I0804 20:20:09.549399  4077 net.cpp:137] Memory required for data: 53186560
I0804 20:20:09.549417  4077 layer_factory.hpp:77] Creating layer conv3_1
I0804 20:20:09.549435  4077 net.cpp:84] Creating Layer conv3_1
I0804 20:20:09.549448  4077 net.cpp:406] conv3_1 <- conv2_2norm
I0804 20:20:09.549465  4077 net.cpp:380] conv3_1 -> conv3_1
I0804 20:20:09.549988  4077 net.cpp:122] Setting up conv3_1
I0804 20:20:09.550006  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.550019  4077 net.cpp:137] Memory required for data: 56397824
I0804 20:20:09.550035  4077 layer_factory.hpp:77] Creating layer relu3_1
I0804 20:20:09.550050  4077 net.cpp:84] Creating Layer relu3_1
I0804 20:20:09.550065  4077 net.cpp:406] relu3_1 <- conv3_1
I0804 20:20:09.550078  4077 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0804 20:20:09.550093  4077 net.cpp:122] Setting up relu3_1
I0804 20:20:09.550108  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.550120  4077 net.cpp:137] Memory required for data: 59609088
I0804 20:20:09.550133  4077 layer_factory.hpp:77] Creating layer conv3_2
I0804 20:20:09.550151  4077 net.cpp:84] Creating Layer conv3_2
I0804 20:20:09.550164  4077 net.cpp:406] conv3_2 <- conv3_1
I0804 20:20:09.550181  4077 net.cpp:380] conv3_2 -> conv3_2
I0804 20:20:09.552040  4077 net.cpp:122] Setting up conv3_2
I0804 20:20:09.552079  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.552098  4077 net.cpp:137] Memory required for data: 62820352
I0804 20:20:09.552121  4077 layer_factory.hpp:77] Creating layer relu3_2
I0804 20:20:09.552141  4077 net.cpp:84] Creating Layer relu3_2
I0804 20:20:09.552155  4077 net.cpp:406] relu3_2 <- conv3_2
I0804 20:20:09.552175  4077 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0804 20:20:09.552194  4077 net.cpp:122] Setting up relu3_2
I0804 20:20:09.552208  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.552222  4077 net.cpp:137] Memory required for data: 66031616
I0804 20:20:09.552237  4077 layer_factory.hpp:77] Creating layer conv3_3
I0804 20:20:09.552255  4077 net.cpp:84] Creating Layer conv3_3
I0804 20:20:09.552270  4077 net.cpp:406] conv3_3 <- conv3_2
I0804 20:20:09.552289  4077 net.cpp:380] conv3_3 -> conv3_3
I0804 20:20:09.554203  4077 net.cpp:122] Setting up conv3_3
I0804 20:20:09.554244  4077 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 20:20:09.554257  4077 net.cpp:137] Memory required for data: 66834432
I0804 20:20:09.554275  4077 layer_factory.hpp:77] Creating layer relu3_3
I0804 20:20:09.554296  4077 net.cpp:84] Creating Layer relu3_3
I0804 20:20:09.554311  4077 net.cpp:406] relu3_3 <- conv3_3
I0804 20:20:09.554325  4077 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0804 20:20:09.554342  4077 net.cpp:122] Setting up relu3_3
I0804 20:20:09.554356  4077 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 20:20:09.554369  4077 net.cpp:137] Memory required for data: 67637248
I0804 20:20:09.554381  4077 layer_factory.hpp:77] Creating layer conv3_3norm
I0804 20:20:09.554400  4077 net.cpp:84] Creating Layer conv3_3norm
I0804 20:20:09.554414  4077 net.cpp:406] conv3_3norm <- conv3_3
I0804 20:20:09.554428  4077 net.cpp:380] conv3_3norm -> conv3_3norm
I0804 20:20:09.554666  4077 net.cpp:122] Setting up conv3_3norm
I0804 20:20:09.554683  4077 net.cpp:129] Top shape: 1 256 28 28 (200704)
I0804 20:20:09.554697  4077 net.cpp:137] Memory required for data: 68440064
I0804 20:20:09.554713  4077 layer_factory.hpp:77] Creating layer conv4_1
I0804 20:20:09.554731  4077 net.cpp:84] Creating Layer conv4_1
I0804 20:20:09.554744  4077 net.cpp:406] conv4_1 <- conv3_3norm
I0804 20:20:09.554764  4077 net.cpp:380] conv4_1 -> conv4_1
I0804 20:20:09.557927  4077 net.cpp:122] Setting up conv4_1
I0804 20:20:09.557979  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.557993  4077 net.cpp:137] Memory required for data: 70045696
I0804 20:20:09.558032  4077 layer_factory.hpp:77] Creating layer relu4_1
I0804 20:20:09.558053  4077 net.cpp:84] Creating Layer relu4_1
I0804 20:20:09.558068  4077 net.cpp:406] relu4_1 <- conv4_1
I0804 20:20:09.558084  4077 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0804 20:20:09.558100  4077 net.cpp:122] Setting up relu4_1
I0804 20:20:09.558115  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.558127  4077 net.cpp:137] Memory required for data: 71651328
I0804 20:20:09.558140  4077 layer_factory.hpp:77] Creating layer conv4_2
I0804 20:20:09.558159  4077 net.cpp:84] Creating Layer conv4_2
I0804 20:20:09.558172  4077 net.cpp:406] conv4_2 <- conv4_1
I0804 20:20:09.558188  4077 net.cpp:380] conv4_2 -> conv4_2
I0804 20:20:09.564174  4077 net.cpp:122] Setting up conv4_2
I0804 20:20:09.564224  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.564239  4077 net.cpp:137] Memory required for data: 73256960
I0804 20:20:09.564257  4077 layer_factory.hpp:77] Creating layer relu4_2
I0804 20:20:09.564278  4077 net.cpp:84] Creating Layer relu4_2
I0804 20:20:09.564292  4077 net.cpp:406] relu4_2 <- conv4_2
I0804 20:20:09.564308  4077 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0804 20:20:09.564327  4077 net.cpp:122] Setting up relu4_2
I0804 20:20:09.564342  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.564353  4077 net.cpp:137] Memory required for data: 74862592
I0804 20:20:09.564366  4077 layer_factory.hpp:77] Creating layer conv4_3
I0804 20:20:09.564385  4077 net.cpp:84] Creating Layer conv4_3
I0804 20:20:09.564399  4077 net.cpp:406] conv4_3 <- conv4_2
I0804 20:20:09.564414  4077 net.cpp:380] conv4_3 -> conv4_3
I0804 20:20:09.570407  4077 net.cpp:122] Setting up conv4_3
I0804 20:20:09.570458  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.570472  4077 net.cpp:137] Memory required for data: 76468224
I0804 20:20:09.570492  4077 layer_factory.hpp:77] Creating layer relu4_3
I0804 20:20:09.570509  4077 net.cpp:84] Creating Layer relu4_3
I0804 20:20:09.570523  4077 net.cpp:406] relu4_3 <- conv4_3
I0804 20:20:09.570541  4077 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0804 20:20:09.570559  4077 net.cpp:122] Setting up relu4_3
I0804 20:20:09.570574  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.570586  4077 net.cpp:137] Memory required for data: 78073856
I0804 20:20:09.570600  4077 layer_factory.hpp:77] Creating layer conv4_3norm
I0804 20:20:09.570617  4077 net.cpp:84] Creating Layer conv4_3norm
I0804 20:20:09.570631  4077 net.cpp:406] conv4_3norm <- conv4_3
I0804 20:20:09.570647  4077 net.cpp:380] conv4_3norm -> conv4_3norm
I0804 20:20:09.570894  4077 net.cpp:122] Setting up conv4_3norm
I0804 20:20:09.570912  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.570925  4077 net.cpp:137] Memory required for data: 79679488
I0804 20:20:09.570942  4077 layer_factory.hpp:77] Creating layer conv5_1
I0804 20:20:09.570961  4077 net.cpp:84] Creating Layer conv5_1
I0804 20:20:09.570976  4077 net.cpp:406] conv5_1 <- conv4_3norm
I0804 20:20:09.570991  4077 net.cpp:380] conv5_1 -> conv5_1
I0804 20:20:09.576974  4077 net.cpp:122] Setting up conv5_1
I0804 20:20:09.577041  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.577059  4077 net.cpp:137] Memory required for data: 81285120
I0804 20:20:09.577090  4077 layer_factory.hpp:77] Creating layer relu5_1
I0804 20:20:09.577111  4077 net.cpp:84] Creating Layer relu5_1
I0804 20:20:09.577124  4077 net.cpp:406] relu5_1 <- conv5_1
I0804 20:20:09.577141  4077 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0804 20:20:09.577158  4077 net.cpp:122] Setting up relu5_1
I0804 20:20:09.577172  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.577185  4077 net.cpp:137] Memory required for data: 82890752
I0804 20:20:09.577198  4077 layer_factory.hpp:77] Creating layer conv5_2
I0804 20:20:09.577217  4077 net.cpp:84] Creating Layer conv5_2
I0804 20:20:09.577230  4077 net.cpp:406] conv5_2 <- conv5_1
I0804 20:20:09.577247  4077 net.cpp:380] conv5_2 -> conv5_2
I0804 20:20:09.583230  4077 net.cpp:122] Setting up conv5_2
I0804 20:20:09.583307  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.583322  4077 net.cpp:137] Memory required for data: 84496384
I0804 20:20:09.583340  4077 layer_factory.hpp:77] Creating layer relu5_2
I0804 20:20:09.583359  4077 net.cpp:84] Creating Layer relu5_2
I0804 20:20:09.583374  4077 net.cpp:406] relu5_2 <- conv5_2
I0804 20:20:09.583390  4077 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0804 20:20:09.583408  4077 net.cpp:122] Setting up relu5_2
I0804 20:20:09.583423  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.583436  4077 net.cpp:137] Memory required for data: 86102016
I0804 20:20:09.583448  4077 layer_factory.hpp:77] Creating layer conv5_3
I0804 20:20:09.583467  4077 net.cpp:84] Creating Layer conv5_3
I0804 20:20:09.583480  4077 net.cpp:406] conv5_3 <- conv5_2
I0804 20:20:09.583500  4077 net.cpp:380] conv5_3 -> conv5_3
I0804 20:20:09.589483  4077 net.cpp:122] Setting up conv5_3
I0804 20:20:09.589540  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.589555  4077 net.cpp:137] Memory required for data: 87707648
I0804 20:20:09.589576  4077 layer_factory.hpp:77] Creating layer relu5_3
I0804 20:20:09.589596  4077 net.cpp:84] Creating Layer relu5_3
I0804 20:20:09.589612  4077 net.cpp:406] relu5_3 <- conv5_3
I0804 20:20:09.589629  4077 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0804 20:20:09.589650  4077 net.cpp:122] Setting up relu5_3
I0804 20:20:09.589665  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.589678  4077 net.cpp:137] Memory required for data: 89313280
I0804 20:20:09.589690  4077 layer_factory.hpp:77] Creating layer conv5_3norm
I0804 20:20:09.589709  4077 net.cpp:84] Creating Layer conv5_3norm
I0804 20:20:09.589721  4077 net.cpp:406] conv5_3norm <- conv5_3
I0804 20:20:09.589737  4077 net.cpp:380] conv5_3norm -> conv5_3norm
I0804 20:20:09.589982  4077 net.cpp:122] Setting up conv5_3norm
I0804 20:20:09.590001  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.590014  4077 net.cpp:137] Memory required for data: 90918912
I0804 20:20:09.590032  4077 layer_factory.hpp:77] Creating layer conv6_1
I0804 20:20:09.590054  4077 net.cpp:84] Creating Layer conv6_1
I0804 20:20:09.590068  4077 net.cpp:406] conv6_1 <- conv5_3norm
I0804 20:20:09.590085  4077 net.cpp:380] conv6_1 -> conv6_1
I0804 20:20:09.596024  4077 net.cpp:122] Setting up conv6_1
I0804 20:20:09.596079  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.596094  4077 net.cpp:137] Memory required for data: 92524544
I0804 20:20:09.596115  4077 layer_factory.hpp:77] Creating layer relu6_1
I0804 20:20:09.596138  4077 net.cpp:84] Creating Layer relu6_1
I0804 20:20:09.596155  4077 net.cpp:406] relu6_1 <- conv6_1
I0804 20:20:09.596174  4077 net.cpp:367] relu6_1 -> conv6_1 (in-place)
I0804 20:20:09.596194  4077 net.cpp:122] Setting up relu6_1
I0804 20:20:09.596212  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.596225  4077 net.cpp:137] Memory required for data: 94130176
I0804 20:20:09.596238  4077 layer_factory.hpp:77] Creating layer conv6_2
I0804 20:20:09.596262  4077 net.cpp:84] Creating Layer conv6_2
I0804 20:20:09.596276  4077 net.cpp:406] conv6_2 <- conv6_1
I0804 20:20:09.596293  4077 net.cpp:380] conv6_2 -> conv6_2
I0804 20:20:09.602218  4077 net.cpp:122] Setting up conv6_2
I0804 20:20:09.602272  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.602285  4077 net.cpp:137] Memory required for data: 95735808
I0804 20:20:09.602304  4077 layer_factory.hpp:77] Creating layer relu6_2
I0804 20:20:09.602324  4077 net.cpp:84] Creating Layer relu6_2
I0804 20:20:09.602337  4077 net.cpp:406] relu6_2 <- conv6_2
I0804 20:20:09.602355  4077 net.cpp:367] relu6_2 -> conv6_2 (in-place)
I0804 20:20:09.602375  4077 net.cpp:122] Setting up relu6_2
I0804 20:20:09.602388  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.602401  4077 net.cpp:137] Memory required for data: 97341440
I0804 20:20:09.602413  4077 layer_factory.hpp:77] Creating layer conv6_3
I0804 20:20:09.602432  4077 net.cpp:84] Creating Layer conv6_3
I0804 20:20:09.602445  4077 net.cpp:406] conv6_3 <- conv6_2
I0804 20:20:09.602474  4077 net.cpp:380] conv6_3 -> conv6_3
I0804 20:20:09.608573  4077 net.cpp:122] Setting up conv6_3
I0804 20:20:09.608626  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.608641  4077 net.cpp:137] Memory required for data: 98947072
I0804 20:20:09.608660  4077 layer_factory.hpp:77] Creating layer relu6_3
I0804 20:20:09.608680  4077 net.cpp:84] Creating Layer relu6_3
I0804 20:20:09.608695  4077 net.cpp:406] relu6_3 <- conv6_3
I0804 20:20:09.608712  4077 net.cpp:367] relu6_3 -> conv6_3 (in-place)
I0804 20:20:09.608731  4077 net.cpp:122] Setting up relu6_3
I0804 20:20:09.608745  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.608758  4077 net.cpp:137] Memory required for data: 100552704
I0804 20:20:09.608770  4077 layer_factory.hpp:77] Creating layer conv6_3norm
I0804 20:20:09.608788  4077 net.cpp:84] Creating Layer conv6_3norm
I0804 20:20:09.608801  4077 net.cpp:406] conv6_3norm <- conv6_3
I0804 20:20:09.608819  4077 net.cpp:380] conv6_3norm -> conv6_3norm
I0804 20:20:09.609087  4077 net.cpp:122] Setting up conv6_3norm
I0804 20:20:09.609109  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.609122  4077 net.cpp:137] Memory required for data: 102158336
I0804 20:20:09.609140  4077 layer_factory.hpp:77] Creating layer conv7_1
I0804 20:20:09.609158  4077 net.cpp:84] Creating Layer conv7_1
I0804 20:20:09.609171  4077 net.cpp:406] conv7_1 <- conv6_3norm
I0804 20:20:09.609187  4077 net.cpp:380] conv7_1 -> conv7_1
I0804 20:20:09.615058  4077 net.cpp:122] Setting up conv7_1
I0804 20:20:09.615111  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.615125  4077 net.cpp:137] Memory required for data: 103763968
I0804 20:20:09.615145  4077 layer_factory.hpp:77] Creating layer relu7_1
I0804 20:20:09.615164  4077 net.cpp:84] Creating Layer relu7_1
I0804 20:20:09.615178  4077 net.cpp:406] relu7_1 <- conv7_1
I0804 20:20:09.615196  4077 net.cpp:367] relu7_1 -> conv7_1 (in-place)
I0804 20:20:09.615214  4077 net.cpp:122] Setting up relu7_1
I0804 20:20:09.615228  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.615242  4077 net.cpp:137] Memory required for data: 105369600
I0804 20:20:09.615254  4077 layer_factory.hpp:77] Creating layer conv7_2
I0804 20:20:09.615275  4077 net.cpp:84] Creating Layer conv7_2
I0804 20:20:09.615288  4077 net.cpp:406] conv7_2 <- conv7_1
I0804 20:20:09.615304  4077 net.cpp:380] conv7_2 -> conv7_2
I0804 20:20:09.621238  4077 net.cpp:122] Setting up conv7_2
I0804 20:20:09.621295  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.621309  4077 net.cpp:137] Memory required for data: 106975232
I0804 20:20:09.621328  4077 layer_factory.hpp:77] Creating layer relu7_2
I0804 20:20:09.621350  4077 net.cpp:84] Creating Layer relu7_2
I0804 20:20:09.621364  4077 net.cpp:406] relu7_2 <- conv7_2
I0804 20:20:09.621382  4077 net.cpp:367] relu7_2 -> conv7_2 (in-place)
I0804 20:20:09.621402  4077 net.cpp:122] Setting up relu7_2
I0804 20:20:09.621417  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.621429  4077 net.cpp:137] Memory required for data: 108580864
I0804 20:20:09.621443  4077 layer_factory.hpp:77] Creating layer conv7_3
I0804 20:20:09.621462  4077 net.cpp:84] Creating Layer conv7_3
I0804 20:20:09.621475  4077 net.cpp:406] conv7_3 <- conv7_2
I0804 20:20:09.621491  4077 net.cpp:380] conv7_3 -> conv7_3
I0804 20:20:09.627493  4077 net.cpp:122] Setting up conv7_3
I0804 20:20:09.627552  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.627573  4077 net.cpp:137] Memory required for data: 110186496
I0804 20:20:09.627596  4077 layer_factory.hpp:77] Creating layer relu7_3
I0804 20:20:09.627615  4077 net.cpp:84] Creating Layer relu7_3
I0804 20:20:09.627630  4077 net.cpp:406] relu7_3 <- conv7_3
I0804 20:20:09.627646  4077 net.cpp:367] relu7_3 -> conv7_3 (in-place)
I0804 20:20:09.627665  4077 net.cpp:122] Setting up relu7_3
I0804 20:20:09.627679  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.627691  4077 net.cpp:137] Memory required for data: 111792128
I0804 20:20:09.627724  4077 layer_factory.hpp:77] Creating layer conv7_3norm
I0804 20:20:09.627745  4077 net.cpp:84] Creating Layer conv7_3norm
I0804 20:20:09.627759  4077 net.cpp:406] conv7_3norm <- conv7_3
I0804 20:20:09.627777  4077 net.cpp:380] conv7_3norm -> conv7_3norm
I0804 20:20:09.628041  4077 net.cpp:122] Setting up conv7_3norm
I0804 20:20:09.628060  4077 net.cpp:129] Top shape: 1 512 28 28 (401408)
I0804 20:20:09.628073  4077 net.cpp:137] Memory required for data: 113397760
I0804 20:20:09.628092  4077 layer_factory.hpp:77] Creating layer conv8_1
I0804 20:20:09.628108  4077 net.cpp:84] Creating Layer conv8_1
I0804 20:20:09.628121  4077 net.cpp:406] conv8_1 <- conv7_3norm
I0804 20:20:09.628137  4077 net.cpp:380] conv8_1 -> conv8_1
I0804 20:20:09.633472  4077 net.cpp:122] Setting up conv8_1
I0804 20:20:09.633524  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.633538  4077 net.cpp:137] Memory required for data: 116609024
I0804 20:20:09.633558  4077 layer_factory.hpp:77] Creating layer relu8_1
I0804 20:20:09.633577  4077 net.cpp:84] Creating Layer relu8_1
I0804 20:20:09.633591  4077 net.cpp:406] relu8_1 <- conv8_1
I0804 20:20:09.633610  4077 net.cpp:367] relu8_1 -> conv8_1 (in-place)
I0804 20:20:09.633627  4077 net.cpp:122] Setting up relu8_1
I0804 20:20:09.633642  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.633656  4077 net.cpp:137] Memory required for data: 119820288
I0804 20:20:09.633667  4077 layer_factory.hpp:77] Creating layer conv8_2
I0804 20:20:09.633687  4077 net.cpp:84] Creating Layer conv8_2
I0804 20:20:09.633700  4077 net.cpp:406] conv8_2 <- conv8_1
I0804 20:20:09.633716  4077 net.cpp:380] conv8_2 -> conv8_2
I0804 20:20:09.635646  4077 net.cpp:122] Setting up conv8_2
I0804 20:20:09.635679  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.635692  4077 net.cpp:137] Memory required for data: 123031552
I0804 20:20:09.635710  4077 layer_factory.hpp:77] Creating layer relu8_2
I0804 20:20:09.635727  4077 net.cpp:84] Creating Layer relu8_2
I0804 20:20:09.635741  4077 net.cpp:406] relu8_2 <- conv8_2
I0804 20:20:09.635756  4077 net.cpp:367] relu8_2 -> conv8_2 (in-place)
I0804 20:20:09.635773  4077 net.cpp:122] Setting up relu8_2
I0804 20:20:09.635788  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.635800  4077 net.cpp:137] Memory required for data: 126242816
I0804 20:20:09.635813  4077 layer_factory.hpp:77] Creating layer conv8_3
I0804 20:20:09.635833  4077 net.cpp:84] Creating Layer conv8_3
I0804 20:20:09.635845  4077 net.cpp:406] conv8_3 <- conv8_2
I0804 20:20:09.635860  4077 net.cpp:380] conv8_3 -> conv8_3
I0804 20:20:09.637930  4077 net.cpp:122] Setting up conv8_3
I0804 20:20:09.637982  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.637996  4077 net.cpp:137] Memory required for data: 129454080
I0804 20:20:09.638026  4077 layer_factory.hpp:77] Creating layer relu8_3
I0804 20:20:09.638046  4077 net.cpp:84] Creating Layer relu8_3
I0804 20:20:09.638061  4077 net.cpp:406] relu8_3 <- conv8_3
I0804 20:20:09.638082  4077 net.cpp:367] relu8_3 -> conv8_3 (in-place)
I0804 20:20:09.638106  4077 net.cpp:122] Setting up relu8_3
I0804 20:20:09.638126  4077 net.cpp:129] Top shape: 1 256 56 56 (802816)
I0804 20:20:09.638142  4077 net.cpp:137] Memory required for data: 132665344
I0804 20:20:09.638159  4077 layer_factory.hpp:77] Creating layer conv8_313
I0804 20:20:09.638182  4077 net.cpp:84] Creating Layer conv8_313
I0804 20:20:09.638200  4077 net.cpp:406] conv8_313 <- conv8_3
I0804 20:20:09.638224  4077 net.cpp:380] conv8_313 -> conv8_313
I0804 20:20:09.640097  4077 net.cpp:122] Setting up conv8_313
I0804 20:20:09.640142  4077 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 20:20:09.640156  4077 net.cpp:137] Memory required for data: 136591616
I0804 20:20:09.640175  4077 layer_factory.hpp:77] Creating layer conv8_313_rh
I0804 20:20:09.640195  4077 net.cpp:84] Creating Layer conv8_313_rh
I0804 20:20:09.640210  4077 net.cpp:406] conv8_313_rh <- conv8_313
I0804 20:20:09.640231  4077 net.cpp:380] conv8_313_rh -> conv8_313_rh
I0804 20:20:09.640395  4077 net.cpp:122] Setting up conv8_313_rh
I0804 20:20:09.640416  4077 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 20:20:09.640430  4077 net.cpp:137] Memory required for data: 140517888
I0804 20:20:09.640447  4077 layer_factory.hpp:77] Creating layer class8_313_rh
I0804 20:20:09.640465  4077 net.cpp:84] Creating Layer class8_313_rh
I0804 20:20:09.640480  4077 net.cpp:406] class8_313_rh <- conv8_313_rh
I0804 20:20:09.640496  4077 net.cpp:380] class8_313_rh -> class8_313_rh
I0804 20:20:09.640589  4077 net.cpp:122] Setting up class8_313_rh
I0804 20:20:09.640606  4077 net.cpp:129] Top shape: 1 313 56 56 (981568)
I0804 20:20:09.640619  4077 net.cpp:137] Memory required for data: 144444160
I0804 20:20:09.640632  4077 layer_factory.hpp:77] Creating layer class8_ab
I0804 20:20:09.640652  4077 net.cpp:84] Creating Layer class8_ab
I0804 20:20:09.640666  4077 net.cpp:406] class8_ab <- class8_313_rh
I0804 20:20:09.640681  4077 net.cpp:380] class8_ab -> class8_ab
I0804 20:20:09.640969  4077 net.cpp:122] Setting up class8_ab
I0804 20:20:09.640990  4077 net.cpp:129] Top shape: 1 2 56 56 (6272)
I0804 20:20:09.641002  4077 net.cpp:137] Memory required for data: 144469248
I0804 20:20:09.641037  4077 layer_factory.hpp:77] Creating layer Silence
I0804 20:20:09.641055  4077 net.cpp:84] Creating Layer Silence
I0804 20:20:09.641068  4077 net.cpp:406] Silence <- class8_ab
I0804 20:20:09.641083  4077 net.cpp:122] Setting up Silence
I0804 20:20:09.641095  4077 net.cpp:137] Memory required for data: 144469248
I0804 20:20:09.641108  4077 net.cpp:200] Silence does not need backward computation.
I0804 20:20:09.641121  4077 net.cpp:200] class8_ab does not need backward computation.
I0804 20:20:09.641134  4077 net.cpp:200] class8_313_rh does not need backward computation.
I0804 20:20:09.641147  4077 net.cpp:200] conv8_313_rh does not need backward computation.
I0804 20:20:09.641160  4077 net.cpp:200] conv8_313 does not need backward computation.
I0804 20:20:09.641173  4077 net.cpp:200] relu8_3 does not need backward computation.
I0804 20:20:09.641186  4077 net.cpp:200] conv8_3 does not need backward computation.
I0804 20:20:09.641199  4077 net.cpp:200] relu8_2 does not need backward computation.
I0804 20:20:09.641212  4077 net.cpp:200] conv8_2 does not need backward computation.
I0804 20:20:09.641224  4077 net.cpp:200] relu8_1 does not need backward computation.
I0804 20:20:09.641237  4077 net.cpp:200] conv8_1 does not need backward computation.
I0804 20:20:09.641252  4077 net.cpp:200] conv7_3norm does not need backward computation.
I0804 20:20:09.641264  4077 net.cpp:200] relu7_3 does not need backward computation.
I0804 20:20:09.641278  4077 net.cpp:200] conv7_3 does not need backward computation.
I0804 20:20:09.641289  4077 net.cpp:200] relu7_2 does not need backward computation.
I0804 20:20:09.641304  4077 net.cpp:200] conv7_2 does not need backward computation.
I0804 20:20:09.641315  4077 net.cpp:200] relu7_1 does not need backward computation.
I0804 20:20:09.641329  4077 net.cpp:200] conv7_1 does not need backward computation.
I0804 20:20:09.641341  4077 net.cpp:200] conv6_3norm does not need backward computation.
I0804 20:20:09.641355  4077 net.cpp:200] relu6_3 does not need backward computation.
I0804 20:20:09.641367  4077 net.cpp:200] conv6_3 does not need backward computation.
I0804 20:20:09.641379  4077 net.cpp:200] relu6_2 does not need backward computation.
I0804 20:20:09.641392  4077 net.cpp:200] conv6_2 does not need backward computation.
I0804 20:20:09.641405  4077 net.cpp:200] relu6_1 does not need backward computation.
I0804 20:20:09.641417  4077 net.cpp:200] conv6_1 does not need backward computation.
I0804 20:20:09.641430  4077 net.cpp:200] conv5_3norm does not need backward computation.
I0804 20:20:09.641443  4077 net.cpp:200] relu5_3 does not need backward computation.
I0804 20:20:09.641455  4077 net.cpp:200] conv5_3 does not need backward computation.
I0804 20:20:09.641469  4077 net.cpp:200] relu5_2 does not need backward computation.
I0804 20:20:09.641481  4077 net.cpp:200] conv5_2 does not need backward computation.
I0804 20:20:09.641511  4077 net.cpp:200] relu5_1 does not need backward computation.
I0804 20:20:09.641525  4077 net.cpp:200] conv5_1 does not need backward computation.
I0804 20:20:09.641540  4077 net.cpp:200] conv4_3norm does not need backward computation.
I0804 20:20:09.641553  4077 net.cpp:200] relu4_3 does not need backward computation.
I0804 20:20:09.641566  4077 net.cpp:200] conv4_3 does not need backward computation.
I0804 20:20:09.641579  4077 net.cpp:200] relu4_2 does not need backward computation.
I0804 20:20:09.641592  4077 net.cpp:200] conv4_2 does not need backward computation.
I0804 20:20:09.641605  4077 net.cpp:200] relu4_1 does not need backward computation.
I0804 20:20:09.641618  4077 net.cpp:200] conv4_1 does not need backward computation.
I0804 20:20:09.641631  4077 net.cpp:200] conv3_3norm does not need backward computation.
I0804 20:20:09.641644  4077 net.cpp:200] relu3_3 does not need backward computation.
I0804 20:20:09.641657  4077 net.cpp:200] conv3_3 does not need backward computation.
I0804 20:20:09.641670  4077 net.cpp:200] relu3_2 does not need backward computation.
I0804 20:20:09.641683  4077 net.cpp:200] conv3_2 does not need backward computation.
I0804 20:20:09.641696  4077 net.cpp:200] relu3_1 does not need backward computation.
I0804 20:20:09.641710  4077 net.cpp:200] conv3_1 does not need backward computation.
I0804 20:20:09.641722  4077 net.cpp:200] conv2_2norm does not need backward computation.
I0804 20:20:09.641736  4077 net.cpp:200] relu2_2 does not need backward computation.
I0804 20:20:09.641748  4077 net.cpp:200] conv2_2 does not need backward computation.
I0804 20:20:09.641762  4077 net.cpp:200] relu2_1 does not need backward computation.
I0804 20:20:09.641775  4077 net.cpp:200] conv2_1 does not need backward computation.
I0804 20:20:09.641789  4077 net.cpp:200] conv1_2norm does not need backward computation.
I0804 20:20:09.641803  4077 net.cpp:200] relu1_2 does not need backward computation.
I0804 20:20:09.641815  4077 net.cpp:200] conv1_2 does not need backward computation.
I0804 20:20:09.641829  4077 net.cpp:200] relu1_1 does not need backward computation.
I0804 20:20:09.641842  4077 net.cpp:200] bw_conv1_1 does not need backward computation.
I0804 20:20:09.641855  4077 net.cpp:200] data_l does not need backward computation.
I0804 20:20:09.641898  4077 net.cpp:255] Network initialization done.
I0804 20:20:09.746301  4077 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./zhang/colorization/models/colorization_release_v2.caffemodel
I0804 20:20:09.746364  4077 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0804 20:20:09.746381  4077 net.cpp:744] Ignoring source layer img
I0804 20:20:09.746395  4077 net.cpp:744] Ignoring source layer img_lab
I0804 20:20:09.746408  4077 net.cpp:744] Ignoring source layer img_slice
I0804 20:20:09.746420  4077 net.cpp:744] Ignoring source layer data_l_meansub
I0804 20:20:09.746433  4077 net.cpp:744] Ignoring source layer data_ab_ss
I0804 20:20:09.746445  4077 net.cpp:744] Ignoring source layer data_ab_ss_data_ab_ss_0_split
I0804 20:20:09.746457  4077 net.cpp:744] Ignoring source layer ab_enc
I0804 20:20:09.746470  4077 net.cpp:744] Ignoring source layer gt_ab_313_ab_enc_0_split
I0804 20:20:09.746482  4077 net.cpp:744] Ignoring source layer ab_pb
I0804 20:20:09.746495  4077 net.cpp:744] Ignoring source layer ab_pb
I0804 20:20:09.746507  4077 net.cpp:744] Ignoring source layer pb_nongray
I0804 20:20:09.774116  4077 net.cpp:744] Ignoring source layer PriorBoost8
I0804 20:20:09.774160  4077 net.cpp:744] Ignoring source layer SoftmaxLoss8
/home/thijser/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.
  warn("The default mode, 'constant', will be changed to 'reflect' in "
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
killing all other torch instances
/home/thijser/torch/install/bin/luajit: no process found
https://www.google.co.in/search?q=tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle&safe=off&source=lnms&tbm=isch&num=25
there are total 100 images
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
could not load : http://u0v052dm9wl3gxo0y3lx0u44wz.wpengine.netdna-cdn.com/wp-content/uploads/2014/05/Future-Protected-Vehicle-6.jpg
HTTP Error 403: Forbidden
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
th imageSelector.lua -avaible_images t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_45.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_23.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_35.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_67.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_61.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_91.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_7.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_59.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_40.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_98.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_11.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_90.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_74.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_44.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_6.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_2.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_9.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_88.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_94.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_57.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_62.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_20.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_30.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_96.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_95.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_58.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_41.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_4.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_28.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_83.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_49.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_52.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_78.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_97.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_37.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_55.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_73.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_66.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_17.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_32.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_84.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_5.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_31.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_13.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_85.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_81.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_82.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_72.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_18.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_60.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_14.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_76.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_3.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_22.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_8.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_33.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_46.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_77.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_75.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_29.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_65.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_63.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_24.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_69.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_68.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_15.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_51.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_80.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_21.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_86.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_56.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_1.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_34.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_99.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_43.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_79.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_92.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_12.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_36.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_16.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_38.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_53.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_64.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_93.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_26.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_25.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_48.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_87.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_71.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_42.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_39.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_50.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_89.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_27.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_47.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_54.jpg,t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_10.jpg
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574671192
Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv3_4: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv4_4: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
conv5_4: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000
coleval=2696184375	
neuroval=731703568	
coleval=2117188125	
neuroval=772922024	
coleval=2890207500	
neuroval=642541368	
coleval=367880625	
neuroval=724977952	
coleval=2392631250	
neuroval=770565904	
coleval=3696594375	
neuroval=712082672	
coleval=1921496250	
neuroval=927523728	
coleval=2218963125	
neuroval=938345120	
coleval=1874791875	
neuroval=712527456	
coleval=1290958125	
neuroval=691383944	
coleval=911351250	
neuroval=856904264	
coleval=3620945625	
neuroval=790289896	
coleval=1750860000	
neuroval=764417320	
coleval=1335238125	
neuroval=807804656	
coleval=2115802500	
neuroval=681119704	
coleval=1324185000	
neuroval=758286608	
coleval=3802674375	
neuroval=692405344	
coleval=2123446875	
neuroval=797662216	
coleval=4567672500	
neuroval=710162680	
coleval=1171550625	
neuroval=680538616	
coleval=1442471250	
neuroval=650282848	
coleval=1536260625	
neuroval=878234360	
coleval=1434788852.8915	
neuroval=741865504	
coleval=1899238125	
neuroval=774248304	
coleval=1992306557.8534	
neuroval=809358256	
coleval=2505050625	
neuroval=798465600	
coleval=1872423750	
neuroval=679186472	
coleval=476551875	
neuroval=818573696	
coleval=478185000	
neuroval=717197304	
coleval=2556650625	
neuroval=644908528	
coleval=1030822500	
neuroval=686025000	
coleval=1762800000	
neuroval=686523064	
coleval=2449183125	
neuroval=876959328	
coleval=869002500	
neuroval=919799904	
{
  1 : 
    {
      1 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_91.jpg"
      2 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_2.jpg"
      3 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_22.jpg"
      4 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_44.jpg"
      5 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_62.jpg"
    }
  2 : 1092858577
}
coleval=3087721875	
neuroval=761184784	
coleval=2066051250	
neuroval=757281808	
coleval=2329441875	
neuroval=711538872	
coleval=1727186250	
neuroval=704757968	
coleval=2105450625	
neuroval=841404736	
coleval=367880625	
neuroval=724977952	
coleval=370768125	
neuroval=628581936	
coleval=1840290000	
neuroval=624125048	
coleval=1794000000	
neuroval=634320056	
coleval=2303188125	
neuroval=670752944	
coleval=2303790000	
neuroval=687546744	
coleval=478185000	
neuroval=717197304	
coleval=2017410000	
neuroval=720048568	
coleval=1775070000	
neuroval=775527968	
coleval=1787679375	
neuroval=847197456	
coleval=2047149375	
neuroval=845933968	
coleval=2178495000	
neuroval=783445216	
coleval=476551875	
neuroval=818573696	
coleval=219849375	
neuroval=917767840	
coleval=210633750	
neuroval=868186496	
coleval=532811250	
neuroval=762594440	
coleval=1033743750	
neuroval=745250136	
coleval=2512190625	
neuroval=705380872	
coleval=1030822500	
neuroval=686025000	
coleval=2700851250	
neuroval=699386976	
coleval=2950297500	
neuroval=743813088	
coleval=2066062500	
neuroval=754983112	
coleval=1976368125	
neuroval=783855824	
coleval=1812000000	
neuroval=715523072	
coleval=911351250	
neuroval=856904264	
coleval=1173425625	
neuroval=846899576	
coleval=955183125	
neuroval=815364008	
coleval=1408606875	
neuroval=772899368	
coleval=1075946250	
neuroval=882347984	
coleval=2043356250	
neuroval=842478720	
{
  1 : 
    {
      1 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_91.jpg"
      2 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_78.jpg"
      3 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_22.jpg"
      4 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_44.jpg"
      5 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_62.jpg"
    }
  2 : 999350061
}
coleval=927106875	
neuroval=825560704	
coleval=3268646732.7046	
neuroval=830012456	
coleval=2858512500	
neuroval=850317304	
coleval=4449528750	
neuroval=790435160	
coleval=2279975625	
neuroval=712183480	
coleval=370768125	
neuroval=628581936	
coleval=249095625	
neuroval=609458096	
coleval=1486560000	
neuroval=622588616	
coleval=1593425625	
neuroval=669636160	
coleval=1609462500	
neuroval=690309536	
coleval=1040778750	
neuroval=759900520	
coleval=210633750	
neuroval=868186496	
coleval=203032500	
neuroval=922714848	
coleval=316025625	
neuroval=849624432	
coleval=2526251250	
neuroval=815444024	
coleval=2460155625	
neuroval=839597576	
coleval=2235661396.6043	
neuroval=775008600	
coleval=367880625	
neuroval=724977952	
coleval=255217500	
neuroval=735172960	
coleval=2377168125	
neuroval=739271632	
coleval=2539597500	
neuroval=811348480	
coleval=2438797500	
neuroval=836125968	
coleval=3106310625	
neuroval=795121680	
coleval=219849375	
neuroval=917767840	
coleval=323007130.30503	
neuroval=890695984	
coleval=1855272555.8073	
neuroval=821755768	
coleval=2004991103.7518	
neuroval=759333032	
coleval=2230680000	
neuroval=805114664	
coleval=2404395000	
neuroval=712226472	
coleval=478185000	
neuroval=717197304	
coleval=805860000	
neuroval=670979232	
coleval=923941875	
neuroval=683243536	
coleval=862220625	
neuroval=668511936	
coleval=549000000	
neuroval=715776376	
coleval=1254378750	
neuroval=715931368	
{
  1 : 
    {
      1 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_91.jpg"
      2 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_78.jpg"
      3 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_22.jpg"
      4 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_44.jpg"
      5 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_87.jpg"
    }
  2 : 858553721
}
coleval=3019158750	
neuroval=758757056	
coleval=2578783125	
neuroval=822889472	
coleval=2679588750	
neuroval=791690216	
coleval=2252795625	
neuroval=721462512	
coleval=921778125	
neuroval=739988512	
coleval=249095625	
neuroval=609458096	
coleval=346455000	
neuroval=664814712	
coleval=244873125	
neuroval=638502664	
coleval=2952841875	
neuroval=745875248	
coleval=2943412500	
neuroval=777401856	
coleval=2922251250	
neuroval=761436992	
coleval=255217500	
neuroval=735172960	
coleval=2303188125	
neuroval=670752944	
coleval=2216038125	
neuroval=761773032	
coleval=2946553125	
neuroval=806199144	
coleval=2954130000	
neuroval=772956640	
coleval=2415886875	
neuroval=735137080	
coleval=370768125	
neuroval=628581936	
coleval=1589473125	
neuroval=631076248	
coleval=2922322500	
neuroval=679810760	
coleval=3128383125	
neuroval=665903512	
coleval=2882653125	
neuroval=706533000	
coleval=2674318125	
neuroval=784036904	
coleval=210633750	
neuroval=868186496	
coleval=1610362500	
neuroval=853699312	
coleval=1795843125	
neuroval=858162320	
coleval=1691613750	
neuroval=852229536	
coleval=3070261875	
neuroval=830597352	
coleval=2655733125	
neuroval=713306800	
coleval=367880625	
neuroval=724977952	
coleval=394513125	
neuroval=788547736	
coleval=902475000	
neuroval=831135816	
coleval=991751250	
neuroval=809731248	
coleval=1042970625	
neuroval=761196272	
coleval=2534431875	
neuroval=768981904	
{
  1 : 
    {
      1 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_91.jpg"
      2 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_78.jpg"
      3 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_22.jpg"
      4 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_44.jpg"
      5 : "t/Pictures/tank+army+tank+armored+combat+vehicle+armoured+combat+vehicle/ActiOn_87.jpg"
    }
  2 : 858553721
}
coleval=2100695625	
neuroval=646313392	
coleval=2329492500	
neuroval=871453960	
coleval=4248663750	
neuroval=728201680	
coleval=3325676250	
neuroval=753501400	
coleval=2290706250	
neuroval=701355848	
coleval=249095625	
neuroval=609458096	
coleval=506349375	
neuroval=684196848	
coleval=581355000	
neuroval=721259552	
coleval=582073125	
neuroval=723605712	
coleval=749056875	
neuroval=690050832	
coleval=980778750	
neuroval=679555896	
coleval=244873125	
neuroval=638502664	
coleval=219748125	
neuroval=763961808	
coleval=2312077500	
neuroval=785810376	
coleval=3204076875	
neuroval=689697976	
coleval=2205492957.2442	
neuroval=734381576	
coleval=2766223125	
neuroval=732948072	
coleval=255217500	
neuroval=735172960	
coleval=1497045000	
neuroval=635148952	
coleval=605201250	
neuroval=635513688	
coleval=629769375	
neuroval=667148960	
coleval=3617566875	
neuroval=672235144	
coleval=3618063750	
neuroval=689028944	
coleval=370768125	
neuroval=628581936	
coleval=4225436250	
neuroval=717972168	
coleval=3731893125	
neuroval=687841216	
